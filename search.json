[
  
    {
      "title"    : "Triển khai seq2seq với Pytorch",
      "title-lower"    : "triển khai seq2seq với pytorch",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "NLP",
      "tags"     : "nlp, pytorch, model",
      "url"      : "/nlp/2023/10/06/seq2seq-pytorch/",
      "date"     : "2023-10-06 00:00:00 +0700",
      "img-feature": "/assets/media/feature/pytorch.png",
      "content": "Bài viết này giới thiệu cách sử dụng Pytorch để xây dựng mô hình seq2seq và triển khai một ứng dụng dịch máy đơn giản, vui lòng đọc sơ qua bài báo sau trước, Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation(2014), để hiểu rõ cấu trúc seq2seq hoạt động như thế nào, sau đó đọc bài viết này để đạt được hiệu quả gấp đôi chỉ với một nửa công sức.Tôi đã thấy rất nhiều sơ đồ cấu trúc mạng seq2seq và tôi cảm thấy sơ đồ này do Pytorch cung cấp là dễ hiểu nhất.        Trước hết, từ hình trên ta có thể thấy rõ ràng, seq2seq cần hoạt động trên ba “biến”, khác với tất cả các cấu trúc mạng mà tôi đã tiếp xúc trước đây. Chúng ta gọi đầu vào cho Encoder là enc_input, đầu vào cho Decoder là dec_input và đầu ra của Decoder là dec_output. Phần sau đây sử dụng một ví dụ cụ thể để minh họa cho toàn bộ quy trình thực hiện của seq2seq.Hình bên dưới là cấu trúc Encoder cấu tạo từ LTSM, đầu vào là từng chữ cái (bao gồm cả dấu cách) trong “go away”, chúng ta cần thông tin của hidden state ở thời điểm cuối cùng, bao gồm (h_{t}) và (c_{t}).        Sau đó sử dụng đầu ra gồm (h_{t}) và (c_{t}) làm đầu vào cho hidden state đầu tiên của Decoder là (h_{0}, c_{0}), như hình bên dưới. Đồng thời, lớp đầu vào (input layer) đầu của Decoder sẽ được nhập một ký tự đại diện cho phần đầu của câu (Do người dùng tự định nghĩa có thể là “&amp;lt;SOS&amp;gt;”, “t”, “S”, …. đều được chấp nhận. Ở đây, tôi lấy “t” làm ví dụ), và sau đó nhận đầu ra “m”, và một hidden state mới (h_{1}) và (c_{1})        Sau đó lấy (h_{1}), (c_{1}) và “m” làm đầu vào, nhận đầu ra là “a”, và một hidden state mới (h_{2}) và (c_{2})        Lặp lại các bước trên cho đến khi ký tự kết thúc của câu cuối cùng được xuất ra (do người dùng xác định, “&amp;lt;EOS&amp;gt;”, “n”, “E”, … ở đây tôi lấy “n” làm ví dụ).        Trong phần Decoder, bạn sẽ có thể có những câu hỏi sau và tôi sẽ trả lời chúng theo hiểu biết cá nhân.  Tôi phài làm như thế nào nếu Decoder không thể dừng lại trong quá trình đào tạo? Tức là ký tự kết thúc của câu không bao giờ được đưa ra.          Đầu tiên, trong quá trình huấn luyện, độ dài của câu mà Decoder sẽ xuất ra sẽ được biết. Giả sử thời điểm hiện tại đã đến ký tự cuối cùng của độ dài câu và dự đoán không phải là ký tự kết thúc thì cũng không sao, chỉ dừng lại ở đây và tính toán tổn thất.        Tôi phải làm như thế nào nếu Decocder không thể dừng lại trong quá trình kiểm tra? Ví dụ, dự đoán là “wasd s w n sdsw n …… (tiếp tục sinh từ)”          Nó sẽ không dừng lại, vì trong quá trình kiểm tra, Decoder cũng có đầu vào, nhưng đầu vào này có rất nhiều placeholder vô nghĩa, chẳng hạn rất nhiều “&amp;lt;pad&amp;gt;”. Vì Decoder phải có đầu ra có độ dài hữu hạn. Khi đó bạn chỉ lấy tất cả các ký tự trước ký tự kết thúc đầu tiên. Ví dụ trên kết quả dự đoán cuối cùng là “wasd s w”.        Mối quan hệ giữa đầu vào và đầu ra của Decoder, tức là dec_input và dec_output là gì?          Trong quá trình huấn luyện, bất kể Decoder sinh ra kí tự nào tại thời điểm hiện tại, Decoder tại thời điểm tiếp theo sẽ nhập theo “kế hoạch” ban đầu. Ví dụ: giả sử dec_input = &quot;twasted&quot;, sau khi nhập “t” lần đầu, Decoder sẽ xuất ra chữ “m”, ghi lại thôi, nó sẽ không ảnh hưởng đến thời điểm tiếp theo khi Decoder tiếp tục nhập chữ “w”.      Trong quá trình valid và testing, đầu ra của Decoder tại mỗi thời điểm sẽ ảnh hưởng đến đầu vào, vì trong quá trình valid và testing, mạng không thể nhìn thấy kết quả nên chỉ tiến hành theo vòng lặp. Ví dụ, bây giờ tôi muốn dịch từ “wasted” trong tiếng anh sang tiếng “lãng phí” trong tiếng việt. Sau đó, Decoder bắt đầu với việc nhập ký tự “t”, nhận kết quả đầu ra nếu là “m”, tại thời điểm tiếp theo, Decoder sẽ nhập “m”, nhận đầu ra, nếu là “a”, sau đó nhận “a” là đầu vào, nhận đầu ra, … và cứ thế cho đến khi gặp kí tự cuối cùng hoặc đạt độ dài tối đa. Mặc dù từ sinh ra không đúng nhưng mong đợi nhưng phải chấp nhận thôi :smiley:.      Hơi lạc đề một chút, cá nhân tôi nghĩ seq2seq rất giống với AutoEncoder.Hãy bắt đầu giải thích mãĐầu tiên, import thư viện, ở đây tôi dùng ‘S’ làm ký tự bắt đầu và ‘E’ làm ký tự kết thúc, nếu đầu vào hoặc đầu ra quá ngắn, tôi sẽ padding nó bằng ký tự ‘?’.# code by Tae Hwan Jung(Jeff Jung) @graykode, modify by zhaospeiimport torchimport numpy as npimport torch.nn as nnimport torch.utils.data as Datadevice = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)# S: Symbol that shows starting of decoding input# E: Symbol that shows starting of decoding output# ?: Symbol that will fill in blank sequence if current batch data size is short than n_stepXác định tập dữ liệu và các tham số tập dữ liệu ở đây rất đơn giản, có thể coi như một công việc dịch thuật, chỉ là dịch tiếng Anh sang tiếng Anh.n_step` là độ dài của từ dài nhất, tất cả các từ khác không đủ dài sẽ được padding bằng ‘?’.letter = [c for c in &#39;SE?abcdefghijklmnopqrstuvwxyz&#39;]letter2idx = {n: i for i, n in enumerate(letter)}seq_data = [[&#39;man&#39;, &#39;women&#39;], [&#39;black&#39;, &#39;white&#39;], [&#39;king&#39;, &#39;queen&#39;], [&#39;girl&#39;, &#39;boy&#39;], [&#39;up&#39;, &#39;down&#39;], [&#39;high&#39;, &#39;low&#39;]]# Seq2Seq Parametern_step = max([max(len(i), len(j)) for i, j in seq_data]) # max_len(=5)n_hidden = 128n_class = len(letter2idx) # classfication problembatch_size = 3Sau đây là xử lý dữ liệu, trước tên là xử lý các từ không đủ độ dài, sử dụng ký tự ‘?’ để padding; Sau đó thêm flag kết thúc ‘E’ vào cuối dữ liệu đầu vào của Encoder, thêm flag bắt đầu ‘S’ vào đầu dữ liệu đầu vào của Decoder và flag kết thúc ‘E’ vào cuối dữ liệu đầu ra của Decoder. Xem hình phía dưới để hiểu rõ hơn.        def make_data(seq_data):    enc_input_all, dec_input_all, dec_output_all = [], [], []    for seq in seq_data:        for i in range(2):            seq[i] = seq[i] + &#39;?&#39; * (n_step - len(seq[i])) # &#39;man??&#39;, &#39;women&#39;        enc_input = [letter2idx[n] for n in (seq[0] + &#39;E&#39;)] # [&#39;m&#39;, &#39;a&#39;, &#39;n&#39;, &#39;?&#39;, &#39;?&#39;, &#39;E&#39;]        dec_input = [letter2idx[n] for n in (&#39;S&#39; + seq[1])] # [&#39;S&#39;, &#39;w&#39;, &#39;o&#39;, &#39;m&#39;, &#39;e&#39;, &#39;n&#39;]        dec_output = [letter2idx[n] for n in (seq[1] + &#39;E&#39;)] # [&#39;w&#39;, &#39;o&#39;, &#39;m&#39;, &#39;e&#39;, &#39;n&#39;, &#39;E&#39;]        enc_input_all.append(np.eye(n_class)[enc_input])        dec_input_all.append(np.eye(n_class)[dec_input])        dec_output_all.append(dec_output) # not one-hot    # make tensor    return torch.Tensor(enc_input_all), torch.Tensor(dec_input_all), torch.LongTensor(dec_output_all)&#39;&#39;&#39;enc_input_all: [6, n_step+1 (because of &#39;E&#39;), n_class]dec_input_all: [6, n_step+1 (because of &#39;S&#39;), n_class]dec_output_all: [6, n_step+1 (because of &#39;E&#39;)]&#39;&#39;&#39;enc_input_all, dec_input_all, dec_output_all = make_data(seq_data)Ví có ba dữ liệu trả về ở đây, vì vậy cần tùy chỉnh Dataset, cụ thể là kế thừa lớp torch.utils.data.Dataset, sau đó triển khai các phương thức __len__ và __getitem__ bên trong.class TranslateDataSet(Data.Dataset):    def __init__(self, enc_input_all, dec_input_all, dec_output_all):        self.enc_input_all = enc_input_all        self.dec_input_all = dec_input_all        self.dec_output_all = dec_output_all        def __len__(self): # return dataset size        return len(self.enc_input_all)        def __getitem__(self, idx):        return self.enc_input_all[idx], self.dec_input_all[idx], self.dec_output_all[idx]loader = Data.DataLoader(TranslateDataSet(enc_input_all, dec_input_all, dec_output_all), batch_size, True)Xác định mô hình seq2seq bên dưới, tôi sử dụng RNN đơn giản làm Encoder và Decoder. Nếu bạn đã quen thuộc với RNN thì thực sự không có gì phải nói về việc xác định cấu trúc mạng, tôi cũng đã viết nhận xét rất rõ ràng, bao gồm cả những thay đổi về kích thước dữ liệu.# Modelclass Seq2Seq(nn.Module):    def __init__(self):        super(Seq2Seq, self).__init__()        self.encoder = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5) # encoder        self.decoder = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5) # decoder        self.fc = nn.Linear(n_hidden, n_class)    def forward(self, enc_input, enc_hidden, dec_input):        # enc_input(=input_batch): [batch_size, n_step+1, n_class]        # dec_inpu(=output_batch): [batch_size, n_step+1, n_class]        enc_input = enc_input.transpose(0, 1) # enc_input: [n_step+1, batch_size, n_class]        dec_input = dec_input.transpose(0, 1) # dec_input: [n_step+1, batch_size, n_class]        # h_t : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]        _, h_t = self.encoder(enc_input, enc_hidden)        # outputs : [n_step+1, batch_size, num_directions(=1) * n_hidden(=128)]        outputs, _ = self.decoder(dec_input, h_t)        model = self.fc(outputs) # model : [n_step+1, batch_size, n_class]        return modelmodel = Seq2Seq().to(device)criterion = nn.CrossEntropyLoss().to(device)optimizer = torch.optim.Adam(model.parameters(), lr=0.001)Sau đây là phần training. Vì giá trị đầu ra là dữ liệu ba chiều nên việc tính toán loss đòi hỏi phải tính toán từng mẫu riêng biệt, do đó có mã vòng for sau đây.for epoch in range(5000):  for enc_input_batch, dec_input_batch, dec_output_batch in loader:      # make hidden shape [num_layers * num_directions, batch_size, n_hidden]      h_0 = torch.zeros(1, batch_size, n_hidden).to(device)      (enc_input_batch, dec_intput_batch, dec_output_batch) = (enc_input_batch.to(device), dec_input_batch.to(device), dec_output_batch.to(device))      # enc_input_batch : [batch_size, n_step+1, n_class]      # dec_intput_batch : [batch_size, n_step+1, n_class]      # dec_output_batch : [batch_size, n_step+1], not one-hot      pred = model(enc_input_batch, h_0, dec_intput_batch)      # pred : [n_step+1, batch_size, n_class]      pred = pred.transpose(0, 1) # [batch_size, n_step+1(=6), n_class]      loss = 0      for i in range(len(dec_output_batch)):          # pred[i] : [n_step+1, n_class]          # dec_output_batch[i] : [n_step+1]          loss += criterion(pred[i], dec_output_batch[i])      if (epoch + 1) % 1000 == 0:          print(&#39;Epoch:&#39;, &#39;%04d&#39; % (epoch + 1), &#39;cost =&#39;, &#39;{:.6f}&#39;.format(loss))                optimizer.zero_grad()      loss.backward()      optimizer.step()Như có thể thấy từ mã testing bên dưới, trong quá trình testing, đầu vào của Decoder là một phần giữ chỗ vô nghĩa và độ dài của vị trí bị chiếm giữ là độ dài tối đa n_step. Và tìm vị trí của dấu kết thúc đầu tiên ở đầu ra, chặn tất cả các ký tự trước nó.# Testdef translate(word):    enc_input, dec_input, _ = make_data([[word, &#39;?&#39; * n_step]])    enc_input, dec_input = enc_input.to(device), dec_input.to(device)    # make hidden shape [num_layers * num_directions, batch_size, n_hidden]    hidden = torch.zeros(1, 1, n_hidden).to(device)    output = model(enc_input, hidden, dec_input)    # output : [n_step+1, batch_size, n_class]    predict = output.data.max(2, keepdim=True)[1] # select n_class dimension    decoded = [letter[i] for i in predict]    translated = &#39;&#39;.join(decoded[:decoded.index(&#39;E&#39;)])    return translated.replace(&#39;?&#39;, &#39;&#39;)print(&#39;test&#39;)print(&#39;man -&amp;gt;&#39;, translate(&#39;man&#39;))print(&#39;mans -&amp;gt;&#39;, translate(&#39;mans&#39;))print(&#39;king -&amp;gt;&#39;, translate(&#39;king&#39;))print(&#39;black -&amp;gt;&#39;, translate(&#39;black&#39;))print(&#39;up -&amp;gt;&#39;, translate(&#39;up&#39;))Mã hoàn chỉnh như sauPhần thực thi bạn có thể xem tại notebook trên kaggle tại https://www.kaggle.com/code/overvisual/seq2seq-torch?scriptVersionId=145596925# code by Tae Hwan Jung(Jeff Jung) @graykode, modify by zhaospeiimport torchimport numpy as npimport torch.nn as nnimport torch.utils.data as Datadevice = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)# S: Symbol that shows starting of decoding input# E: Symbol that shows starting of decoding output# ?: Symbol that will fill in blank sequence if current batch data size is short than n_stepletter = [c for c in &#39;SE?abcdefghijklmnopqrstuvwxyz&#39;]letter2idx = {n: i for i, n in enumerate(letter)}seq_data = [[&#39;man&#39;, &#39;women&#39;], [&#39;black&#39;, &#39;white&#39;], [&#39;king&#39;, &#39;queen&#39;], [&#39;girl&#39;, &#39;boy&#39;], [&#39;up&#39;, &#39;down&#39;], [&#39;high&#39;, &#39;low&#39;]]# Seq2Seq Parametern_step = max([max(len(i), len(j)) for i, j in seq_data]) # max_len(=5)n_hidden = 128n_class = len(letter2idx) # classfication problembatch_size = 3def make_data(seq_data):    enc_input_all, dec_input_all, dec_output_all = [], [], []    for seq in seq_data:        for i in range(2):            seq[i] = seq[i] + &#39;?&#39; * (n_step - len(seq[i])) # &#39;man??&#39;, &#39;women&#39;        enc_input = [letter2idx[n] for n in (seq[0] + &#39;E&#39;)] # [&#39;m&#39;, &#39;a&#39;, &#39;n&#39;, &#39;?&#39;, &#39;?&#39;, &#39;E&#39;]        dec_input = [letter2idx[n] for n in (&#39;S&#39; + seq[1])] # [&#39;S&#39;, &#39;w&#39;, &#39;o&#39;, &#39;m&#39;, &#39;e&#39;, &#39;n&#39;]        dec_output = [letter2idx[n] for n in (seq[1] + &#39;E&#39;)] # [&#39;w&#39;, &#39;o&#39;, &#39;m&#39;, &#39;e&#39;, &#39;n&#39;, &#39;E&#39;]        enc_input_all.append(np.eye(n_class)[enc_input])        dec_input_all.append(np.eye(n_class)[dec_input])        dec_output_all.append(dec_output) # not one-hot    # make tensor    return torch.Tensor(enc_input_all), torch.Tensor(dec_input_all), torch.LongTensor(dec_output_all)&#39;&#39;&#39;enc_input_all: [6, n_step+1 (because of &#39;E&#39;), n_class]dec_input_all: [6, n_step+1 (because of &#39;S&#39;), n_class]dec_output_all: [6, n_step+1 (because of &#39;E&#39;)]&#39;&#39;&#39;enc_input_all, dec_input_all, dec_output_all = make_data(seq_data)class TranslateDataSet(Data.Dataset):    def __init__(self, enc_input_all, dec_input_all, dec_output_all):        self.enc_input_all = enc_input_all        self.dec_input_all = dec_input_all        self.dec_output_all = dec_output_all        def __len__(self): # return dataset size        return len(self.enc_input_all)        def __getitem__(self, idx):        return self.enc_input_all[idx], self.dec_input_all[idx], self.dec_output_all[idx]loader = Data.DataLoader(TranslateDataSet(enc_input_all, dec_input_all, dec_output_all), batch_size, True)# Modelclass Seq2Seq(nn.Module):    def __init__(self):        super(Seq2Seq, self).__init__()        self.encoder = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5) # encoder        self.decoder = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5) # decoder        self.fc = nn.Linear(n_hidden, n_class)    def forward(self, enc_input, enc_hidden, dec_input):        # enc_input(=input_batch): [batch_size, n_step+1, n_class]        # dec_inpu(=output_batch): [batch_size, n_step+1, n_class]        enc_input = enc_input.transpose(0, 1) # enc_input: [n_step+1, batch_size, n_class]        dec_input = dec_input.transpose(0, 1) # dec_input: [n_step+1, batch_size, n_class]        # h_t : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]        _, h_t = self.encoder(enc_input, enc_hidden)        # outputs : [n_step+1, batch_size, num_directions(=1) * n_hidden(=128)]        outputs, _ = self.decoder(dec_input, h_t)        model = self.fc(outputs) # model : [n_step+1, batch_size, n_class]        return modelmodel = Seq2Seq().to(device)criterion = nn.CrossEntropyLoss().to(device)optimizer = torch.optim.Adam(model.parameters(), lr=0.001)for epoch in range(5000):  for enc_input_batch, dec_input_batch, dec_output_batch in loader:      # make hidden shape [num_layers * num_directions, batch_size, n_hidden]      h_0 = torch.zeros(1, batch_size, n_hidden).to(device)      (enc_input_batch, dec_intput_batch, dec_output_batch) = (enc_input_batch.to(device), dec_input_batch.to(device), dec_output_batch.to(device))      # enc_input_batch : [batch_size, n_step+1, n_class]      # dec_intput_batch : [batch_size, n_step+1, n_class]      # dec_output_batch : [batch_size, n_step+1], not one-hot      pred = model(enc_input_batch, h_0, dec_intput_batch)      # pred : [n_step+1, batch_size, n_class]      pred = pred.transpose(0, 1) # [batch_size, n_step+1(=6), n_class]      loss = 0      for i in range(len(dec_output_batch)):          # pred[i] : [n_step+1, n_class]          # dec_output_batch[i] : [n_step+1]          loss += criterion(pred[i], dec_output_batch[i])      if (epoch + 1) % 1000 == 0:          print(&#39;Epoch:&#39;, &#39;%04d&#39; % (epoch + 1), &#39;cost =&#39;, &#39;{:.6f}&#39;.format(loss))                optimizer.zero_grad()      loss.backward()      optimizer.step()    # Testdef translate(word):    enc_input, dec_input, _ = make_data([[word, &#39;?&#39; * n_step]])    enc_input, dec_input = enc_input.to(device), dec_input.to(device)    # make hidden shape [num_layers * num_directions, batch_size, n_hidden]    hidden = torch.zeros(1, 1, n_hidden).to(device)    output = model(enc_input, hidden, dec_input)    # output : [n_step+1, batch_size, n_class]    predict = output.data.max(2, keepdim=True)[1] # select n_class dimension    decoded = [letter[i] for i in predict]    translated = &#39;&#39;.join(decoded[:decoded.index(&#39;E&#39;)])    return translated.replace(&#39;?&#39;, &#39;&#39;)print(&#39;test&#39;)print(&#39;man -&amp;gt;&#39;, translate(&#39;man&#39;))print(&#39;mans -&amp;gt;&#39;, translate(&#39;mans&#39;))print(&#39;king -&amp;gt;&#39;, translate(&#39;king&#39;))print(&#39;black -&amp;gt;&#39;, translate(&#39;black&#39;))print(&#39;up -&amp;gt;&#39;, translate(&#39;up&#39;))Tham khảo[1] https://www.kaggle.com/code/overvisual/seq2seq-torch?scriptVersionId=145596925"
    } ,
  
    {
      "title"    : "Attention is All You Need",
      "title-lower"    : "attention is all you need",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "NLP",
      "tags"     : "nlp, paper, model",
      "url"      : "/nlp/2023/10/06/attention-is-all-you-need/",
      "date"     : "2023-10-06 00:00:00 +0700",
      "img-feature": "/assets/media/feature/transformers.jpg",
      "content": "Transformer là mô hình seq2seq được Google Brain đề xuất trong một bài báo xuất bản vào cuối năm 2017. Giờ đây, nó đã đạt được nhiều ứng dụng và tiện ích mở rộng và BERT là mô hình ngôn ngữ được đào tạo trước có nguồn gốc từ Transformer.Việc đào tạo RNN truyền thống là nối tiếp và nó phải đợi từ hiện tại được xử lý trước khi có thể xử lý từ tiếp theo. Transformer được huấn luyện song song, tức là tất cả các từ đều được huấn luyện cùng một lúc, điêu này làm tăng đáng kể hiệu quả tính toán.        Kiến trúc mô hình Transformer# Self-AttentionScaled Dot-Product Attention là tích chấm chuẩn hóa Attention, chi tiết cụ thể được thể hiện trong hình.        [Attention(Q,K,V)=softmax(dfrac{QK^T}{sqrt{d_k}})V]Sự chú ý của nhiều đầu vào sử dụng nhiều bộ trọng số (weights) ((W_q,W_k,W_v)), ghép lại cho ra kết quả cuối cùng.[MultiHead(Q,K,V)=Concat(head_1,...,head_h)W^O]trong đó[head_i=Attention(QW^Q_i,KW^K_i,VW^V_i)]Trong đó (h = 8), (d_q=d_k=d_v=d_{model}/4=64).# EncoderEncoder được xếp chồng lên nhau bởi sáu lớp giống hệt nhau, mỗi lớp bao gồm hai lớp con - cơ chế tự chú ý nhiều đầu (multi-head self-attention mechanism) và mạng nơ ron vị trí chuyển tiếp được kết nối đầy đủ (position-wise fully connected feed-forward network). Mỗi lớp con sử dụng các kết nối dư (residual connection) và lớp chuẩn hóa (layer normalization). Kích thước đầu ra của các lớp con là (d_{model} = 512).Đầu ra của lớp con có thể được biểu diễn dưới dạng:[LayerNorm(x+Sublayer(x))]position-wise fully connected feed-forward networkMạng nơ-ron chuyển tiếp được kết nối đầy đủ (position-wise fully connected feed-forward network) bao gồm hai phép biến đổi tuyến tính với kích hoạt ReLU ở giữa.[FFN(x)=ReLU(xW_1+b_1)W_2+b_2]Kích thước lớp bên trong (inner-layer) là 2048.residual connectionMạng dư (Residual Network), các kết nối tắt có khả năng bỏ qua một hoặc nhiều lớp, do sự tồn tại của kết nối tắt nên hiệu suất của mạng sâu (có nhiều lớp) không kém hơn so với các mạng nông (mạng có ít lớp). Phương pháp này giải quyết vấn đề suy thoái do các lớp chập xếp chồng lên nhau gây ra, số lượng lớp của mạng nơ-ron tích chập đã được tăng lên rất nhiều lên hàng trăm lớp, và cải thiện đáng kể hiệu suất của mạng thần kinh tích chập (resnet).        Batch Norm và Layer Norm        Đặt kích thước hình ảnh đầu vào là ([N, C, H, W]):  Batch Norm, chuẩn hóa theo từng batch NHW, là để chuẩn hóa đầu vào từng kênh đơn, đều này không hiệu quả đối với batch-size nhỏ.  Layer Norm, chuẩn hóa theo từng layer CHW, là để chuẩn hóa đầu vào ở mỗi độ sâu, chủ yếu có tác dụng rõ ràng trên RNN.Sự hiểu biết cá nhân:  Dành cho CNN, nếu hạt nhân tích chập quét hình ảnh đầu vào, nó được tính là thao tác tích chập, cần có tổng thao tác batchsize. Do đó, chuẩn hóa cần được thực hiện theo batch.  Dành cho RNN, batchsize thường là 1, số vòng lặp là số độ dài đầu vào (số channel). Do đó, chuẩn hóa cần được thực hiện theo channel.Toàn bộ kiến trúc Encoderinput &amp;amp; positional embedding[X=Embedding-Lookup(X)+Positional-Encoding]multi-head attention[Q=Linear_q(X)=XW_q][K=Linear_q(X)=XW_k][V=Linear_v(X)=XW_v][X_{attention}=Self-Attention(Q,K,V)]add &amp;amp; norm[X_{attention}=LayerNorm(X+X_{attention})]feed forward[X_{hidden}=Linear(ReLU(Linear(X_{attention})))]add &amp;amp; norm[X_{hidden}=LayerNorm(X_{hidden}+X_{attention})]multi-head attention trong Encoder là một cơ chế tự chú ý (self-attention mechanism). (k), (q) và (v) trong cơ chế tự chú ý đều xuất phát từ cùng một vị trí, mỗi lớp của Encoder có thể nhận được tất cả vị trí của lớp trước.# DecoderDecoder bao gồm sáu lớp giống hệt xếp chồng lên nhau; trong Multi-head Attention, (q) được đến từ lớp trước đó của Decoder, k và v đến từ đầu ra của Encoder. Điều cho phép mỗi vị trí trong Decoder nhận biết được tất cả các vị trí của chuỗi đầu vào.Ngoài hai lớp con trong Encoder, Decoder thêm một lớp con mới xử lý đầu ra của Encoder - masked multi-head self-attention mechanism. Encoder trong seq2seq truyền thống sử dụng mô hình RNN, vì vậy nếu các từ tại thời điểm t được nhập vào trong quá trình huấn luyện thì mô hình sẽ không thể nhìn thấy các từ trước đó vào các thời điểm trong tương lai, bởi vì RNN hoạt động theo thời gian và chỉ khi thao tác tại thời điểm t hoàn thành, chỉ khi đó ta mới có thể nhìn thấy các từ tại thời điểm t + 1. Và Transformer Decoder đã không sử dụng RNN, thay đổi sang Self-Attention, điều này tạo ra một vấn đề, trong quá trình huấn luyện, toàn bộ ground truth đã được hiển thị với Decoder, điều này rõ ràng là sai, chúng ta cần phải thực hiện một số xử lý trên đầu vào của Decoder, quá trình này được gọi là Mask - Đặt tất cả các giá trị sau postion thành (-infty) trước khi vào softmax.Ví dụ, ground truth của Decoder là “&amp;lt;start&amp;gt; I am fine”, chúng ta cho câu này vào bộ Decoder, sau khi Word Embedding và Positional Encoding, thực hiện phép biến đổi tuyến tính bậc 3 trên ma trận thu được ((W_Q,W_K,W_V)) Sau đó thực hiện self-attention, trước tiên, nhận Scaled Scores thông qua (dfrac{Q×K^T}{sqrt{d_k}}), bước tiếp theo rất quan trọng, chúng ta cần mask theo Scaled Scores, ví dụ, khi nhập “I”, hiện tại mô hình chỉ biết thông tin của tất cả các từ trước đó của “I”, tức thông tin của “&amp;lt;start&amp;gt;” và “I”, không được phép biết được thông tin của các từ sau “I”. Lý do rất đơn giản, khi dự đoán là chúng ta dự đoán theo thứ tự từng chữ, làm sao có thể biết được thông tin của những từ sau trước khi dự đoán xong từ này? Mask rất đơn giản, đầu tiên tạo một ma trận có tam giác hoàn toàn phía dưới bằng 0 và tam giác hoàn tòan phía trên bằng âm vô cùng, sau đó chỉ cần thêm nó vào Scaled Scores.# Word Embedding và Positional EmbeddingWord EmbeddingPhần nhúng từ sử dụng nhúng từ có thể học được, kích thước của nó là (d_{model}).Hình thức mã hóa One-hot ngắn gọn, nhưng quá thưa thớt, nó không phản ánh sự giống nhau về nghĩa của từ. Vì vậy hãy sử dụng the Skip-Gram Model hoặc continuous bag of words model hoặc các nhúng từ khác có thể học được khác.Positional EmbeddingBởi vì mô hình không bao gồm các cấu trúc tuần hoàn, vì vậy nắm bắt được các thông tin thứ tự tuần tự, ví dụ nếu (K) và (V) được xóa trộn theo từng hàng thì kết quả sau Attention sẽ giống nhau. Tuy nhiên, thông tin tuần tự rất quan trọng và thể hiện cấu trúc toàn cầu, do đó thông tin position tuyệt đối và tương đối của token tuần tự phải được sử dụng.Nhúng vị trí tùy chinhMột ý tưởng là lấy một số trong khoảng ([0, 1]) và gán nó cho mỗi từ, trong đó 0 được trao cho từ đầu tiên, 1 cho từ cuối cùng, công thức cụ thể là (PE=dfrac{pos}{T−1}). Vấn đề của việc gán theo công thức này là nó bị phụ thuộc và kích thước của văn bản. Tứclà văn bản có số kí tự là 30. Khi đó theo công thức trên, thì khoảng cách giữa hai từ sẽ là 0.0333. Khi văn bản khác có số lượng kí từ &amp;lt; 30, thì con số 0.0333 vẫn mô tả đúng vị trí tương đối giữa chúng, tuy nhiên với văn bản &amp;gt; 30, ví dụ 90 thì 0.0333 đang gộp khoảng cách thực tế đang được phân tách bởi hai ký tự. Điều này rõ ràng là không phù hợp, vì sự khác biệt giống nhau không có nghĩa là giống nhau trong các câu khác nhau.Một ý tưởng khác là gắn tuyến tính mỗi bước theo thời gian, nghĩa là từ đầu tiên được gán là 1, từ thứ hai được gán là 2, … Phương pháp này cũng có những vấn đề lớn: 1. Nó lớn hơn giá trị nhúng từ thông từ, có thể gây nhiễu cho mô hình; 2. Ký tự cuối cùng lớn hơn nhiều ký tự đầu tiên, sau khi hợp nhất với các từ nhúng, giá trị của các đặc trưng sẽ bị sai lệch.Nhúng từ vị trí “lý tuởng”Một lý tưởng là thiết kế nhúng vị trí phải đáp ứng những tiêu chí sau:  Nó sẽ xuất ra mã hóa duy nhất cho mỗi từ.  Sự khác biệt giữa hai từ phải nhất quán giữa các câu có độ dài khác nhau.  Giá trị của nó phải được giới hạn.Do đó việc nhúng vị trí sin và cosin đã được sử dụng cho Transformer.Bây giờ hãy định nghĩa lại Positional Embedding, kích thước của việc nhúng vị trí là [max_sequence_length, embedding_dimension], kích thước của phần nhúng vị trí giống với kích thước của vector từ, đều bằng embedding_dimension. max_sequence_length là một hyperparameter, đề cập đến số lượng tối đa mà một câu bao gồm.Kích thước của việc nhúng vị trí cũng giống như kích thước của việc nhúng từ, cùng là (d_{model}). Công thước tính toán của nó là:[PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})][PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})]Trong đó, (pos) đại diện cho chỉ mục vị trí, (i) đại diện cho chỉ số chiều. Nghĩa là mỗi chiều (i) của positional embedding pos tương ứng với một sóng sin.Trong hình dưới này minh họa cho cách tính position embedding của tác giả với số chiều là 6. Giá trị của các vector tại mỗi vị trí được tính toán theo công thức ở hình dưới.        Bản thân việc nhúng vị trí là một thông tin vị trí tuyệt đối, nhưng trong ngôn ngữ, vị trí tương đối cũng rất quan trọng, bởi vì[sin(alpha+beta)=sinalpha cosbeta+cosalpha sinbetacos(alpha+beta)=cosalpha cosbeta-sinalpha sinbeta]cho thấy vector tại vị trí (p + k) có thể được biểu diễn dưới dạng phép biến đổi tuyến tính của vectơ tại vị trí (p), điều này cung cấp khả năng thể hiện thông tin vị trí tương đối. Phiên bản hình sin cũng cho phép mô hình ngoại suy với độ dài chuỗi dài hơn so với độ dài chuỗi gặp phải trong quá trình huấn luyện.# Q &amp;amp; ATại sao Transformer cần Multi-head Attention ?Bài báo đề cập lý do việc tiến hành Multi-head Attention là để chia mô hình thành nhiều đầu để tạo thành nhiều không gian con, cho phép mô hình chú ý đến các khía cạnh khác nhau của thông tin và cuối cùng tổng hợp thông tin từ tất cả các khía cạnh. Trên thực tế, có thể hình dung bằng trực giác rằng nếu bạn tự thiết kế một mô hình như vậy, attention sẽ không chỉ được thực hiện một lần, kết quả tổng hợp của nhiều lần chú ý ít nhất có thể nâng cao mô hình và cũng có thể được so sánh với vai trò của việc sử dụng nhiều tích chập cùng lúc trong CNN, theo trực giác, sự chú ý của nhiều người đứng đầu giúp mạng nắm bắt được các tính năng/ thông tin phong phú hơn.Ưu điểm của Transformer so với RNN/LSTM là gì? Tại sao?  Các mô hình RNN không thể tính toán song song vì việc tính toán tại thời điểm T phụ thuộc vào kết quả tính toán của lớp ẩn tại thời điểm T - 1, còn việc tính toán tại thời điểm T - 1 lại phụ thuộc tính toán của lớp ẩn tại thời điểm T - 2.  Khả năng trích xuất đặc trưng của Transformer tốt hơn so với các mô hình RNN.Tại sao Transformer có thể thay thế seq2seq?Từ thay thế ở đây hơi không phù hợp, seq2seq tuy cũ nhưng vẫn có chỗ đứng, vấn đề lớn nhất của seq2seq là ở chỗ Nén thông tin ở phía Encoder thành một vector có độ dài cố định và sử dụng nó làm đầu vào của trạng thái đầu tiên ở phía Decoder, để dự đoán trạng thái ẩn của từ đầu tiên (mã thông báo) ở phía Decoder. Khi chuỗi đầu vào tương đối dài, điều này rõ ràng sẽ mất rất nhiều thông tin ở phía Encoder và vector cố định sẽ được gửi đến phía Decoder cùng một lúc, bên Decoder không thể chú ý đến thông tin mà nó muốn chú ý. Mô hinh transformer không chỉ cải thiện đáng kể hai khuyết điểm này của mô hình seq2seq (Mô-đun attention tương tác nhiều đầu), và cũng giới thiệu mô-đun self-attention, trước tiên hãy để trình tự nguồn và trình tự đích được “tự liên kết”, trong trường hợp này, thông tin chứa trong embedding của trình tự nguồn và trình tự đích sẽ phong phú hơn và lớp FFN tiếp theo cũng nâng cao khả năng biểu đạt của mô hình, và tính toán song song của Transfomer vượt xa các model seq2seq.Tham khảo[1] Attention is All You Need"
    } ,
  
    {
      "title"    : "[NLP] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "title-lower"    : "[nlp] bert: pre-training of deep bidirectional transformers for language understanding",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "NLP",
      "tags"     : "nlp, paper, model",
      "url"      : "/nlp/2023/10/05/bert-pretrained-model/",
      "date"     : "2023-10-05 00:00:00 +0700",
      "img-feature": "/assets/media/feature/bert.png",
      "content": "BERT: Pre-training of Deep Bidirectional Transformers for Language UnderstandingTiêu đềPre-training (Đào tạo trước): Nếu một mô hình được đào tạo trên một tập dữ liệu lớn nhưng mục đích chính là sử dụng cho nhiệm vụ khác (được gọi là Training), thì nhiệm vụ đào tạo mô hình đó được gọi là Pre-training.Deep: rất dễ hiểu, chỉ là sâu thôi.Bidirectional: nghĩa là có 2 chiều, được giải thích ở cuối bài viết.Transformers: Mô hình học sâu được thiết kế dùng để phục vụ giải quyết nhiều bài toán trong xử lý ngôn ngữ tự nhiên và tiếng nói. Vui lòng xem thêmTóm lại, mô hình BERT là một mô hình Transfomers sâu 2 chiều, được sử dụng làm mô hình đào tạo trước để hiểu ngôn ngữ.AbstractBERT viết tắt của Bidirectional Encoder Representations from Transformers.Như đã nói ở đoạn đầu, BERT dùng thiết kể để đào tạo sâu, biểu diễn hai chiều, dữ liệu không gán nhãn được sử dụng và thông tin ngữ cảnh song phương trái và phải được kết hợp (Tức context được xác định ở cả hai phía của từ). Do thiết kế tinh tế của BERT, nó chỉ cần thêm một lớp đầu ra bổ sung và thực hiện tinh chỉnh tương ứng, và nó có thể được áp dụng cho nhiểu tác vụ mà không cần thực hiên nhiều sửa đổi đối với các tác vụ cụ thể.IntroductionĐào tạo trước đã trở nên phổ biến trong NLP. Ví dụ, trong bài toán nhận dạng thực thể có tên (NER), BERT không phải là mô hình đầu tiên được đề xuất, xét cho cùng chúng ta có thể dùng BERT ứng dụng trong CV - Compution Vision, nhưng BERT ứng dụng tốt nhất trong các bài toán NLP.Khi sử dụng mô hình đào tạo trước để biểu diễn đặc trưng cho các tác vụ tiếp theo, thường có hai chiến lược, một chiến lược dựa trên các đặc trưng (feature-based) và chiến lược còn lại dựa trên tinh chỉnh (fine-tuning). Cả hai phương pháp đều sử dụng cùng một hàm mục tiêu trong quá trình đào tạo trước, đây là mô hình ngôn ngữ một chiều.Dựa trên tính năng, cách làm tiêu biểu [ELMo], sử dụng kiến trúc RRN, đối với mỗi tác vụ xuôi dòng, xây dựng mạng thần kinh liên quan đến tác vụ hiện tại, biểu diễn đặc trưng được đào tạo trước, như một tính năng bổ sung, đưa nó vào mạng cùng với đầu vào ban đầu.Dựa trên sự tinh chỉnh, cách làm tiêu biểu [GPT], giảm tham số cho một tác vụ cụ thể, khi đưa các tham số mô hình được huấn luyện trước vào dữ liệu xuôi dòng, tất cả các thông số sẽ được tinh chinh.Sau đó tác giả thảo luận về những hạn chế của các phương pháp này, đặc biêt với phương pháp tinh chỉnh, do mô hình ngôn ngữ là một chiều nên có một số hạn chế trong việc lựa chọn kiến trúc. Ví dụ: trong GPT sử dụng kiến trúc từ trái sang phải. Theo cách nói của con người, khi đọc một câu, chúng ta chỉ có thể đọc từ trái sang phải. Trong một số nhiệm vụ, chẳng hạn như đánh giá cảm xúc của một câu (QA), … việc đọc từ phải sang trái hay trái sang phải được hợp pháp. Tác giả tin rằng việc đưa thông tin từ cả hai hướng vào cùng một lúc sẽ giúp nâng cao hiệu quả thực hiện.(Tiếp tục viết trong tương lai xa…)"
    } ,
  
    {
      "title"    : " Bọ là gì? Defect, Fault, Error, Bug, Failure?",
      "title-lower"    : " bọ là gì? defect, fault, error, bug, failure?",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "SE",
      "tags"     : "Bug, Defect, Fault, Failure",
      "url"      : "/se/2023/07/02/what-is-bug/",
      "date"     : "2023-07-02 00:00:00 +0700",
      "img-feature": "/assets/media/feature/Software-bugs.jpg",
      "content": "Người đọc tự chịu trách nhiệm về tính xác thực của bài viết.ContextChuyện là tuần vừa rồi tôi tham gia lab nghiên cứu ở trường và được giao đọc một bài báo khoa học. Nếu không nhầm thì mục đích của thầy khi bảo tôi đọc bài báo này là nắm được sơ qua “context” nghiên cứu của nhóm đang thực hiện.Do lần đầu tôi được giao đọc một bài báo khoa học (à trước đó có đọc, dịch gì đấy một bài rồi nhưng mà khi chú tâm thực hiện), thì tất nhiên chưa có kinh nghiệm nên là chỉ nghĩ đọc hiểu nghĩa, cái chung chung bài báo đang nói là gì, hiểu cách bài báo đang thực hiện, vân vân mây mây… Và rồi, sau một tuần được giao đọc bài báo thì mình lên gặp thầy trao đổi về hiểu biết của mình về bài báo. À thì mọi việc sẽ chả có gì nếu như cách đọc của mình là đúng.Nhưng KHÔNG, mình đã được khai sáng một đống tri thức mới. Thầy bảo mình không thể hiểu chung chung bài báo nói gì được mà phải nắm rõ và chính xác toàn bộ khái niệm mà bài báo đã đề cập như bài báo mình “được” đọc là “Classifying Software Changes: Clean or Buggy?” thì đầu tiên phải đặt câu hỏi Software Changes là gì? Clean, Buggy là gì? (Tất nhiên là trong “context” của bài báo).Trong một đống thứ thầy nói và hỏi mình thì chắc thứ tồn đọng lại (khắc sâu mình nhất) là câu hỏi (cũng là câu hỏi đầu tiên) là: “Theo em, bug là gì?” (Vì tiêu đề bài báo có việc phân loại hai nhãn là Clean và Buggy mà). Lúc đấy, mình kiểu :))). Tại mình nghĩ là thầy sẽ vấn đề và hướng giải quyết của bài báo chứ không phải mấy câu hỏi lí thuyết như này. Và thầy doạ mình là không trả lời được sẽ hạ điểm (tất nhiên là đùa) môn mình kì trước (Do kì trước mình có tham gia lớp kiểm thử của thầy, không hiểu sao thầy vẫn còn nhớ mình :)).Và một đứa thường bỏ qua những thứ căn bản như mình thì tất nhiên chả bao giờ tìm hiểu định nghĩa nó là gì rồi và khi một từ thông dụng và được dùng rất nhiều trong cộng đồng lập trình như từ “bug” như thế thì mình trả lời đại khái là: “Bug là lỗi phần mềm. Nó xảy ra khi phần mềm thực hiện sai và không đúng mong đợi đã được đề ra ban đầu”. Và thầy nhìn mình, nhìn ánh mắt “trìu mến” mà thầy nhìn mình là mình biết chất lượng trả lời câu hỏi của mình như thế nào rồi. Xong thầy bảo, trong phát triển phần mềm, lỗi phần mềm không chỉ là bug, mà còn có defect, fault, error, failure. Lúc thầy nói mấy từ này mình chả nghe ra đâu (do trình nghe đọc tiếng anh mình hơi kém, thực ra là rất kém) đến lúc thầy viết ra mình và giải thích mình mới có thể hình dung ra những từ này. Và đấy là lí do mình viết bài viết này để “flex” (đùa chứ xem mình hiểu tới đâu và nhờ bạn đọc xác nhận lại giùm mình.).MainThực ra trên mạng có rất nhiều bài viết viết về vấn đề này rồi, bạn chỉ cần hỏi “ông Gu Gồ” là nó ra một đống cho bạn đọc nên là mình không đi sâu vào lắm mà chỉ sơ qua những gì mình hiểu được về nó và phân biệt những khái niệm đã nêu ở phần tiêu đề.        Defects, like quality, can be defined in many different ways but are more commonly defined as deviations from specifications or expectations which might lead to failures in operation. (Có thể dịch là: Defects, giống như Quality (Chất lượng phần mềm), có thể định nghĩa bằng nhiều cách khách nhau nhưng thường được định nghĩa là sai lệch so với thông số kỹ thuật hoặc mong đợi có thể dẫn đến failures khi vận hành.)A software failure is observable software misbehavior; however, a defect may not always lead to a failure. (Có thể dịch là: Failure là hành vi sai trái của phần mềm có thể quan sát được. Tuy nhiên, một defect không phải lúc nào cũng dẫn đến một failure.)Defects colloquially called bugs in software artifacts, typically in the software source code. (Có thể dịch là: Defects thường được gọi (một cách không chính thức) là bugs trong software artifacts (bất kỳ thứ gì tạo ra phần mềm), điển hình là mã nguồn.)ExitBài viết này khoảng một nửa là mình bịa, một nửa còn lại cũng bịa nốt."
    } ,
  
    {
      "title"    : "Lựa chọn đặc trưng trong học máy bằng kiểm tra Chi-Square",
      "title-lower"    : "lựa chọn đặc trưng trong học máy bằng kiểm tra chi-square",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "Machine-Learning",
      "tags"     : "Data Science, Statistics, Machine Learning, Feature Selection",
      "url"      : "/machine-learning/2023/06/27/chi-square-feature-selection-ml/",
      "date"     : "2023-06-27 00:00:00 +0700",
      "img-feature": "/assets/media/feature/Chi-Square.jpg",
      "content": "Lựa chọn đặc trưng là một trong những vấn đề quan trọng trong học máy, khi chúng ta có một đống cái đặc trưng và quyết định xem những đặc trưng nào là tốt nhất để xây dựng mô hình.Có nhiều phương pháp để lựa chọn đặc trưng, trong bài viết này tôi sẽ đưa giải pháp thực hiện bằng Chi-Square.Phân phối Chi-SquareMột biến ngẫu nhiên (chi) tuân theo phân phối chi-square nếu nó có thể viết được viết dưới dạng tổng bình phương các biến chuẩn chuẩn hoá.[chi^{2} = sum_{}^{}Z_{i}^{2}]Trong đó (Z_{1}, Z_{2}, ...) là các biến chuẩn chuẩn hoá.Bậc tự do (Degrees of freedom)Bậc tự do đề cập đến số lượng tối đa các giá trị độc lập logic, có quyền tự do thay đổi. Nói một cách đơn giản, nó có thể được định nghĩa là tổng số mẫu dữ liệu trừ đi số lượng ràng buộc độc lập áp đặt cho các mẫu dữ liệu.        Phân phối Chi-SquareTrong hình trên, chúng ta có thể thấy phân phối Chi-Square cho các bậc tự do khác nhau. Chúng ta cũng có thể quan sát thấy rằng khi bậc tự do tăng thì phân phối Chi-Square xấp xỉ với phân phối chuẩn.Kiểm tra tính độc lập của hai biến cố bằng Chi-SquareChi-Square được sử dụng trong thống kê để kiểm tra tính độc lập của hai sự kiện. Với dữ liệu của hai biến, chúng ta có thể nhận được số lượng thực tế quan sát (observed) (O) và số lượng kỳ vọng (expected) (​​E). Chi-Square đo lường mức độ chênh lệch của hai đại lượng này.[chi_{c}^{2} = sum_{}^{}frac{(O_{i} - E_{i})^{2}}{E_{i}}]Trong đó:  (c) : Số bậc tự do  (O) : Số lượng thực tế quan sát  (E) : Số lượng kỳ vọngKhi hai sự kiện độc lập, số lượng được quan sát gần với số lượng dự kiến, do đó chúng ta sẽ có giá trị Chi-Square nhỏ hơn. Vì vậy, giá trị Chi-Square cao cho thấy giả thuyết về tính độc lập là không chính xác. Nói một cách đơn giản, giá trị Chi-Square càng cao thì các sự kiện này càng phụ thuộc vào nhau. Hay nếu ta xem một sự kiện là một đặc trưng của mô hình và sự kiện còn lại là phân loại mà mô hình cần dự đoán (Phản hồi). Khi đó nếu giá trị Chi-Square càng cao thì đặc trưng này càng phụ thuộc vào phản hồi và nó có thể được chọn để đào tạo mô hình.Đối với lựa chọn đặc trưng bằng Chi-Square, chúng ta mong đợi rằng trong tổng số các đặc trưng được chọn có một phần nhỏ trong chúng vẫn độc lập với lớp phân loại. Tuy nhiên, trong phân loại văn bản hiếm khi các đặc trưng này được thêm vào trong tập đặc trưng trích xuất cuối cùng. Tất nhiên là nó vẫn tốt miễn là phương pháp vẫn xếp hàng các đặc trưng theo tính hữu ích của nó đối với mô hình chứ không phải chỉ sử dụng để đưa ra tuyên bố về sự phụ thuộc hay tính độc lập của các biến trong thống kê.Các bước thực hiện kiểm tra Chi-SquareHãy xem xét một tập dữ liệu mà chúng ta phải xác định lý do tại sao khách hàng rời khỏi ngân hàng, hãy thực hiện kiểm tra Chi-Square cho hai biến. Giới tính của khách hàng với các giá trị là Nam/Nữ và Rời khỏi mô tả liệu khách hàng có rời ngân hàng hay không với các giá trị Có/Không. Trong thử nghiệm này, chúng tôi sẽ kiểm tra xem có mối quan hệ nào giữa Giới tính và Rời khỏi.1. Xác định giả thuyếtGiả thuyết rỗng ((H_{0})): Hai biến đã cho độc lậpGiả thuyết thay thế ((H_{1})): Hai biến đã cho phụ thuộc nhau2. Xây dựng bảng tương quanMột bảng hiển thị phân phối của một biến trong hàng và biến khác trong cột. Nó được sử dụng để nghiên cứu mối quan hệ giữa hai biến.            Giới tính  Rời bỏ      Có      Không      Tổng              Nam      38      178      216              Nữ      44      140      184              Tổng      82      318      400      Bậc tự do của bảng tương quan được tính bằng công thức: ((r-1) * (c-1)) trong đó  (r), (c) là số hàng và số cột. Như bảng trên, ta có:[df = (2–1) * (2–1) = 1.]Trong bảng trên, chúng ta đã tìm ra tất cả các giá trị được quan sát và các bước tiếp theo của chúng tôi là tìm các giá trị kỳ vọng, tính giá trị Chi-Square và kiểm tra mối quan hệ giữa chúng.3. Tìm giá trị kỳ vọngDựa trên giả thiết rỗng là hai biến đã cho độc lập lẫn nhau. Nếu hai biến A, B là biến cố độc lập ta có:[P(A cap B) = P(A) * P(B)]Hãy tính giá trị kỳ vọng cho ô đầu tiên là những người là Nam và Có rời khỏi ngân hàng.[p = p(Yes) * p(Male)][p = (82/400) * (216/400)][p = 0.1107][E_{1} = n * p = 400 * 0.1107 = 44]Tương tự, ta tính toán được có giá trị (E_{2}),  (E_{3}), (E_{4}) và được kết quả như bên dưới.            Giới tính  Rời bỏ      Có      Không              Nam      44      172              Nữ      38      146      4. Tính toán giá trị Chi-Square[chi_{c}^{2} = sum_{}^{}frac{(O_{i} - E_{i})^{2}}{E_{i}}]Sử dụng công thức đã cho ở trên và các giá trị đã tính toán được, ta dễ dàng có giá trị của Chi-Square bằng 2.225. Bác bỏ Giả thuyết rỗngVới độ tin cậy (95%) là (alpha = 0,05), chúng ta sẽ kiểm tra xem giá trị Chi-Square tính được có nằm trong vùng chấp nhận hay từ chối hay không.Các giá trị Chi-Square chấp thuận có thể xác định bẳng Bảng Chi-Square. Bạn đọc có thể tham khảo tại https://people.richland.edu/james/lecture/m170/tbl-chi.html. Dưới đây là phần của bảng trên.            df      0.995      0.99      0.975      0.95      0.90      0.10      0.05      0.025      0.01      0.005                  1      —      —      0.001      0.004      0.016      2.706      3.841      5.024      6.635      7.879              2      0.010      0.020      0.051      0.103      0.211      4.605      5.991      7.378      9.210      10.597              3      0.072      0.115      0.216      0.352      0.584      6.251      7.815      9.348      11.345      12.838              4      0.207      0.297      0.484      0.711      1.064      7.779      9.488      11.143      13.277      14.860              5      0.412      0.554      0.831      1.145      1.610      9.236      11.070      12.833      15.086      16.750              6      0.676      0.872      1.237      1.635      2.204      10.645      12.592      14.449      16.812      18.548              7      0.989      1.239      1.690      2.167      2.833      12.017      14.067      16.013      18.475      20.278              8      1.344      1.646      2.180      2.733      3.490      13.362      15.507      17.535      20.090      21.955              9      1.735      2.088      2.700      3.325      4.168      14.684      16.919      19.023      21.666      23.589              10      2.156      2.558      3.247      3.940      4.865      15.987      18.307      20.483      23.209      25.188              11      2.603      3.053      3.816      4.575      5.578      17.275      19.675      21.920      24.725      26.757              12      3.074      3.571      4.404      5.226      6.304      18.549      21.026      23.337      26.217      28.300              13      3.565      4.107      5.009      5.892      7.042      19.812      22.362      24.736      27.688      29.819              14      4.075      4.660      5.629      6.571      7.790      21.064      23.685      26.119      29.141      31.319              15      4.601      5.229      6.262      7.261      8.547      22.307      24.996      27.488      30.578      32.801              16      5.142      5.812      6.908      7.962      9.312      23.542      26.296      28.845      32.000      34.267      Ta có bậc tự do (df) bằng 1 (được tính toán dựa vào bảng tương quan phía trên) và  (alpha = 0,05) thì giá trị Chi-Square chấp nhận là 3.84.Nhận thấy giá trị Chi-Square tính được thấp hơn giá trị Chi-Square chấp nhận thì ta chấp nhận giả thiết rỗng. Hay ta có thể kết luận được rằng hai biến cố đã cho độc lập nhau. Vậy nếu ta xem Giới tính là một đặc trưng cần xem xét của mô hình và Rời bỏ ngân hàng hay không là lớp giá trị mô hình cần phân loại, thì ta có thể kết luận, Giới tính không thể được sử dụng để huấn luyện mô hình vì hai biến cố này không có mối liên hệ lẫn nhau.Sử dụng Chi-Square để lựa chọn đặc trưng cho mô hình phân loại văn bảnMột phương pháp lựa chọn đặc trưng phổ biến được sử dụng với dữ liệu văn bản là lựa chọn đặc trưng với Chi-Square. (chi^{2}) như chúng ta thấy ở trên có thể được sử dụng trong thống kê để kiểm tra tính độc lập của hai biến cố. Cụ thể hơn, trong lựa chọn đặc trưng cho mô hình, chúng ta sử dụng nó để kiểm tra một thuật ngữ cụ thể và một lớp phân loại cụ thể có độc lập hay không.Cho một văn bản (D), chúng tôi ước tính số lượng sau cho mỗi thuật ngữ và xếp hạng chúng theo điểm số của chúng:[chi^2(D, t, c) = sum_{e_t in {0, 1}} sum_{e_c in {0, 1}}  frac{ (O_{e_te_c} - E_{e_te_c} )^2 }{ E_{e_te_c} }]Trong đó:  (O) là tần số quan sát và (E) tần số kỳ vọng  (e_{t}) nhận giá trị (1) nếu văn bản có chứa thuật ngữ (t), (0) với trường hợp ngược lại.  (e_{c}) nhận giá trị (1) nếu văn bản thuộc lớp phân loại (c), (0) với trường hợp ngược lại.Với mỗi đặc trưng (thuật ngữ), một điểm  (chi^{2}) tương ứng chỉ ra Giả thuyết rỗng (H_{0}) về tính độc lập của hai biến cố (có nghĩa là lớp của văn bản được phân loại không ảnh hưởng đến tần suất xuất hiện của thuật ngữ) nên bị bác bỏ hay sự xuất hiện của thuật ngữ và lớp của văn bản phụ thuộc lẫn nhau. Hay trong trường hợp này, chúng ta sẽ chọn thuật ngữ này làm đặc trưng cho mô hình phân loại văn bản.Kết luậnChi-Square nhạy cảm với kích thước mẫu. Các mối quan hệ có thể có ý nghĩa khi chúng không chỉ đơn giản là do một mẫu rất lớn được sử dụng. Ngoài ra, Chi-Square không thể xác định liệu một biến cố có mối quan hệ nhân quả với biến khác hay không. Nó chỉ có thể xác định liệu hai biến cố có liên quan với nhau hay không.. Nói chung, khi giá trị kỳ vọng ​​trong một ô của bảng tương quan nhỏ hơn 5, Chi-Square có thể dẫn đến sai sót trong kết luận. Hy vọng bài viết có thể giúp bạn có cái nhìn tổng quan về phương pháp này và có thể áp dụng nó cho mô hình của bạn."
    } ,
  
    {
      "title"    : "Từ nơ-ron sinh học đến nơ-ron nhân tạo",
      "title-lower"    : "từ nơ-ron sinh học đến nơ-ron nhân tạo",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "Deep-Learning",
      "tags"     : "Neuron, Deep Learning",
      "url"      : "/deep-learning/2023/05/13/tu-noron-sinh-hoc-den-noron-nhan-tao/",
      "date"     : "2023-05-13 00:00:00 +0700",
      "img-feature": "/assets/media/feature/no-ron-sinh-hoc.png",
      "content": "Con người lấy cảm hứng từ các loài chim để bay, loài sứa biển để điều trị ung thư, da cá mập để làm bề mặt vật liệu chống bám và còn rất nhiều phát minh khác lấy cảm hứng từ thiên nhiên.Vì thế, rất dễ hiểu khi ta xem xét cấu trúc bộ não sinh học để tìm cảm hứng cho việc xây dựng một bộ máy thông minh. Đây cũng chính là ý tưởng đằng sau của Mạng nơ-ron nhân tạo (artificial neural network - ANN).Tuy nhiên, dù máy bay lấy cảm hứng từ loài chim, chúng lại không cần phải vỗ cánh. Tương tự, ANN đã dần trở nên rất khác biệt so với phiên bản sinh học của nó. Một số nhà nghiên cứu còn cho rằng chúng ta nên ngừng sử dụng phép so sánh với sinh học (ví dụ như sử dụng từ “đơn vị” - “unit” - thay cho “nơ-ron”), vì lo rằng phép so sánh này sẽ giới hạn sự sáng tạo trong các hệ thống hợp lý về mặt sinh học.Nơ-ron Sinh họcTrước khi chúng ta bàn về nơ-ron nhân tạo, chúng ta cùng tìm hiểu qua nơ-ron sinh học. Nơ-ron sinh học là một tế bào với vẻ ngoài khác thường được tìm thấy trong não động vật. Nó bao gồm một thân tế bào chứa nhân và hầu hết các thành phần phức tạp khác, với các nhánh mở rộng được gọi là sợi nhánh, cùng với một phần mở rộng rất dài được gọi là sợi trục. Chiều dài của sợi trục lớn hơn thân tế bào từ vài lần cho đến hàng chục nghìn lần. Ở gần cuối, sợi trục tách thành nhiều nhành được gọi là telodendria, và tại đỉnh của những nhành này là các cấu trúc siêu nhỏ được gọi là điểm tiếp hợp synap (hoặc đơn giản là synap), được nối với các sợi nhánh hoặc thân tế bào của những nơ-ron khác. Các nơ-ron sinh học sinh ra các xung điện ngắn được gọi là điện thế hoạt động (hoặc đơn giản  là tín hiệu). Chúng di chuyển dọc theo sợi trục và kích thích synap giải phóng ra tín hiệu hoá học được gọi chất dẫn truyền thần kinh. Khi một nơ-ron nhận đủ một lượng chất dẫn truyền thần kinh này trong một vài mili giây, nó sẽ phát ra các xung điện của chính nó (thật ra, điều này còn phụ thuộc vào chất dẫn truyền thần kinh bởi có một số chất ức chế sự kích hoạt của nơ-ron).        Nơ-ron sinh họcDo đó, mặc dù các nơ-ron sinh học riêng lẻ dường như có cách hoạt động khá đơn giản, chúng lại được tổ chức trong một mạng lưới rộng lớn với hàng tỷ nơ-ron, và ở đố mỗi nơ-ron được kết nối với hàng nghìn nơ-ron khác. Các phép tính với độ phức tạp cao có thể được xử lý bởi một mạng nơ-ron khá đơn giản, tương tự như cách một tổ kiến phức tạp được tạo nên bởi nỗ lực tổng hợp từ những các thể kiến riêng lẻ. Kiến trúc mạng nơ-ron sinh học (biological neural network - BNN) vẫn đang là chủ đề được tích cực nghiên cứ, tuy nhiên một vài phần của não đã được khám phá, và có vẻ như các nơ-ron thường được sắp xếp thành các tầng liên tiếp, đặc biệt là ở vùng đại não (lớp ngoài cùng của bộ não), như có thể thấy ở hình bên dưới.        Các tầng trong mạng nơ-ron sinh học (Võ não người)Nơ-ron Nhân tạoMạng nơ-ron Nhân tạo là một phương thức, công cụ trong lĩnh vực trí tuệ nhân tạo, được lấy cảm hứng từ cấu trúc bộ não con người, để máy tính có thể xử lý dữ liệu một cách tự động. Đây là một loại Học máy(Machine Learning), còn được gọi là Học sâu (Deep Learning), sử dụng các nơ-ron kết nối với nhau trong một cấu trúc phân lớp tương tự như bộ não con người. Quá trình này cho phép máy tính học hỏi từ sai lầm và cải thiện liên tục, tạo ra một hệ thống thích ứng. Mạng nơ-ron nhân tạo được áp dụng để giải quyết các vấn đề phức tạp, chẳng hạn như tóm tắt tài liệu hoặc nhận diện khuôn mặt, với độ chính xác cao hơn.Bộ não sinh học chính là nguồn cảm hứng cho kiến trúc mạng nơ ron. Các tế bào não của con người, có được gọi là nơ-ron, tạo thành một mạng lưới phức tạp, có tính liên kết cao và gửi các tín hiệu điện đến nhau để giúp con người xử lý thông tin. Tương tự, một mạng nơ-ron nhân tạo được tạo ra từ các tế bào nơ-ron nhân tạo, cùng nhau phối hợp để giải quyết một vấn đề. Nơ-ron nhân tạo là các mô đun phần mềm, được gọi là nút và mạng nơ-ron nhân tạo là các chương trình phần mềm hoặc thuật toán mà về cơ bản, sử dụng hệ thống máy tính để giải quyết các phép toán.McCulloch và Pitts đề xuất một mô hình rất đơn giản để mô tả mạng nơ-ron sinh học, và mô hình này về sau được biết đến là nơ-ron nhân tạo: nó có một hoặc nhiều đầu vào nhị phân (bật/tắt) và một đầu ra nhị phân. Nơ-ron nhân tạo kích hoạt đầu vào của nó khi có nhiều hơn một lượng đầu vào nhất định được kích hoạt. Trong bài báo, họ đã chứng minh rằng ngay cả với một mô hình đơn giản như trên, ta vẫn có thể xây dựng một mạng chứa các nơ-ron nhân tạo với khả năng tính toán bất kỳ mệnh đề logic nào. Hình phía dưới là một vài ANN thực hiện các phép toán khác nhau, với giả định rằng một nơ-ron được kích hoạt khi ít nhất hai trong số các đầu vào của nó được kích hoạt.        ANN thực hiện các phép tính logic đơn giảnCác mạng nơ-ron nhân tạo được nghiên cứu và phát triển thay đổi liên tục trong nhiều năm, với nhiều kiến trúc mạng nơ-ron nhân tạo khác nhau. Ngày nay, một mạng nơ-ron nhân tạo bao gồm 3 lớp (layer):Lớp đầu vàoThông tin từ thế giới bên ngoài đi vào mạng nơ-ron nhân tạo thông qua lớp đầu vào. Các nút đầu vào xử lý dữ liệu, phân tích hoặc phân loại và sau đó chuyển dữ liệu sang lớp tiếp theo.Lớp ẩnDữ liệu đi vào lớp ẩn đến từ lớp đầu vào hoặc các lớp ẩn khác. Mạng nơ-ron nhân tạo có thể có một số lượng lớn lớp ẩn. Mỗi lớp ẩn phân tích dữ liệu đầu ra từ lớp trước, xử lý dữ liệu đó sâu hơn và rồi chuyển dữ liệu sang lớp tiếp theo.Lớp đầu raLớp đầu ra cho ra kết quả cuối cùng của tất cả dữ liệu được xử lý bởi mạng nơ-ron nhân tạo. Lớp này có thể có một hoặc nhiều nút. Ví dụ: giả sử chúng ta gặp phải một vấn đề phân loại nhị phân (có/không), lớp đầu ra sẽ có một nút đầu ra, nút này sẽ cho kết quả 1 hoặc 0. Tuy nhiên, nếu chúng ta gặp phải vấn đề phân loại nhiều lớp, lớp đầu ra sẽ có thể bao gồm nhiều hơn một nút đầu ra.Kiến trúc mạng nơ-ron chuyên sâuMạng nơ-ron chuyên sâu, hoặc mạng deep learning, có nhiều lớp ẩn với hàng triệu nơ-ron nhân tạo liên kết với nhau. Một con số, có tên gọi là trọng số, đại diện cho các kết nối giữa hai nút. Trọng số sẽ dương nếu một nút kích thích nút còn lại, hoặc âm nếu một nút ngăn cản nút còn lại. Các nút với trọng số cao hơn sẽ có ảnh hưởng lớn hơn lên các nút khác.Về mặt lý thuyết, mạng nơ-ron chuyên sâu có thể ánh xạ bất kỳ loại dữ liệu đầu vào với bất kỳ loại dữ liệu đầu ra nào. Tuy nhiên, chúng cũng cần được đào tạo hơn rất nhiều so với các phương pháp máy học khác. Chúng cần hàng triệu ví dụ về dữ liệu đào tạo thay vì hàng trăm hoặc hàng nghìn ví dụ mà một mạng đơn giản hơn thường cần.Phía dưới là một ví dụ cho kiến trúc mạng nơ-ron nhân tạo        Mạng nơ-ron nhân tạoTừ Nơ-ron Sinh học đến Nơ-ron Nhân tạoMột điều đáng nhiên là ANN đã tồn tại từ khá lâu: chúng được giới thiệu vào năm 1943 bởi nhà sinh lý học thần kinh Warren McCulloch và nhà toán học Walter Pitts. Trong bài báo mang tính bước ngoặt của họ “A Logical Calculus of Ideas Immanent in Nervous Activity”, McCulloch và Pitts đã trình bày một mô hình tính toán giản lược của cách mà các nơ-ron sinh học có thể làm việc cùng nhau trong não bộ động vật để thực hiện các phép tính phức tạp bằng logic mệnh đề (propositional logic). Đây chính là kiến trúc mạng nơ-ron nhân tạo đầu tiên. Kể từ đó, hàng loạt các kiến trúc khác đã được phát minh, xử lý tính toán linh hoạt và hoạt động hiệu quả hơn.Sự thành công sớm của ANN đã khiến nhiều người tin rằng họ sẽ sớm được nói chuyện với những cố máy thực sự thông minh. Vào thập niên 1960, khi rõ ràng là lời hứa này sẽ không được thực hiện (ít nhất là trong một khoảng thời gian dài), các nguồn tài trợ được chuyển sang lĩnh vực khác, và ANN bước vào một mùa đông dài. Vào thập niên 1980, các kiến trúc mới được phát minh và các kỹ thuật huấn luyện tốt hơn được phát triển, giúp cho thuyết kết nối (connectionism - ngành nghiên cứu về mạng nơ-ron) bắt đầu được quan tâm trở lại. Tuy nhiên, tiến độ trong ngành này khá chậm, vào vào thập niên 1990, các kỹ thuật Học Máy mạnh mẽ khác đã được phát minh, ví dụ Máy Vector Hỗ trợ,… Có vẻ những kỹ thuật này đem lại kết quả tốt hơn và nền tảng lý thuyết vững chắc hơn so với ANN, nên lần nữa việc nghiên cứu ANN lại bị trì hoãn.Giờ đây, khi lượng dữ liệu lớn bùng nổ và sự phát triển vượt bậc về năng lực tính toán từ thập niên 1990, chúng ta lại đang chứng kiến thêm một làn sống quan tâm khác tới ANN. Liệu xu hướng này sẽ lại lụi tàn như trước?"
    } ,
  
    {
      "title"    : "Kiểm thử bằng phương pháp phân tích giá trị biên",
      "title-lower"    : "kiểm thử bằng phương pháp phân tích giá trị biên",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "Testing",
      "tags"     : "testing",
      "url"      : "/testing/2023/05/13/kiem-thu-gia-tri-bien/",
      "date"     : "2023-05-13 00:00:00 +0700",
      "img-feature": "/assets/media/feature/kiem-thu-gia-tri-bien.jpg",
      "content": "Trong quá trình phát triển phần mềm, kiểm thử là một bước không thể thiếu để đảm bảo chất lượng và độ tin cậy của sản phẩm.Trong số các phương pháp kiểm thử, kiểm thử phân tích giá trị biên (Boundary Value Analysis) đã được đánh giá cao vì tính hiệu quả và độ chính xác của nó. Phương pháp này giúp tập trung kiểm thử vào các giá trị biên của dữ liệu đầu vào, từ đó giảm thiểu thời gian và chi phí kiểm thử.Bài viết này sẽ cách sinh test cho ca kiểm thử phân tích giá trị biên thông qua một bài toán kiểm thử nhỏ.Bài toánDummyTel có cấu trúc tỷ lệ sau đây cho các cuộc gọi đường dài:  Bất kỳ cuộc gọi nào bắt đầu lúc hoặc sau 18:00 nhưng trước 08:00 được giảm 50%.  Bất kỳ cuộc gọi nào bắt đầu lúc hoặc sau 08:00 nhưng trước 18:00 được tính giá đầy đủ.  Bất kỳ cuộc gọi nào dài hơn 60 phút đều được giảm giá 15% trên chi phí (sau khi trừ đi bất kỳ khoản giảm giá nào khác).Chương trình đọc thời điểm bắt đầu cuộc gọi dựa trên đồng hồ 24 giờ và thời lượng của cuộc gọi. Thời gian cuộc gọi tối đa là 180 phút.Chương trả về:  -1 nếu đầu vào không hợp lệ.  0  nếu không được giảm giá.  1  nếu được giảm 15%.  2  nếu được giảm 50%.  3  nếu vừa được giảm 50% và 15%.Chương trình sẽ giả sử chỉ các giá trị số nguyên được nhập vào, thời lượng không âm và thời gian bắt đầu biểu thị thời gian đồng hồ thực.Phân tích yêu cầuĐầu vào của chương trình: Thời điểm bắt đầu, Thời lượng của cuộc gọi. Đầu ra của chường trình: Chi phí của cuộc gọi Điều kiện hợp lệ của đầu vào:  Thời điểm bắt đầu: Có giá trị nguyên trong khoảng từ 0 đến 23.  Thời lượng cuộc gọi: Từ 0 đến 180.Giá trị đầu ra: 0 (nếu không được giảm giá), 1 (nếu được giảm 15%), 2 (nếu được giảm 50%), 3 (nếu vừa được giảm 50% và 15%).Phân vùng tương đươngTa chia thành các giá trị đầu vào thành các phân vùng tương đương sau:Gọi TĐBB là Thời điểm bắt đầu cuộc gọi, TLCG là Thời lượng cuộc gọi.            TH      Inputs      Output                  1      TĐBB ∉{0,…,23} hoặc TGCG ∉{0,…,180}      -1              2      Hợp lệ và (8 &amp;lt;= TĐBB &amp;lt; 18 và TGCG &amp;lt;= 60)      0              3      Hợp lệ và (8 &amp;lt;= TĐBB &amp;lt; 18 và TGCG &amp;gt; 60)      1              4      Hợp lệ và (TGCG &amp;lt;= 60 và (TĐBB &amp;gt;= 18 hoặc TĐBB &amp;lt; 8))      2              5      Các TH còn lại      3      Từ bảng trên ta sinh 5 test cho 5 phần vùng tương đương lần lượt là:            Testcase      Inputs      EO                  1      TĐBB = -2 và TGCG = 191      -1              2      TĐBB = 12 và TGCG = 45      0              3      TĐBB = 14 và TGCG = 92      1              4      TĐBB = 20 và TGCG = 30      2              5      TĐBB = 21 và TGCG = 124      3      Xác định biênBiên của TĐBB:  Giá trị biên của TĐBB lần lượt là 0, 8, 18, 23  Giá trị nom của TĐBB là 12 (Điểm giữa của miền hợp lệ)Biên của TGCG:  Giá trị biên của TGCG lần lượt là 0, 60, 180  Giá trị nom của TGCG là 90 (Điểm giữa của miền hợp lệ)Sinh test cho kiểm thử biên đơn giảnMỗi giá trị biên của một input kết hợp với các giá trị nom của các input còn lại và một test bao gồm tất cả các giá trị nom của các input.Hay chúng ta có tổng cộng: 4 + 3 + 1 = 8 (Testcases)            Testcase      Inputs      EO                  1      TĐBB = 0 và TGCG = 90      3              2      TĐBB = 8 và TGCG = 90      1              3      TĐBB = 18 và TGCG = 90      3              4      TĐBB = 23 và TGCG = 90      3              5      TĐBB = 12 và TGCG = 0      0              6      TĐBB = 12 và TGCG = 60      0              7      TĐBB = 12 và TGCG = 180      1              8      TĐBB = 12 và TGCG = 90      1      Biên và cận biên trong miền hợp lệCác test case tương tự như biên đơn giản và thêm các test case cận biên bằng cách kết hợp giá trị cận biên của một input với các giá trị nom của các input còn lại.Lấy các giá trị cận biên cách giá trị biên một khoảng là 1.TĐBB có 4 giá trị biên -&amp;gt; 6 giá trị cận biên trong miền hợp lệ.TGCG có 3 giá trị biên -&amp;gt; 4 giá trị cận biên trong miền hợp lệ.Vậy số test cases tất cả là 8 + 6 + 4 = 18 (Testcase)            Testcase      Inputs      EO                  1      TĐBB = 0 và TGCG = 90      3              2      TĐBB = 8 và TGCG = 90      1              3      TĐBB = 18 và TGCG = 90      3              4      TĐBB = 23 và TGCG = 90      3              5      TĐBB = 12 và TGCG = 0      0              6      TĐBB = 12 và TGCG = 60      0              7      TĐBB = 12 và TGCG = 180      1              8      TĐBB = 12 và TGCG = 90      1              9      TĐBB = 1 và TGCG = 90      3              10      TĐBB = 7 và TGCG = 90      3              11      TĐBB = 9 và TGCG = 90      1              12      TĐBB = 17 và TGCG = 90      1              13      TĐBB = 19 và TGCG = 90      3              14      TĐBB = 22 và TGCG = 90      3              15      TĐBB = 12 và TGCG = 1      0              16      TĐBB = 12 và TGCG = 59      0              17      TĐBB = 12 và TGCG = 61      1              18      TĐBB = 12 và TGCG = 179      1      Biên và cận biên trong toàn bộ miền giá trị.Các test case tương tự như biên và cận biên trong miền hợp lệ và thêm các test case cận biên ngoài miền hợp lệ bằng cách kết hợp giá trị cận biên ngoài miền hợp lệ của một input với các giá trị nom của các input còn lại.Lấy các giá trị cận biên cách giá trị biên một khoảng là 1.Nhận thấy:  TĐBB có 2 giá trị cận biên ngoài miền hợp lệ.  TGCG có 2 giá trị cận biên ngoài miền hợp lệ.Vậy số test cases tất cả là 18 + 2 + 2 = 22 (Testcase)            Testcase      Inputs      EO                  1      TĐBB = 0 và TGCG = 90      3              2      TĐBB = 8 và TGCG = 90      1              3      TĐBB = 18 và TGCG = 90      3              4      TĐBB = 23 và TGCG = 90      3              5      TĐBB = 12 và TGCG = 0      0              6      TĐBB = 12 và TGCG = 60      0              7      TĐBB = 12 và TGCG = 180      1              8      TĐBB = 12 và TGCG = 90      1              9      TĐBB = 1 và TGCG = 90      3              10      TĐBB = 7 và TGCG = 90      3              11      TĐBB = 9 và TGCG = 90      1              12      TĐBB = 17 và TGCG = 90      1              13      TĐBB = 19 và TGCG = 90      3              14      TĐBB = 22 và TGCG = 90      3              15      TĐBB = 12 và TGCG = 1      0              16      TĐBB = 12 và TGCG = 59      0              17      TĐBB = 12 và TGCG = 61      1              18      TĐBB = 12 và TGCG = 179      1              19      TĐBB = 12 và TGCG = -1      -1              20      TĐBB = 12 và TGCG = 181      -1              21      TĐBB = -1 và TGCG = 90      -1              22      TĐBB = 24 và TGCG = 90      -1      Kết luậnNhận thấy toàn bộ test case trong kiểm thử giá trị biên trên đều không cho output nằm trong trường hợp số 2. Vì vậy, kiểm thử giá trị biên sẽ không thể bao hàm toàn bộ trường hợp và thường kết hợp với các loại kiểm thử khác như phân hoạch tương đương hoặc kiểm thử bằng quyết định,.. Thường trong thực tế, các công ty thường sinh test kiểu này: Kết hợp phân hoạch tương đương (hoặc bảng quyết định) với phân tích giá trị biên thường cho kết quả tốt vì nó có chi phí, thời gian, công sức vừa phải và bao hàm hầu hết mọi trường hợp của giá trị đầu vào."
    } ,
  
    {
      "title"    : "Điểm mạnh/yếu công cụ kiểm thử chịu tải tự động k6 với các đối thủ",
      "title-lower"    : "điểm mạnh/yếu công cụ kiểm thử chịu tải tự động k6 với các đối thủ",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "Testing",
      "tags"     : "k6, jmeter, testing",
      "url"      : "/testing/2023/05/01/k6-vs-jmeter/",
      "date"     : "2023-05-01 00:00:00 +0700",
      "img-feature": "/assets/media/feature/k6.png",
      "content": "Các công cụ kiểm thử tải (Load Testing Tool - LTT) đã trở nên rất phổ biến hiện nay, cả miễn phí và có phí, nguồn mở và nguồn đóng, và mỗi công cụ đều có điểm mạnh và yếu của riêng mình.Một số LTT được nhiều nhà phát triển sử dụng, có thể kể đến công cụ miễn phí như JMeter, Locus, fortio,… hay có tính phí như LoadNinja, Gatling,…  Và Grafana k6 (hay k6) là một trong số ấy.Được phát triển bới Grafana Labs, k6 là một LTT mã nguồn mở giúp kiểm tra hiệu suất dễ dàng và hiệu quả cho các nhà phát triển. Nó là công cụ mã nguồn mở, hướng đến nhà phát triển và dễ dàng mở rộng. Dù chỉ mới ra đời gần đây, bản release chính thức đầu tiên trên github vào ngày 27/02/2017, nhưng k6 đã nhanh chóng nổi lên trong cộng đồng nhà phát triển bởi hiệu suất và tính dễ sử dụng đáng bất ngờ của nó.  Tính đến thời điểm hiện tại (04/2023), k6 có 20.1k stars, 311 watching và 1.1k forks trên github. Nhờ cộng đồng phát triển hoạt động tích cực, k6 đang phát triển ngày càng lớn mạnh. Kho extensions phong phú, pull request và những bản releases thường xuyên là những lợi ích mà mã nguồn mở của k6 mang lại.Phần so sánh với các công cụ dưới đây không khẳng định công cụ nào là tốt hơn bởi vì không có điều kiện cụ thể nào để khẳng định công cụ nào là tốt nhất. Mọi thứ đều phụ thuộc vào vấn đề, tình huống mà nhóm phát triển đang gặp phải trả lời bởi các câu hỏi: cái gì (what), như thế nào (how), tại sao (why), khi nào (when) ca kiểm thử được thực hiện. Phần so sánh dưới đây của chúng tôi muốn trả lời ở đây là: “Mỗi công cụ vượt trội trong những tình huống nào?”.Do hạn chế của bài viết nên tôi lựa chọn công cụ kiểm thử tự động đặc trưng nhất là Jmeter - công cụ kiểm thử ra đời sớm, được sử dụng rộng rãi. Mặc dù vậy, bằng việc so sánh với công cụ JMeter cũng để khát quát toàn bộ những tính năng nổi bật ở k6 và một số hạn chế còn gặp phải của nó.JMeter[10] là một công cụ kiểm tra tải mã nguồn mở được xây dựng hoàn toàn bằng Java bởi Apache Foundation[11]. Nó được phát hành lần đầu tiên vào năm 1998 và nó đã tạo nên làn sóng vì sự táo bạo của nó trong việc sử dụng các công cụ kiểm tra chịu tải độc quyền nhưng biến nó thành miễn phí và trở nên phổ biến trong cộng đồng hơn. JMeter đã dùng thứ mà người dùng cần trả rất nhiều tiền để có thể sử dụng và phát hành nó công khai và miễn phí cho mọi người sử dụng. Mặc dù tập lệnh (scripts) cũng có thể được mở rộng bằng cách viết mã nhưng phần lớn tập lệnh trong JMeter được thực hiện bằng giao diện người dùng (GUI - Graphical User Interface). Tính đến thời điểm hiện tại (27/04/2023), phiên bản mới nhất của JMeter là 5.4.1. Khi nào Jmeter nổi bật hơn?1.1. Jmeter có giao diện người dùng (GUI - Graphical User Interface)Nếu bạn ở trong tình huống mà mọi người chưa từng thực hiện kiểm tra chịu tải trước đó và cần tìm hiểu một công cụ mới, thì một công cụ điều khiển bằng GUI như JMeter đơn giản là lựa chọn dễ dàng nhất. Tuy nhiên, màn hình kế hoạch kiểm tra (Test Plan) chào đón bạn khi bạn khởi động JMeter lần đầu tiên không cung cấp bất kỳ hướng dẫn nào về cách tạo trình lấy mẫu HTTP. UI là chủ quan ở một mức độ nhất định. Tuy nhiên, chúng tôi cho rằng việc khám phá giao diện người dùng dễ dàng hơn đối với những người không phải là nhà phát triển hơn là một chút sử dụng mã lệnh như k6.k6 không có GUI được đóng gói trong công cụ, nhưng Trình tạo thử nghiệm k6(k6 Test Builder) có sẵn miễn phí. Đó là một cách để tạo các bài kiểm tra với giao diện GUI và mặc dù được đưa vào đám mây k6 nhưng nó không yêu cầu bất kỳ đăng ký nào để sử dụng. Tuy nhiên, nó không có đầy đủ tính năng như JMeter.1.2. JMeter hỗ trợ nhiều giao thức và tính năng vượt trộiJMeter là công cụ kiểm thử tự động hỗ trợ nhiều giao thức nổi bật có thể kể đến như Web - HTTP, HTTPS (Java, NodeJS, PHP, ASP.NET, …), SOAP / REST Webservices, FTP, Database thông qua JDBC, Mail - SMTP(S), POP3(S) and IMAP(S), TCP, Java Objects, …JMeter cũng có hầu hết các tính năng mà bạn sẽ cần cho một bài kiểm tra tải cơ bản và bạn không phải tự mình viết mã cho bất kỳ tính năng nào. Cấu trúc phần tử cha-con của nó có nghĩa là bạn có thể sửa đổi một phần tử cụ thể, chẳng hạn như yêu cầu HTTP hoặc sửa đổi tất cả các yêu cầu HTTP một cách dễ dàng như nhau. Thêm thời gian suy nghĩ cho tất cả các yêu cầu cũng dễ dàng như thêm Đồng hồ bấm giờ ngẫu nhiên thống nhất vào nhóm luồng của bạn và tất cả các yêu cầu trong nhóm đó sẽ kế thừa nó. Với các công cụ kiểm thử chịu tải dựa trên mã lệnh như k6, có thể khó tìm ra những gì có thể thực hiện được nếu không có giao diện người dùng.1.3. JMeter có cộng đồng người dùng kinh nghiệm với nhiều tài liệuJMeter đã xuất hiện từ rất lâu và điều đó giúp nó có được một số điểm mạnh so với các cộng cụ mới ra đời như k6. JMeter đã xuất hiện từ năm 1998, vì vậy tính đến thời điểm này, nó đã có 22 năm để cải thiện và xây dựng cộng đồng người sử dụng. JMeter hiện diện trên gần như mọi trang mạng cộng đồng và cho dù trường hợp sử dụng JMeter của bạn cụ thể đến đâu, thì rất có thể nó đã được thực hiện trước đó. Tìm kiếm “cách tải bài kiểm tra X bằng JMeter” chắc chắn sẽ mang lại hàng nghìn lượt truy cập và một số video chỉ cho bạn chính xác cách thực hiện.JMeter’s Component Reference[12]  là bằng chứng về tài liệu mở rộng và toàn diện của JMeter. Mọi phần tử, chức năng và thuộc tính đều được thảo luận chi tiết hơn hầu hết mọi người có thể mong muốn và đó chỉ là tài liệu chính thức trên trang web của Apache. Có hàng nghìn cuốn sách, hướng dẫn và khóa học về JMeter của những người dùng đam mê nó.1.4. JMeter có thể thực hiện các kiểm thử chịu tải phân tán với chi phí hợp lýMột trong những tính năng tuyệt vời nhất của JMeter là nó cung cấp cho bạn một khung để chạy kiểm thử chịu tải phân tán với nó. Điều này khá đặc biệt đối với một công cụ mã nguồn mở và miễn phí.Kiểm thử phân tán có nghĩa là tăng lượng tải bạn đang tạo bằng các kiểm thử chịu tải của mình, thường bằng cách tăng số lượng VU và chạy nhiều phiên bản tập lệnh của bạn trên các trình tạo chịu tải khác. JMeter thực hiện điều này bằng cách chỉ định một nút điều khiển và cho phép bạn thiết lập các nút worker. Mỗi nút worker cần có một bản sao của jmeter-server, một tiện ích đi kèm với mọi cài đặt JMeter (trong jmeter/bin).k6 hỗ trợ chế độ kiểm thử chịu tải phân tán thông qua toán tử Kubernetes: Toán tử k6 cho phép bạn tạo đối tượng tài nguyên tùy chỉnh k6 trong cụm Kubernetes. Tuy nhiên, kiểm thử phân tán thông qua toán tử Kubernetes yêu cầu một mạng ổn định và tốc độ cao để đảm bảo rằng các nút kiểm thử có thể giao tiếp với nhau một cách hiệu quả. Nếu mạng không ổn định hoặc tốc độ mạng chậm, kiểm thử phân tán có thể gặp vấn đề về trễ hoặc thất bại.2. Khi nào k6 nổi bật hơn?2.1. k6 có thể bắt đầu sử dụng nhanh chóngBản thân JMeter khá dễ cài đặt, nhưng trước khi cài đặt JMeter, bạn cần cài đặt Java. Đặc biệt nếu bạn đang sử dụng Windows, thì người dùng JMeter mới sẽ gặp phải các vấn đề khi thêm các biến môi trường(environment variables) cần thiết để Java hoạt động. Cũng có thể gây nhầm lẫn khi xác định phiên bản Java nào là phiên bản phù hợp. Trong khi đó k6, có thể cài đặt dễ dàng thông qua một một câu lệnh trên terminal hay một gói cài đặt có sẵn.Đối với JMeter, nơi mọi thứ đều là plugin… kể cả Trình quản lý plugin (Plugin Manager)! Hầu hết người dùng JMeter sẽ tranh luận rằng có một bộ plugin tiêu chuẩn mà bạn nên tải xuống trước khi bắt đầu sử dụng nó. Trong khi đó, tất cả các chức năng này đều có sẵn trong k6 ngay từ đầu.2.2. k6 có thể tối đa hiệu suất và hiệu quả của ca kiểm thửk6 được viết bằng Go và Go được xây dựng có tính hiệu suất. Go là một ngôn ngữ được biên dịch và không cần phải thông dịch, không giống như Java hay Python. Không có lớp phức tạp nào được thêm vào.Cách đơn giản và phổ biến nhất để công cụ kiểm thử chịu tải tạo VU là chỉ định một VU cho một nhân hoặc luồng (thread) hệ điều hành. Tuy nhiên, mô hình 1 luồng (thread): 1 VU có một lỗ hổng nghiêm trọng: khi VU đang chờ phản hồi hoặc thực hiện hàm sleep(), luồng cũng bị chặn và không thể xử lý công việc khác.Trong k6, mỗi VU được chạy trên một goroutine chứ không phải một luồng. Điều đó tạo nên sự khác biệt gì? Goroutines có thể được điều khiển bởi Go Scheduler, hoạt động giống như một cảnh sát giao thông. Nó sử dụng lại các luồng nhàn rỗi và phân công công việc một cách thông minh, bằng cách cho phép “đánh cắp công việc” và chuyển giao công việc giữa các luồng. Điều này nghe có quen không? Đây cũng là nguyên tắc mà các bộ cân bằng tải được xây dựng dựa trên: Một màn hình bên ngoài giám sát luồng công việc giúp cải thiện hiệu suất chung. Bản thân Go về bản chất đã cân bằng tải theo cách mà nhiều ngôn ngữ lập trình không có, điều này làm cho nó trở thành nền tảng hoàn hảo cho một công cụ kiểm thử chịu tải.Việc có thể tận dụng khả năng tối ưu hóa hiệu suất vốn có của Go cũng đồng nghĩa với việc sử dụng bộ nhớ ít hơn đáng kể. Một luồng chạy k6 không vượt quá 100 kb, trong khi một luồng JVM như JMeter sử dụng, chẳng hạn, sử dụng mặc định là 1MB. Đó là hơn 1000% so với k6! Tất nhiên, Java cho phép người dùng điều chỉnh mức sử dụng bộ nhớ của ứng dụng, do đó, sự khác biệt thường không quá rõ ràng, nhưng vẫn thú vị khi lưu ý rằng Go có xuất phát điểm thấp hơn nhiều.2.3. Lợi ích về hiệu suất trong thực tế2.3.1. k6 cần ít load generator hơnMột load generator là một hệ thống mà chạy nhiều VU theo thứ tự để tạo một load trên hệ thống. Hiệu suất tương đối tốt hơn của k6 nằm ở chỗ nó cần ít load generator hơn để thực hiện một lượng tải nhất định. Kết quả chạy thực tế của hai công cụ kiểm thử k6 và JMeter có sự khác biệt đáng kể. JMeter cần tới 760MB bộ nhớ, trong khi đó, con số này là 256MB bộ nhớ ở k6.Dung lượng bộ nhớ thấp hơn của k6 là lý do nó có thể chạy nhiều VU hơn và tạo ra nhiều tải hơn mức trung bình. Cho dù bạn đang sử dụng load generator tại chỗ hay trên đám mây, bạn sẽ trả ít chi phí cung cấp hơn khi sử dụng k6. Tiết kiệm chi phí này làm cho k6 trở thành một công cụ tuyệt vời cho các nhóm có ngân sách hạn hẹp.2.3.2. k6 xử lý lỗi tràn bộ nhớ (Out of memory errors)k6 cũng là lựa chọn tốt khi bạn đang thiếu thời gian để thực hiện ca kiểm thử. Sử dụng JMeter có nghĩa là làm quen với cách điều chỉnh hiệu suất Java và cách khắc phục các sự cố hiệu suất Java phổ biến nhất, bởi vì có một số vấn đề. Cái mà gặp phải nhiều nhất khi sử dụng JMeter là chính là lỗi out of memory errors (Tràn bộ nhớ). Vấn đề này bạn sẽ không bao giờ gặp phải khi sử dụng k6.2.3.3. Không có GUI có nghĩa là không cần thêm chi phí tài nguyên trong quá trình kiểm thử chịu tảiGUI thường bổ sung thêm chi phí đáng kể cho một ứng dụng, đó là một trong những lý do tại sao k6 không có. Khi bạn đang chạy kiểm tra tải, cách tốt nhất vẫn là chạy nó từ dòng lệnh, vì nếu không, nó sẽ ảnh hưởng đến kết quả của bạn. Các công cụ kiểm thử chịu tải thực hiện trên dòng lệnh có hiệu suất ngay từ đầu.JMeter có rất nhiều cảnh báo về ảnh hưởng của GUI đối với hiệu suất. Đây là một từ “tài liệu JMeter”: Don’t run load test using GUI mode ! (Không chạy kiểm thử chịu tải sử dụng chế độ GUI) và đây là thông báo xuất hiện khi chạy JMeter.Không có GUI nghĩa là có ít vấn đề hơn. Bất kỳ tập lệnh kiểm thử chịu tải nào bạn tạo trong k6 đều sẵn sàng để thực thi vào thời gian hợp lý nhất bất cứ khi nào bạn sẵn sàng.2.4. k6 có thể thực hiện kiểm thử hướng mục tiêu (goal-oriented testing)Câu hỏi quan trọng nhất mà người kiểm thử chịu tải có thể đặt ra khi bắt đầu một dự án kiểm thử chịu tải mới là “Tại sao”? Các kế hoạch kiểm tra nên được thiết lập để giải quyết trực tiếp các lý do của nhóm muốn thực hiện kiểm tra chịu tải và điều đó phải được phản ánh trong các yêu cầu phi chức năng. Các yêu cầu phi chức năng sẽ đưa ra một số điều khiển về các giới hạn của hiệu suất có thể chấp nhận được. Một ví dụ phổ biến cho các giới hạn hoặc ngưỡng này là thời gian phản hồi trung bình dưới 3 giây cho tất cả các giao dịch trong quá trình thử nghiệm. k6 thực hiện điều này một cách tự nhiên với các ngưỡng cục bộ được đưa vào tập lệnh và bạn cũng có thể tạo chỉ số của riêng mình để sử dụng trong một ngưỡng. JMeter vốn không hỗ trợ các ngưỡng ở cấp độ thử nghiệm. Chúng ta phải sử dụng một số công cụ bổ sung để thực hiện công việc này như Timers, Duration Assertion, Performance Plugin,..Vấn đề là mặc dù các tùy chọn này có thể thiết lập ngưỡng trong JMeter, nhưng chúng vẫn là giải pháp thay thế không đi kèm với JMeter hoặc không giải quyết thỏa đáng việc tạo các loại ngưỡng khác nhau (lỗi, thời gian phản hồi, thông lượng, CPU, bộ nhớ). Cuối cùng, mọi người thường làm là xuất dữ liệu thô từ JMeter và tự mình thực hiện phân tích bằng một công cụ khác.Ngoài ra, k6 còn có một số tính năng nổi bật khác như dễ dàng hợp tác giữa người phát triển và người kiểm thử. Đây là ý tưởng ban đầu xây dựng nên công cụ kiểm thử này đã được chúng tôi phân tích trong phần ý tưởng nên tôi không phân tích rõ ở đây nữa. K6 sử dụng các tập lệnh của bạn là mã thuần túy giúp giảm bớt sự mơ hồ ở chỗ bạn không bị giới hạn bởi thiết kế giao diện người dùng kém hoặc lỗi trong các phần bổ trợ của bên thứ ba.Tóm lại, qua một phép so sánh cơ bản với công cụ kiểm thử lâu đời như JMeter, chúng tôi rút ra một số trường hợp mà k6 thực hiện tốt và một số hạn chế của nó.Cụ thể, k6 phù hợp cho:  Việc hợp tác giữa các thành viên trong bộ phận phát triển phần mềm giúp cho ca kiểm thử chất lượng và bao hàm được nhiều thành phần hơn khi tất cả các thành viên cùng xây dựng bối cảnh kiểm thử.  Những người đang tìm kiếm một công cụ kiểm thử chịu tải nhẹ, đơn giản mà vẫn đầy đủ các tính năngCác nhóm đang tìm cách tích hợp thử nghiệm vào quy trình phát triển hiện có và quy trình CI/CD (Continuous Integration và Continuous Delivery/Deployment - quy trình kiểu mới, kết hợp tự động hoá giúp đẩy nhanh tiến độ phát triển sản phẩm và đưa sản phẩm đến người dùng cuối cùng)  Đây là một công cụ mã nguồn mở, miễn phí vì vậy giúp cho đội ngũ phát triển của bạn không cần bận tâm nhiều đến các vấn đề pháp lý của phần mềm và việc mã nguồn mở nên k6 được cộng đồng người dùng đóng góp sửa đổi thường xuyên, giúp phần mềm ngày càng phát triển hoàn thiện.Và hạn chế trong một số trường hợp kể đến như:  Không có phân tích kết quả chi tiết. Người dùng cần tích hợp kết quả với cơ sở dữ liệu và phần mềm trực quan hoá dữ liệu.  Không phù hợp với các nhóm kiểm thử truyền thống khi mà các nhóm này thường sử dụng các phần mềm kiểm thử có GUI trong khi k6 lại không hỗ trợ vấn đề này.  K6 là một công cụ mới được phát hiện nên cộng đồng chưa được rộng lớn, phát triển như các công cụ kiểm thử lâu đời và không hỗ trợ chuyển giao với công cụ thương mại khác như LoadRunner hay NeoLoad.Các công cụ kiểm thử chịu tải bằng dòng lệnh không phải là yếu tố quan trọng nhất để cân nhắc thành công của kiểm tra tải. Biết lý do tại sao bạn đang kiểm thử, các yêu cầu là gì, hiểu và truyền đạt kết quả đều quan trọng hơn. Công cụ phù hợp sẽ cho phép bạn giải quyết những lo ngại đó trong khi cung cấp càng ít xung đột càng tốt. Không có công cụ “tốt nhất” rõ ràng; chỉ có công cụ phù hợp cho dự án và bối cảnh của bạn.Tài liệu liên quan  [1] Phạm Ngọc Hùng, Trương Anh Hoàng, Đặng Văn Hưng. Giáo trình kiểm thử phần mềm, 2014.  [2] k6 Documentation https://k6.io/docs/  [3] Comparing k6 and JMeter for load testing https://k6.io/blog/k6-vs-jmeter/  [4] Jmeter https://jmeter.apache.org/  [5] Apace Foundation https://www.apache.org/  [6] JMeter’s Component Reference https://jmeter.apache.org/usermanual/component_reference.html"
    } ,
  
    {
      "title"    : "Bài toán sinh test cho kỹ thuật kiểm thử theo cặp - Pairwise Testing (All-Pairs Testing)",
      "title-lower"    : "bài toán sinh test cho kỹ thuật kiểm thử theo cặp - pairwise testing (all-pairs testing)",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "Testing",
      "tags"     : "pairwise, all-pairs, testing",
      "url"      : "/testing/2023/03/25/two-pairs-testing/",
      "date"     : "2023-03-25 00:00:00 +0700",
      "img-feature": "/assets/media/feature/testing.png",
      "content": "Trong bài viết này, chúng ta sẽ tìm hiểu về một kỹ thuật kiểm thử tổ hợp (Combinatorial Testing) được gọi là Kiểm thử theo cặp(Pairwise Testing hay All-Pairs Testing).Định nghĩa: Thế nào là All-Pairs Testing?Theo ISTQB, All-Pairs Testing (hay Pairwise Testing) là một kỹ thuật kiểm thử hộp đen trong đó các test cases được thiết kế để thực hiện tất cả các tổ hợp có thể có của từng cặp tham số đầu vào. Tức là với mỗi cặp input đầu vào, tất cả các giá trị của cặp input đấy được phủ toàn bộ (Một test case có thể phủ được nhiều cặp input khác nhau).Kỹ thuật All-Pairs rất hữu ích để thiết kế các bài kiểm tra cho các ứng dụng liên quan đến nhiều tham số. Các thử nghiệm được thiết kế sao cho đối với mỗi cặp tham số đầu vào của một hệ thống, có tất cả các tổ hợp riêng biệt có thể có của các tham số đó. Do bộ thử nghiệm bao gồm tất cả các tổ hợp nên nó không toàn diện nhưng rất hiệu quả trong việc tìm lỗi.Kiểm thử All-Pairs được áp dụng phổ biến trong công nghiệp khi mà một số vấn đề chỉ được xảy ra bởi sự tương tác giữa các tham số đầu vào hoặc components. Kiểm thử All-Pairs có thể tìm được đến 50 - 90% lỗi của phần mềm, hệ thống.Số test cases cần sinh cho All-Pairs TestingTa có công thức tính số lượng test cases cần sinh như sau:Số lượng test case = Số lượng miền giá trị lớn nhất của các biến * Số lượng miền giá trị lớn nhất của các biếnChứng minh tính đúng đắn của công thức:Cách sinh test cho All-Pairs TestingChúng ta sẽ lấy ví dụ cho Ứng dụng giao dịch xe với các yêu cầu sau:  Ứng dụng giao dịch xe cho phép Mua và Bán xe.  Nó sẽ hỗ trợ giao dịch ở Delhi và Mumbai.  Ứng dụng phải có số đăng ký có thể hợp lệ hoặc không hợp lệ.  Nó sẽ cho phép giao dịch với các hãng xe: BMW, Audi và Mercedes.  Có thể thực hiện hai loại booking: E-booking và In-store.  Chỉ có thể đặt xe trong giờ giao dịch.Chúng ta sẽ thực hiện việc sinh test cho ca kiểm thử All-Pairs lần lượt theo các bước sau:Bước 1: Liệt kê các giá trị của các tham số đầu vào.Chúng ta có thể dễ dàng liêt kê các giá trị có thể có của các tham số đầu vào của ứng dụng như sau:  Loại giao dịch: Mua, Bán.  Vị trí: Delhi, Mumbai.  Hãng xe: BMW, Audi, Mercedes.  Số đăng ký xe: Valid (5000 giá trị), Invalid  Cách thức giao dịch: E-Booking, In-store  Thời gian giao dịch: Thời gian trong giờ làm việc, Thời gian ngoài giờ làm việcNếu chúng ta sinh test cases cho toàn bộ các tổ hợp hợp lệ thì sẽ có đến:  2 . 2 . 3 . 5000 . 2 . 2 = 24000 test cases tổ hợp hợp lệ.Chưa kể chúng ta còn chưa tính đến các test cases không hợp lệ trong quá trình sinh test.Bước 2: Đơn giản hóa việc sinh test cases (Simplify)Chúng ta sẽ đơn giản việc sinh các test cases theo các cách:  Sử dụng một cách lẫy mẫu thông minh  Sử dụng các nhóm hay ranh giới, ngay cả khi dữ liệu không rời rạc.Theo đó chúng ta có thể giảm số đăng ký xuống còn hai loại: Valid và Invaild.Bây giờ, số test cases chúng ta sẽ phải sinh sẽ còn lại:  2 . 2 . 3 . 2 . 2 . 2  = 96 test cases.Woa Woa Woa! Chúng ta đã giảm số lượng các test case cần phải sinh một số rất lớn rồi đúng không? Nhưng đây vẫn chưa phải các sinh hợp lí để cho số lượng test cases nhỏ nhất có thể. Tiếp tục nào!Bước 3: Sắp xếp các biến theo miền giá trịChúng ta tiến hành sắp xếp các biến theo thứ tự giảm dần số lượng miền giá trị: Tức biến có nhiều miền giá trị nhất sẽ được xếp đầu tiên  và biến có ít miền giá trị nhất được xếp cuối cùng. Sau khi sắp xếp, chúng ta sẽ có một bảng trông như thế này đây.            Hãng xe      Loại giao dịch      Vị trí      Số đăng ký xe      Cách thức giao dịch      Thời gian giao dịch                                                                                                                                                                Bước 4: Sắp xếp các miền giá trị của các biến để tạo bộ kiểm thửChúng ta sẽ lần lượt điền giá trị của bảng trống đã tạo phía trên theo từng cột một.            Hãng xe      Loại giao dịch      Vị trí      Số đăng ký xe      Cách thức giao dịch      Thời gian giao dịch                  BMW      Mua      Delhi      Valid      E-booking      Trong giờ              Audi      Bán      Mumbai      Invalid      In-store      Ngoài giờ              Mercedes                                         "
    } ,
  
    {
      "title"    : "Một số mô hình phát triển phần mềm (Phần 1)",
      "title-lower"    : "một số mô hình phát triển phần mềm (phần 1)",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "SE",
      "tags"     : "software, model",
      "url"      : "/se/2023/02/27/software-models-chapter-1/",
      "date"     : "2023-02-27 00:00:00 +0700",
      "img-feature": "/assets/media/feature/Software-Development-Life-Cycle.png",
      "content": "Mô hình phát triển phần mềm là thể hiện trừu tượng của các tiến trình phát triển phần mềm. Nó xác định các pha/ giai đoạn trong phát triển phần mềm.Trong các dự án phát triển phần mềm, mô hình đóng vai trò rất quan trọng. Mô hình đóng vai trò là hướng đi và quyết định đến chất lượng đầu ra của sản phẩm.Có nhiều loại mô hình phát triển phần mềm khác nhau như:  Mô hình thác nước  Mô hình xoắn ốc  Mô hình tăng trưởng  Mô hình Scrum…Trong bài viết này, tôi sẽ mô tả và phân tích chi tiết bốn loại mô hình phát triển phần mềm cơ bản nhất bao gồm: Mô hình thác nước (Waterfall model), Mô hình chữ V (V-Shaped Model), Bản mẫu và Mô hình xoắn ốc.1. Mô hình thác nướcMô hình thác nước được xem là mô hình đầu tiên được giới thiệu. Đây là mô hình SDLC (Software Development Life Cycle) lâu đời với đơn giản nhất. Mô hình thác nước là mô hình điển hình cho phát triển phần mềm đảm bảo bảo tốt.        Mô hình thác nướca. Đặc điểmTrong mô hình thác nước, toàn bộ quá trình phát triển phần mềm được chia thành các giai đoạn riêng biệt. Trong mô hình thác nước, thông thường, kết quả của một pha/ giai đoạn đóng vai trò là đầu vào cho pha/ giai đoạn tiếp theo.Đặc điểm quan trọng nhất của mô hình thác nước là phát triển tuần tự tuyến tính (Vì vậy, nó còn có tên gọi khác là linear - sequential life cycle model). Tức trong mô hình thác nước, giai đoạn tiếp theo chỉ được bắt đầu sau khi các mục tiêu đã được xác định của giai đoạn trước được hoàn thành. Trong mô hình này, các giai đoạn phát triển một cách độc lập mà không xếp chồng lẫn nhau.Tuy nhiên, trong thực tế việc thực hiện tốt một pha không phải dễ và việc xảy ra vấn đề ở là điều hiển nhiên. Vậy nếu trong quá trình phát triển gặp vấn đề có liên quan đến giai đoạn đã hoàn thành trước đó thì phải giải quyết như nào? Câu trả lời là chúng ta vẫn có thể quay lại giai đoạn trước đó sau khi đã thực hiện xong giai đoạn đấy. Tuy nhiên, sau khi quay lại, chúng ta vẫn phải tuân theo tính tuần tự của model.Các giai đoạn tuần tự trong mô hình thác nước  Thu thập và phân tích yêu cầu: Tất cả mọi yêu cầu có thể của hệ thống được xác định trong giai đoạn này và được ghi lại đầy đủ trong tài liệu đặc tả yêu cầu.  Thiết kế: Các thông số kỹ thuật trong giai đoạn đầu tiên được nghiên cứu trong giai đoạn này. Thiết kế giúp ta xác định những yêu cầu về phần cứng hệ thống, giúp ta xác định được kiến thức tổng thể của hệ thống.  Triển khai và kiểm thử đơn vị: Với số liệu đầu vào từ giai đoạn thiết kế, chúng ta phát triển các chương trình nhỏ gọi là Unit, sẽ được tích hợp trong giai đoạn tiếp theo. Mỗi đơn vị được triển khai và kiểm thử chức năng của nó được gọi là Unit Testing.  Tích hợp và kiểm thử hệ thống: Tất cả các đơn vị được thực hiện trong giai đoạn trước được tích hợp vào một hệ thống xác định. Sau khi tích hợp, toàn bộ hệ thống sẽ được kiểm tra chức năng và phi chức năng.  Vận hành và bảo trì:  Sản phẩm được triển khai trong môi trường của khách hàng hoặc được tung ra thị trường. Có thể có một số lỗi xảy ra trong môi trường của khách hàng, bảo trì được thực hiện để khắc phục những vấn đề trong môi trường khách hàng. Hoặc khi cần nâng cấp sản phẩm, thêm tính năng mới, bảo trì sẽ được sẽ được thực hiện.b. Ưu, nhược điểmMô hình thác nước được thực hiện tuần tự tuyến tính, do vậy ưu điểm lớn nhất của nó là đơn giản, dễ dàng để học và thực hiện. Mô hình đảm bảo chất lượng cao cho sản phẩm.Mỗi pha của mô hình được thực hiện khi pha trước đấy đã được hoàn thiện. Vì vậy, cần làm mỗi pha phải tốt, chất lượng, khi đó mới thực hiện pha tiếp theo do nếu xảy ra lỗi việc quay lại pha trước đáy sẽ mất rất nhiều thời gian.Do đó, công việc thực thiện của người phát triển nhiều hơn. Mỗi giai đoạn không chỉ thực thi mà còn viết docs và giảng giải cho những người giai đoạn tiếp theo. Dẫn đến người phát triển cần bỏ ra nhiều thời gian hơn làm cho sản phẩm thực hiện theo mô hình này thường thực hiện lâu, chi phí cao.Đây là nhược điểm rõ ràng nhất của mô hình này. Bù lại, sản phẩm sẽ đảm bảo chất lượng cao do mỗi pha được thực hiện một cách hoàn chỉnh, đầy đủ, chính xác.Chính vì vậy, mô hình thác nước chỉ phù hợp với các dự án vừa và nhỏ do những dự án này có thể xác định rõ yêu cầu từ đầu. Ngược lại, đối với những dự án lớn, việc xác định yêu cầu rõ ràng từ ban đầu là rất khó. Ngoài ra, việc làm tuần tự với dự án lớn là rất tốn thời gian khi mà khách hàng luôn mong muốn có sản phẩm chất lượng càng sớm càng tốt.Mô hình thác nước là mô hình đầu tiên, mọi mô hình cơ bản hiện nay đều xuất phát, phát triển từ mô hình thác nước.2. Mô hình chữ VChất lượng kiểm thử phần mềm được đánh giá qua bộ test kiểm thử và quá trình thực hiện kiểm thử. Do vậy, chất lượng của bộ test kiểm thử là rất quan trọng. Tuy nhiên, mô hình thác nước đến giai đoạn kiểm thử mới được sinh test. Việc sinh test của mô hình thác nước khiến cho khả năng phát hiện ra lỗi của bộ test rất là thấp, dẫn đến việc kiểm thử, đánh giá chất lượng phần mềm không khách quan, chính xác. Và mô hình chữ V đã được cải tiến từ thác nước để giải quyết vấn đề sinh test muộn từ mô hình thấy nước.        Mô hình chữ Va. Đặc điểmCũng giống như mô hình thác nước, các giai đoạn trong mô hình chữ V được thực hiện một cách tuần tự theo hình chữ V. Tuy nhiên, cải tiến của mô hình chữ V đến từ việc sinh bộ test kiểm thử sớm bằng cách tích hợp liên kết giai đoạn kiểm thử cho từng giai đoạn phát triển tương ứng. Có nghĩa là, đối với mỗi giai đoạn trong chu kỳ phát triển sẽ có giai đoạn kiểm thử tương ứng. Mỗi giai đoạn bên trái model sẽ sinh bộ test cho giai đoạn kiểm thử bên phải của model:  Giai đoạn phân tích đặc tả yêu cầu sinh bộ test cho giai đoạn kiểm thử hệ thống, giai đoạn kiểm thử chấp nhận  Giai đoạn thiết kế sinh bộ test cho giai đoạn kiểm thử tích hợp.  Quá trình implementing thực hiện luôn giai đoạn kiểm thử unit.b. Ưu, nhược điểmDo V Model kế thừa hầu hết từ Waterfall Model nên mọi ưu, nhược điểm đa số đều giống Waterfall Model. Tuy nhiên, ưu điểm nổi bật nhất so với Waterfall Model là giai đoạn kiểm thử được thực hiện ngay từ đầu qua công việc sinh bộ test sớm cho giai đoạn kiểm thử tương ứng nên bộ test trong V Model chính xác hơn. Nhờ vậy, việc kiểm thử được thực hiện nhanh chóng, chính xác và đánh giá phần mềm một cách khách quan nhất.3. Bản mẫuĐặc điểm của mô hình thác nước là cần xác định rõ yêu cầu từ đầu. Nhưng trong thực tế rất ít dự án xác định được rõ yêu cầu từ đầu. Vậy cần phải làm sao? Bản mẫu chính là giải pháp giải quyết vấn đề này.a. Đặc điểmBản mẫu là mô hình phát triển phần mềm được phát triển dựa trên các yêu cầu của hệ thống. Dựa vào bản mẫu, khách hàng có cái nhìn tổng quan về hệ thống thực tế.Bản mẫu cho phép hiểu các yêu cầu của khách hàng ở giai đoạn phát triển ban đầu ngay cả những yêu cầu khó xác định. Nhờ nhận được những phản hồi có giá trị từ khách hàng, từ đó giúp các nhà thiết kế và phát triển phần mềm hiểu chính xác những gì được mong đợi từ sản phẩm đang được phát triển.Chúng ta cần dồn chi phí và nguồn lực nhiều cho làm bản mẫu, dẫn tới các công đoạn còn lại sẽ thiếu thời gian và chi phí, … Kết quả là chất lượng sản phẩm nhất là tài liệu và chất lượng code dễ có vấn đề. Ngoài ra, việc chú trọng đến bản mẫu (thường cho yêu cầu chức năng) dẫn đến dễ bỏ qua các yêu cầu phi chức năng và đa số các dự án không đạt các yêu cầu phi chức năng. Chính vì vậy, thực tế nó không được dùng phổ biến như một mô hình phát triển phần mềm. Tuy nhiên, tư tưởng của bản mẫu rất quan trọng. Nó là mấu chốt để chúng ta lôi kéo khách hàng, giải quyết những yêu cầu không được rõ ràng. Do đó, người ta thường dùng bản mẫu như là một phương pháp thu thập yêu cầu cho các mô hình khác. Bây giờ, người ta dùng bản mẫu như là một kỹ thuật thu thập yêu cầu.b. Ưu, nhược điểmƯu điểm lớn nhất của bản mẫu giúp ta giải quyết việc xác định các yêu cầu khó của mô hình thác nước. Nhờ bản mẫu, việc xác định yêu cầu được diễn ra thuận chính xác nhờ đó việc thực hiện phần mềm dựa trên mô hình thác nước được diễn ra một cách thuận lợi. Bù lại, chúng ta cần chi phí cao khi sử dụng bản mẫu do cần nhiều nguồn lực cho việc làm bản mẫu. Ngoài ra, sự tham gia của khách hàng vào bản mẫu là rất quan trọng.Tuy nhiên trong thực tế, việc nhiệt tình tham gia của khách hàng là khó, dẫn tới xây dựng bản mẫu khó chính xác. Từ đó, yêu cầu xác định không được rõ ràng.Mặc dù vậy, chúng ta vẫn có cách làm được nhưng không phải là điều dễ dàng.4. Xoắn ốcMô hình thác nước, chữ V chỉ phù hợp các dự án vừa và nhỏ, những dự án được xác định rõ yêu cầu từ đầu. Việc xác định những yêu cầu khó, phức tạp đã được giải quyết nhờ bản mẫu. Tuy nhiên, trong thực tế, đa số có dự án đều lớn, phức tạp. Vậy với các dự án lớn thì giải quyết như nào? Mô hình xoắn ốc là một lựa chọn mô hình để thực hiện các dự án lớn, phức tạp.        Mô hình xoắn ốca. Đặc điểmMô hình xoắn ốc là mô hình phát triển phần mềm kết hợp ý tưởng phát triển lặp đi lặp lại với các giai đoạn có hệ thống, được kiểm soát của mô hình thác nước.Mô hình xoắn ốc này là sự kết hợp giữa mô hình quy trình phát triển lặp và mô hình phát triển tuyến tính tuần tự, tức là mô hình thác nước với sự nhấn mạnh rất cao vào phân tích rủi ro. Nó cho phép phát hành sản phẩm qua mỗi lần lặp xung quanh hình xoắn ốc.Thực chất, mô hình xoắn ốc được kết hợp từ mô hình thác nước sử dụng bản mẫu để giải quyết những yêu cầu khó. Ngoài ra nó còn có quá trình phân tích rủi ro của dự án.Mô hình xoắn ốc là quy trình phát triển định hướng rủi ro cho các dự án phần mềm, nghĩa là trọng tâm dự án quản lý rủi ro thông qua nhiều lần lặp lại quy trình phát triển phần mềm.Mặc dù, các quá trình được lặp đi lặp lại nhưng mô hình vẫn theo tư tưởng phát triển tăng dần.Các giai đoạn trong phát triển phần mềm theo mô hình xoắn ốc  Planning: Lập kế hoạch, trong đó phạm vi của dự án được xác định. Một kế hoạch được tạo ra cho lần lần lặp tiếp theo của mô hình xoắn ốc.  Risk Analysis: Trong giai đoạn này, các rủi ro liên quan đến dự án được xác định và đánh giá.  Engineering: Trong giai đoạn này, phần mềm được phát triển dựa trên lần thu thập yêu cầu trước đó.  Evaluation: Phần mềm được đánh giá để xác định xem nó có đáp ứng các yêu cầu của khách hàng hay không và liệu nó có chất lượng cao hay không?  Planning: Vòng lặp tiếp theo của vòng xoắn ốc bắt đầu bằng một giai đoạn lập kế hoạch mới, dựa trên kết quả đánh giá.Trong thực tế, chúng ta không thể bê bản mẫu hay mô hình thác nước vào dự án lớn do đối với những dự án càng lớn, tỉ lệ thất bại càng cao. Vậy chúng ta thực hiện nó như thế nào? Chúng ta có hai chiến lược để thực hiện quá trình phát triển:  Quá trình ImplementingTheo thống kê tính năng khách hàng sử dụng, nhận thấy có 20% tính năng bắt buộc phải có của phần mềm (core), 40 % tính năng thường xuyên được sử dụng và 40% tính năng hiếm khi sử dụng.Chúng ta có thể thực hiện quá trình implementing một cách tuần tự, tức là thực hiện xong 20% tính năng bắt buộc, sau khi quá trình kiểm thử được diễn ra xong thành công, mới tiếp tục thực hiện 40% tính năng thường xuyên sử dụng. Tiếp tục với 40% tính năng hiếm khi sử dụng. Nhờ vậy, giúp chúng ta giảm thiểu khi thực hiện. Đây gọi là chống rủi ro.  Phân tích rủi roNhận thấy, khi chúng ta muốn xây một căn nhà cao 5 tầng, chúng ta có thể xây 3 tầng đầu tiên. Sau một thời gian, chúng ta có thể xây 2 tầng còn lại. Tuy nhiên, cái móng để xây nhà phải làm chắc có thể trụ được 5 tầng, không phải chỉ cho 3 tầng của tòa nhà được. Chính vì vậy, khi chúng ta thực hiện 20% tính năng core của phần mềm thì base không chỉ đủ 20% core đấy mà phải làm base cho cả hệ thống. Nhờ vậy, giảm thiểu rủi ro cho hệ thống.Chúng ta, cần phải phát hiện rủi ro có thể xảy ra với dự án. Từ đó, xây dựng phương án giảm thiểu thiệt hại.Tuy nhiên, mô hình xoắn ốc lại không được dùng trong thực tế do tính khả thi của phân tích rủi ro. Để phân tích được rủi ro, chúng ta cần những người có kinh nghiệm lớn, trải qua nhiều số người như này rất hiếm.Tuy nhiên, mô hình xoắn lại có giá trị cao về học thuật.b. Ưu, nhược điểmƯu điểm của mô hình xoắn ốc là nó cho phép các yếu tố, tính năng của sản phẩm được thêm vào ngay cả khi chúng đã được thực thi. Điều này đảm bảo rằng không có xung đột với các yêu cầu và thiết kế trước đó của phần mềm.Mô hình xoắn ốc giải quyết được các hạn chế của mô hình thác nước. Các yêu cầu trong mô hình xoắn ốc có thể được thay đổi. Nhờ đó, các yêu cầu được xác định rõ ràng, chính xác hơn. Việc phát triển phần theo mô hình xoắn ốc giúp cho khách hàng có thể thấy toàn bộ hệ thống sớm hơn. Quá trình phát triển có thể được chia các phần nhỏ hơn và các phần rủi ro có thể được phát triển sớm hơn giúp quản lý rủi ro tốt hơn.Tuy nhiên, việc quản lý, quy trình phát triển mô hình xoắn ốc sẽ phức tạp. Từ đó, mô hình xoắn ốc không phù hợp với các mô hình vừa và nhỏ hoặc rủi ro thấp. Ngoài ra, số lượng lớn các giai đoạn đòi hỏi cần một số lượng lớn tài liệu.Kết luậnMô hình đóng vai trò là hướng đi và quyết định đến chất lượng đầu ra của sản phẩm. Vì vậy, việc xác định đúng và chính xác mô hình cho phần mềm là rất quan trọng. Mỗi mô hình quy trình tuân theo một loạt các bước duy nhất đối với loại của nó để đảm bảo thành công trong quy trình phát triển phần mềm. Tùy vào cấu trúc phần mềm mà từ đó chọn đúng mô hình phần mềm để thực hiện. Trong thực tế, chúng ta không nhất thiết phải sử dụng đúng các mô hình phần mềm trên mà có thể “biến tấu”, thay đổi để phù hợp với dự án phần mềm."
    } ,
  
    {
      "title"    : "Một bài giới thiệu về cái blog nho nhỏ này",
      "title-lower"    : "một bài giới thiệu về cái blog nho nhỏ này",
      "sub-titile" : "",
      "sub-titile-lower" : "",
      "categories" : "Dummy",
      "tags"     : "doc, talk, zhao",
      "url"      : "/dummy/2023/02/22/about-this-blog/",
      "date"     : "2023-02-22 00:00:00 +0700",
      "img-feature": "/assets/media/feature/about-this-blog.jpg",
      "content": "Chào!Hmm, đầu tiên phải giới thiệu đôi chút về bản thân nhỉ? À chắc không cần, vì mấy cái câu giới thiệu bản thân tớ viết đi viết lại ở hầu hết mọi trang của blog rồi… LOL.Lần đầu tiên viết bài, không biết viết như nào :)). Chắc tớ sẽ nói vì sao tớ lại tạo cái blog nào và cách tớ thực hiện nó.Tại sao tớ lại xây dựng cái blog này?À chắc cái blog này được tạo bởi vì các ý nghĩ vớ vẩn của tớ tại một thời điểm nào đấy.Tớ tạo blog này với mục đích ban đầu là tạo ra một chỗ lưu trữ những bài viết của tớ, nó có thể là các bài viết học thuật hay là những bài viết vớ vẩn chia sẻ trải nghiệm của bản thân tớ. Nhưng mục đích cuối cùng tớ muốn hướng tới là cải thiện khả năng viếtlách của bản thân và tìm một niềm vui khác khi rảnh.Cách tớ thực hiện cái blog này…Ban đầu, tớ định dùng Django để xây dựng blog nhưng nghĩ lại là dùng Django thì host kiểu gì vì tớ không có tiền để duy trì hosting. Tớ cũng đã nghĩ đến các hosting free nhưng mà nó khá là ba chấm và deloy Django rất rườm rà. Và rồi, tớ nghĩ sao tớ không dùng chính Github Pages để host nhỉ? Cuối cùng, tớ đã quyết định dùng nó để host và sử dụng jekyll để xây dựng blog. Và rồi, tớ đã bắt tay vào làm nó…Về giao diện của blog, tớ lấy cảm hứng từ Reaganhenke và Digital Ocean.Tớ biết đến Reaganhenke nhờ vào một hôm tìm cái trang web nghe nhạc lofi để học. Sau khi tìm hiểu, tớ có biết đến I Miss My Cafe. Đây là một trang đối với tớ khá là hay, recommend cậu trang này nhé!(à cậu có thể vào để tìm hiểu về nó nhé :))). Tính tớ hay tò mò nên tớ đã lục lọi để tìm ra source của nó để clone lại một trang giống như vậy :)). Kết quả là tớ chỉ tìm được page của người làm ra nó. Và rồi, tớ bị thu hút bởi thiết kế của page, nhất là mấy cái card đầu của page. Haha, và rồi tớ lấy nó để làm giao diện. (Reagan Henke, if you see this blog, please forgive me for using it without your permission!).Còn Digital Ocean thì một lần tớ tìm tutorial và tìm ra nó. Đây cũng một trang chất lượng, recommend cậu trang này nữa nhé! (À thực ra ai cũng biết đến trang này :))).Ngoài ra tớ còn sử dụng particles.js để làm mấy cái lines nối nhau trông rườm rà ở background và Hyvor để làm phần comment (Tớ chỉ được dùng thử 15 ngày nên không biết 15 ngày sau nó có bị mất không :))).Mục đích hướng đến của blog…Blog này tớ dự định sẽ là chia sẻ những bài viết, chủ đề mà tớ tìm hiểu và nghiên cứu. Hiện tại, tớ đang theo Lab CNPM nên đa số bài viết sẽ liên quan đến chủ đề này. Nếu cậu cũng đang tìm hiểu về chủ đề này thì có thể đọc blog của tớ nhé để giúp tớ cản thiện bài viết của bản thân. Ngoài ra, tớ cũng đang tìm hiểu về AI/ML nữa. Cũng có thể sẽ là những bài viết chia sẻ những trải nghiệm của bản thân. Nhưng mà tớ rất là lười viết nên có thể rất lâu tớ mới viết một bài mới _D:.Cậu cũng có thể gửi bài tới blog nhé. Rất là khuyến khích ủng hộ luôn.Mong muốn của tớ…Tớ tạo blog vì ý nghĩ nhất thời và mục đích cá nhân là nhiều nên tớ cũng không mong blog sẽ được biết đến rộng rãi. À được nhiều người biết thì cũng không sao. Mong rằng với những người biết đến blog của tớ sẽ nhận được điều gì đó mới mẻ khi đọc những bài viết vớ vẩn của tớ. Vậy thôi…Cậu có thể xem source code của blog tớ tại Github.Cảm ơn cậu đã ghé thăm blog của tớ và đọc cái post mở đầu xàm này. Nếu có gì góp ý cho blog thì cậu comment phía dưới nhé, tớ sẽ sớm khắc phục. (À comment sớm nhé chứ phần comment chỉ được dùng thử 15 ngày :)). See yaaaaaaaaaaaaaaaaaaaaaaaaaaaa, Zhao"
    } 
    
]