<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://zhaospei.github.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://zhaospei.github.io//" rel="alternate" type="text/html" /><updated>2024-06-12T20:11:46+07:00</updated><id>https://zhaospei.github.io//feed.xml</id><title type="html">Tuan-Dung Bui</title><subtitle>A markdown blog made by Tuan-Dung Bui aka Zhao (zhaospei). Hosted on zhaospei.github.io. I'll write something i like maybe my study or life.</subtitle><author><name>Tuan-Dung Bui</name></author><entry><title type="html">Sử dụng SVG như một Placeholder</title><link href="https://zhaospei.github.io//op/2024/03/21/how-to-use-svg-to-show-images/" rel="alternate" type="text/html" title="Sử dụng SVG như một Placeholder" /><published>2024-03-21T00:00:00+07:00</published><updated>2024-03-21T00:00:00+07:00</updated><id>https://zhaospei.github.io//op/2024/03/21/how-to-use-svg-to-show-images</id><content type="html" xml:base="https://zhaospei.github.io//op/2024/03/21/how-to-use-svg-to-show-images/"><![CDATA[<p>Trong post này chúng ta sẽ nói về:</p>
<ul>
  <li>Tổng quan về các loại placeholder</li>
  <li>SVG-based placeholders (edges, shapes and silhouettes)</li>
  <li>Auto các process</li>
</ul>]]></content><author><name>zhao</name></author><category term="OP" /><category term="js" /><summary type="html"><![CDATA[Trong post này chúng ta sẽ nói về: Tổng quan về các loại placeholder SVG-based placeholders (edges, shapes and silhouettes) Auto các process]]></summary></entry><entry><title type="html">Phép thuật tuyệt vời của việc đếm tần số Word2Vec, Glove, Fasttext</title><link href="https://zhaospei.github.io//nlp/2023/10/20/word2vec/" rel="alternate" type="text/html" title="Phép thuật tuyệt vời của việc đếm tần số Word2Vec, Glove, Fasttext" /><published>2023-10-20T00:00:00+07:00</published><updated>2023-10-20T00:00:00+07:00</updated><id>https://zhaospei.github.io//nlp/2023/10/20/word2vec</id><content type="html" xml:base="https://zhaospei.github.io//nlp/2023/10/20/word2vec/"><![CDATA[<p>Hello, xin chào các bạn lại là mình đây. Trong bài đăng này, chúng ta sẽ tìm hiểu về Word2Vec, Glove và Fast</p>]]></content><author><name>zhao</name></author><category term="NLP" /><category term="nlp" /><category term="embedding" /><summary type="html"><![CDATA[Hello, xin chào các bạn lại là mình đây. Trong bài đăng này, chúng ta sẽ tìm hiểu về Word2Vec, Glove và Fast]]></summary></entry><entry><title type="html">Attention is All You Need</title><link href="https://zhaospei.github.io//nlp/2023/10/06/attention-is-all-you-need/" rel="alternate" type="text/html" title="Attention is All You Need" /><published>2023-10-06T00:00:00+07:00</published><updated>2023-10-06T00:00:00+07:00</updated><id>https://zhaospei.github.io//nlp/2023/10/06/attention-is-all-you-need</id><content type="html" xml:base="https://zhaospei.github.io//nlp/2023/10/06/attention-is-all-you-need/"><![CDATA[<p><code class="language-plaintext highlighter-rouge">Transformer</code> là mô hình seq2seq được Google Brain đề xuất trong một bài báo xuất bản vào cuối năm 2017. Giờ đây, nó đã đạt được nhiều ứng dụng và tiện ích mở rộng và <code class="language-plaintext highlighter-rouge">BERT</code> là mô hình ngôn ngữ được đào tạo trước có nguồn gốc từ Transformer.</p>

<p>Việc đào tạo <code class="language-plaintext highlighter-rouge">RNN</code> truyền thống là nối tiếp và nó phải đợi từ hiện tại được xử lý trước khi có thể xử lý từ tiếp theo. Transformer được huấn luyện song song, tức là tất cả các từ đều được huấn luyện cùng một lúc, điêu này làm tăng đáng kể hiệu quả tính toán.</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/transformer-model-architecture.png" alt="Kiến trúc mô hình Transformer" style="margin: auto;" />
    <figcaption style="font-style: italic;">Kiến trúc mô hình Transformer</figcaption>
</figure>

<h1 id="-self-attention"># Self-Attention</h1>
<p><code class="language-plaintext highlighter-rouge">Scaled Dot-Product Attention</code> là tích chấm chuẩn hóa Attention, chi tiết cụ thể được thể hiện trong hình.</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/attention.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

\[Attention(Q,K,V)=softmax(\dfrac{QK^T}{\sqrt{d_k}})V\]

<p>Sự chú ý của nhiều đầu vào sử dụng nhiều bộ trọng số (<code class="language-plaintext highlighter-rouge">weights</code>) (\(W_q,W_k,W_v\)), ghép lại cho ra kết quả cuối cùng.</p>

\[MultiHead(Q,K,V)=Concat(head_1,...,head_h)W^O\]

<p>trong đó</p>

\[head_i=Attention(QW^Q_i,KW^K_i,VW^V_i)\]

<p>Trong đó \(h = 8\), \(d_q=d_k=d_v=d_{model}/4=64\).</p>

<h1 id="-encoder"># Encoder</h1>
<p>Encoder được xếp chồng lên nhau bởi sáu lớp giống hệt nhau, mỗi lớp bao gồm hai lớp con - cơ chế tự chú ý nhiều đầu (<code class="language-plaintext highlighter-rouge">multi-head self-attention mechanism</code>) và mạng nơ ron vị trí chuyển tiếp được kết nối đầy đủ (<code class="language-plaintext highlighter-rouge">position-wise fully connected feed-forward network</code>). Mỗi lớp con sử dụng các kết nối dư (<code class="language-plaintext highlighter-rouge">residual connection</code>) và lớp chuẩn hóa (<code class="language-plaintext highlighter-rouge">layer normalization</code>). Kích thước đầu ra của các lớp con là \(d_{model} = 512\).</p>

<p>Đầu ra của lớp con có thể được biểu diễn dưới dạng:</p>

\[LayerNorm(x+Sublayer(x))\]

<h2 id="position-wise-fully-connected-feed-forward-network">position-wise fully connected feed-forward network</h2>
<p>Mạng nơ-ron chuyển tiếp được kết nối đầy đủ (<code class="language-plaintext highlighter-rouge">position-wise fully connected feed-forward network</code>) bao gồm hai phép biến đổi tuyến tính với kích hoạt <code class="language-plaintext highlighter-rouge">ReLU</code> ở giữa.</p>

\[FFN(x)=ReLU(xW_1+b_1)W_2+b_2\]

<p>Kích thước lớp bên trong (inner-layer) là 2048.</p>

<h2 id="residual-connection">residual connection</h2>
<p>Mạng dư (<code class="language-plaintext highlighter-rouge">Residual Network</code>), các kết nối tắt có khả năng bỏ qua một hoặc nhiều lớp, do sự tồn tại của kết nối tắt nên hiệu suất của mạng sâu (có nhiều lớp) không kém hơn so với các mạng nông (mạng có ít lớp). Phương pháp này giải quyết vấn đề suy thoái do các lớp chập xếp chồng lên nhau gây ra, số lượng lớp của mạng nơ-ron tích chập đã được tăng lên rất nhiều lên hàng trăm lớp, và cải thiện đáng kể hiệu suất của mạng thần kinh tích chập (<code class="language-plaintext highlighter-rouge">resnet</code>).</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/resnet.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<h2 id="batch-norm-và-layer-norm">Batch Norm và Layer Norm</h2>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/normalization.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<p>Đặt kích thước hình ảnh đầu vào là \([N, C, H, W]\):</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Batch Norm</code>, chuẩn hóa theo từng batch NHW, là để chuẩn hóa đầu vào từng kênh đơn, đều này không hiệu quả đối với <code class="language-plaintext highlighter-rouge">batch-size</code> nhỏ.</li>
  <li><code class="language-plaintext highlighter-rouge">Layer Norm</code>, chuẩn hóa theo từng layer CHW, là để chuẩn hóa đầu vào ở mỗi độ sâu, chủ yếu có tác dụng rõ ràng trên RNN.</li>
</ul>

<p>Sự hiểu biết cá nhân:</p>

<ul>
  <li>Dành cho CNN, nếu hạt nhân tích chập quét hình ảnh đầu vào, nó được tính là thao tác tích chập, cần có tổng thao tác batchsize. Do đó, chuẩn hóa cần được thực hiện theo batch.</li>
  <li>Dành cho RNN, batchsize thường là 1, số vòng lặp là số độ dài đầu vào (số channel). Do đó, chuẩn hóa cần được thực hiện theo channel.</li>
</ul>

<h2 id="toàn-bộ-kiến-trúc-encoder">Toàn bộ kiến trúc Encoder</h2>
<h3 id="input--positional-embedding">input &amp; positional embedding</h3>

\[X=Embedding-Lookup(X)+Positional-Encoding\]

<h3 id="multi-head-attention">multi-head attention</h3>

\[Q=Linear_q(X)=XW_q\]

\[K=Linear_q(X)=XW_k\]

\[V=Linear_v(X)=XW_v\]

\[X_{attention}=Self-Attention(Q,K,V)\]

<h3 id="add--norm">add &amp; norm</h3>

\[X_{attention}=LayerNorm(X+X_{attention})\]

<h3 id="feed-forward">feed forward</h3>

\[X_{hidden}=Linear(ReLU(Linear(X_{attention})))\]

<h3 id="add--norm-1">add &amp; norm</h3>

\[X_{hidden}=LayerNorm(X_{hidden}+X_{attention})\]

<p><code class="language-plaintext highlighter-rouge">multi-head attention</code> trong <code class="language-plaintext highlighter-rouge">Encoder</code> là một cơ chế tự chú ý (<code class="language-plaintext highlighter-rouge">self-attention mechanism</code>). \(k\), \(q\) và \(v\) trong cơ chế tự chú ý đều xuất phát từ cùng một vị trí, mỗi lớp của Encoder có thể nhận được tất cả vị trí của lớp trước.</p>

<h1 id="-decoder"># Decoder</h1>
<p>Decoder bao gồm sáu lớp giống hệt xếp chồng lên nhau; trong Multi-head Attention, \(q\) được đến từ lớp trước đó của Decoder, k và v đến từ đầu ra của Encoder. Điều cho phép mỗi vị trí trong Decoder nhận biết được tất cả các vị trí của chuỗi đầu vào.</p>

<p>Ngoài hai lớp con trong Encoder, Decoder thêm một lớp con mới xử lý đầu ra của Encoder - <code class="language-plaintext highlighter-rouge">masked multi-head self-attention mechanism</code>. Encoder trong seq2seq truyền thống sử dụng mô hình RNN, vì vậy nếu các từ tại thời điểm t được nhập vào trong quá trình huấn luyện thì mô hình sẽ không thể nhìn thấy các từ trước đó vào các thời điểm trong tương lai, bởi vì RNN hoạt động theo thời gian và chỉ khi thao tác tại thời điểm t hoàn thành, chỉ khi đó ta mới có thể nhìn thấy các từ tại thời điểm t + 1. Và Transformer Decoder đã không sử dụng RNN, thay đổi sang Self-Attention, điều này tạo ra một vấn đề, trong quá trình huấn luyện, toàn bộ ground truth đã được hiển thị với Decoder, điều này rõ ràng là sai, chúng ta cần phải thực hiện một số xử lý trên đầu vào của Decoder, quá trình này được gọi là <code class="language-plaintext highlighter-rouge">Mask</code> - Đặt tất cả các giá trị sau postion thành \(-\infty\) trước khi vào softmax.</p>

<p>Ví dụ, ground truth của Decoder là “&lt;start&gt; I am fine”, chúng ta cho câu này vào bộ Decoder, sau khi Word Embedding và Positional Encoding, thực hiện phép biến đổi tuyến tính bậc 3 trên ma trận thu được \((W_Q,W_K,W_V)\) Sau đó thực hiện self-attention, trước tiên, nhận Scaled Scores thông qua \(\dfrac{Q×K^T}{\sqrt{d_k}}\), bước tiếp theo rất quan trọng, chúng ta cần mask theo Scaled Scores, ví dụ, khi nhập “I”, hiện tại mô hình chỉ biết thông tin của tất cả các từ trước đó của “I”, tức thông tin của “&lt;start&gt;” và “I”, không được phép biết được thông tin của các từ sau “I”. Lý do rất đơn giản, khi dự đoán là chúng ta dự đoán theo thứ tự từng chữ, làm sao có thể biết được thông tin của những từ sau trước khi dự đoán xong từ này? Mask rất đơn giản, đầu tiên tạo một ma trận có tam giác hoàn toàn phía dưới bằng 0 và tam giác hoàn tòan phía trên bằng âm vô cùng, sau đó chỉ cần thêm nó vào Scaled Scores.</p>

<h1 id="-word-embedding-và-positional-embedding"># Word Embedding và Positional Embedding</h1>
<h2 id="word-embedding">Word Embedding</h2>
<p>Phần nhúng từ sử dụng nhúng từ có thể học được, kích thước của nó là \(d_{model}\).
Hình thức mã hóa <code class="language-plaintext highlighter-rouge">One-hot</code> ngắn gọn, nhưng quá thưa thớt, nó không phản ánh sự giống nhau về nghĩa của từ. Vì vậy hãy sử dụng <code class="language-plaintext highlighter-rouge">the Skip-Gram Model</code> hoặc <code class="language-plaintext highlighter-rouge">continuous bag of words model</code> hoặc các nhúng từ khác có thể học được khác.</p>

<h2 id="positional-embedding">Positional Embedding</h2>
<p>Bởi vì mô hình không bao gồm các cấu trúc tuần hoàn, vì vậy nắm bắt được các thông tin thứ tự tuần tự, ví dụ nếu \(K\) và \(V\) được xóa trộn theo từng hàng thì kết quả sau Attention sẽ giống nhau. Tuy nhiên, thông tin tuần tự rất quan trọng và thể hiện cấu trúc toàn cầu, do đó thông tin position tuyệt đối và tương đối của token tuần tự phải được sử dụng.</p>
<h3 id="nhúng-vị-trí-tùy-chinh">Nhúng vị trí tùy chinh</h3>
<p>Một ý tưởng là lấy một số trong khoảng \([0, 1]\) và gán nó cho mỗi từ, trong đó 0 được trao cho từ đầu tiên, 1 cho từ cuối cùng, công thức cụ thể là \(PE=\dfrac{pos}{T−1}\). Vấn đề của việc gán theo công thức này là nó bị phụ thuộc và kích thước của văn bản. Tức
là văn bản có số kí tự là 30. Khi đó theo công thức trên, thì khoảng cách giữa hai từ sẽ là 0.0333. Khi văn bản khác có số lượng kí từ &lt; 30, thì con số 0.0333 vẫn mô tả đúng vị trí tương đối giữa chúng, tuy nhiên với văn bản &gt; 30, ví dụ 90 thì 0.0333 đang gộp khoảng cách thực tế đang được phân tách bởi hai ký tự. Điều này rõ ràng là không phù hợp, vì sự khác biệt giống nhau không có nghĩa là giống nhau trong các câu khác nhau.</p>

<p>Một ý tưởng khác là gắn tuyến tính mỗi bước theo thời gian, nghĩa là từ đầu tiên được gán là 1, từ thứ hai được gán là 2, … Phương pháp này cũng có những vấn đề lớn: 1. Nó lớn hơn giá trị nhúng từ thông từ, có thể gây nhiễu cho mô hình; 2. Ký tự cuối cùng lớn hơn nhiều ký tự đầu tiên, sau khi hợp nhất với các từ nhúng, giá trị của các đặc trưng sẽ bị sai lệch.</p>

<h3 id="nhúng-từ-vị-trí-lý-tuởng">Nhúng từ vị trí “lý tuởng”</h3>
<p>Một lý tưởng là thiết kế nhúng vị trí phải đáp ứng những tiêu chí sau:</p>
<ul>
  <li>Nó sẽ xuất ra mã hóa duy nhất cho mỗi từ.</li>
  <li>Sự khác biệt giữa hai từ phải nhất quán giữa các câu có độ dài khác nhau.</li>
  <li>Giá trị của nó phải được giới hạn.</li>
</ul>

<p>Do đó việc nhúng vị trí sin và cosin đã được sử dụng cho Transformer.</p>

<p>Bây giờ hãy định nghĩa lại Positional Embedding, kích thước của việc nhúng vị trí là <code class="language-plaintext highlighter-rouge">[max_sequence_length, embedding_dimension]</code>, kích thước của phần nhúng vị trí giống với kích thước của vector từ, đều bằng <code class="language-plaintext highlighter-rouge">embedding_dimension</code>. <code class="language-plaintext highlighter-rouge">max_sequence_length</code> là một hyperparameter, đề cập đến số lượng tối đa mà một câu bao gồm.</p>

<p>Kích thước của việc nhúng vị trí cũng giống như kích thước của việc nhúng từ, cùng là \(d_{model}\). Công thước tính toán của nó là:</p>

\[PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})\]

\[PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})\]

<p>Trong đó, \(pos\) đại diện cho chỉ mục vị trí, \(i\) đại diện cho chỉ số chiều. Nghĩa là mỗi chiều \(i\) của positional embedding pos tương ứng với một sóng sin.</p>

<p>Trong hình dưới này minh họa cho cách tính position embedding của tác giả với số chiều là 6. Giá trị của các vector tại mỗi vị trí được tính toán theo công thức ở hình dưới.</p>
<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/pe.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<p>Bản thân việc nhúng vị trí là một thông tin vị trí tuyệt đối, nhưng trong ngôn ngữ, vị trí tương đối cũng rất quan trọng, bởi vì</p>

\[sin(\alpha+\beta)=sin\alpha cos\beta+cos\alpha sin\beta\cos(\alpha+\beta)=cos\alpha cos\beta-sin\alpha sin\beta\]

<p>cho thấy vector tại vị trí \(p + k\) có thể được biểu diễn dưới dạng phép biến đổi tuyến tính của vectơ tại vị trí \(p\), điều này cung cấp khả năng thể hiện thông tin vị trí tương đối. Phiên bản hình sin cũng cho phép mô hình ngoại suy với độ dài chuỗi dài hơn so với độ dài chuỗi gặp phải trong quá trình huấn luyện.</p>

<h1 id="-q--a"># Q &amp; A</h1>
<h2 id="tại-sao-transformer-cần-multi-head-attention-">Tại sao Transformer cần Multi-head Attention ?</h2>
<p>Bài báo đề cập lý do việc tiến hành Multi-head Attention là để chia mô hình thành nhiều đầu để tạo thành nhiều không gian con, cho phép mô hình chú ý đến các khía cạnh khác nhau của thông tin và cuối cùng tổng hợp thông tin từ tất cả các khía cạnh. Trên thực tế, có thể hình dung bằng trực giác rằng nếu bạn tự thiết kế một mô hình như vậy, attention sẽ không chỉ được thực hiện một lần, kết quả tổng hợp của nhiều lần chú ý ít nhất có thể nâng cao mô hình và cũng có thể được so sánh với vai trò của việc sử dụng nhiều tích chập cùng lúc trong CNN, theo trực giác, sự chú ý của nhiều người đứng đầu giúp mạng nắm bắt được các tính năng/ thông tin phong phú hơn.</p>
<h2 id="ưu-điểm-của-transformer-so-với-rnnlstm-là-gì-tại-sao">Ưu điểm của Transformer so với RNN/LSTM là gì? Tại sao?</h2>
<ol>
  <li>Các mô hình RNN không thể tính toán song song vì việc tính toán tại thời điểm T phụ thuộc vào kết quả tính toán của lớp ẩn tại thời điểm T - 1, còn việc tính toán tại thời điểm T - 1 lại phụ thuộc tính toán của lớp ẩn tại thời điểm T - 2.</li>
  <li>Khả năng trích xuất đặc trưng của Transformer tốt hơn so với các mô hình RNN.</li>
</ol>

<h2 id="tại-sao-transformer-có-thể-thay-thế-seq2seq">Tại sao Transformer có thể thay thế seq2seq?</h2>
<p>Từ thay thế ở đây hơi không phù hợp, seq2seq tuy cũ nhưng vẫn có chỗ đứng, vấn đề lớn nhất của seq2seq là ở chỗ <strong>Nén thông tin ở phía Encoder thành một vector có độ dài cố định</strong> và sử dụng nó làm đầu vào của trạng thái đầu tiên ở phía Decoder, để dự đoán trạng thái ẩn của từ đầu tiên (mã thông báo) ở phía Decoder. Khi chuỗi đầu vào tương đối dài, điều này rõ ràng sẽ mất rất nhiều thông tin ở phía Encoder và vector cố định sẽ được gửi đến phía Decoder cùng một lúc, <strong>bên Decoder không thể chú ý đến thông tin mà nó muốn chú ý</strong>. Mô hinh transformer không chỉ cải thiện đáng kể hai khuyết điểm này của mô hình seq2seq (Mô-đun attention tương tác nhiều đầu), và cũng giới thiệu mô-đun self-attention, trước tiên hãy để trình tự nguồn và trình tự đích được “tự liên kết”, trong trường hợp này, thông tin chứa trong embedding của trình tự nguồn và trình tự đích sẽ phong phú hơn và lớp FFN tiếp theo cũng nâng cao khả năng biểu đạt của mô hình, và tính toán song song của Transfomer vượt xa các model seq2seq.</p>

<h1 id="tham-khảo">Tham khảo</h1>

<p>[1] <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a></p>]]></content><author><name>zhao</name></author><category term="NLP" /><category term="nlp" /><category term="paper" /><category term="model" /><summary type="html"><![CDATA[Transformer là mô hình seq2seq được Google Brain đề xuất trong một bài báo xuất bản vào cuối năm 2017. Giờ đây, nó đã đạt được nhiều ứng dụng và tiện ích mở rộng và BERT là mô hình ngôn ngữ được đào tạo trước có nguồn gốc từ Transformer.]]></summary></entry><entry><title type="html">NLP Papers to be Read</title><link href="https://zhaospei.github.io//nlp/2023/10/06/nlp-papers-to-be-read/" rel="alternate" type="text/html" title="NLP Papers to be Read" /><published>2023-10-06T00:00:00+07:00</published><updated>2023-10-06T00:00:00+07:00</updated><id>https://zhaospei.github.io//nlp/2023/10/06/nlp-papers-to-be-read</id><content type="html" xml:base="https://zhaospei.github.io//nlp/2023/10/06/nlp-papers-to-be-read/"><![CDATA[<h2 id="0-surveys-of-natural-language-processing">0. Surveys of Natural Language Processing</h2>

<ol>
  <li>
    <p><strong>Neural Network Methods for Natural Language Processing</strong>. <em>Yoav Goldberg</em>. SLHLT 2017. [<a href="">paper</a>]</p>
  </li>
  <li>
    <p><strong>Advances in natural language processing</strong>. <em>Julia Hirschberg, Christopher D Manning</em>. Science 2015. [<a href="https://nlp.stanford.edu/~manning/xyzzy/Hirschberg-Manning-Science-2015.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Jumping NLP Curves: A Review of Natural Language Processing Research</strong>.
<em>Erik Cambria, Bebo White</em>. CIM 2014. [<a href="https://www.gwern.net/docs/ai/2014-cambria.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Natural Language Processing: An Introduction</strong>.
<em>Prakash M Nadkarni,  Lucila Ohno-Machado,  Wendy W Chapman</em>. JAMIA 2011. [<a href="https://watermark.silverchair.com/18-5-544.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAskwggLFBgkqhkiG9w0BBwagggK2MIICsgIBADCCAqsGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMTbW0kBdq70u31A2pAgEQgIICfB9c_mxn3VbFBsTi1npJDFQeVGcPm4ColBNSaoe_IQi7mxDJx5DwD9mmYvdhOQf3CIcds_yDPpLJFP_9bvkf0mfQkKb3U9TSm-KMl_xwLjhkIi090ceKWUhQqcbihY4IWKJmapv0kADF73tPUl9yGhmjFe6Bn7wAKhBC0_XE_A1qpqgscRoyQ3rocVi6dklbHjFKBbIKO5790l6gJXijbVqwAJF3WBGWhP9v0uvXlRun--BG8BZYk2CA6aleWw4T_pCh0fh4ZA1zXNnkr3MiE3Z3YtSdNvDuNA19kekWt8WtRDJd33KRqqWIzk_t-Tekk87SpMLR3O59In65vBSUIBiuFB6xPXJu4-HkU6m5hb9NybU8iYT2oQNQQXdh3Xep4c8OfzCkhLO-CVGhIEOLmNgfKuOnxZW9KAQeZrauNHd-binadf6b5MKrtecCOvrdNgAZNSIyTlGUC_knXbGmMbI3ELTDvARIulZykTF0ZfPCFDDxCrWlpy2FzS_9yBwNc_h7qRC0MxINmxHlADF7efxm3L9XoM7v2bul5tqInTjmjGDZX8ZjSlBs0E2Nvq8YaBxaGJkYV7L-KSY81qgRVMfekEha7eRZFPAn6bFbfO3WulUpfD1veDasuwyIlRsql3EGx4VGmkSE7SpYPrMEVSdHU0Wo8LKKj1xCTzmIv_0Por_y4uAnjB7J3IToavjoanU6iOkg-rFyYw5Y8guFBDPJ9CyKLeBf3RjU1_KEOXW2IGaVIcKvQqFIL_Xnb8sBUSZfFJ3bpNpT4aqHyAKun8Ec6yYGd1hVuGg57nHbuDODtxoe-RB0f3BK3K-Lu698fCh-fpWhAAcziNHZhQ">paper</a>]</p>
  </li>
</ol>

<h2 id="1-language-parsing">1. Language Parsing</h2>

<h3 id="11-vietnamese-word-segmentation">1.1 Vietnamese Word Segmentation</h3>

<ol>
  <li><strong>State-of-the-Art Vietnamese Word Segmentation</strong>. Song Nguyen Duc Cong, Quoc Hung Ngo, Rachsuda Jiamthapthaksin. IEEE 2019. [<a href="https://browse.arxiv.org/pdf/1906.07662.pdf">paper</a>]</li>
</ol>

<h3 id="12-syntactic-parsing">1.2 Syntactic Parsing</h3>

<ol>
  <li><strong>Syntactic Parsing: A Survey</strong>.
<em>Alton F. Sanders and Ruth H. Sanders</em>. Computers and the Humanities 1989. [<a href="https://www.academia.edu/download/46281305/bf0005876620160606-13840-7rn8pc.pdf">paper</a>]</li>
</ol>

<h3 id="13-dependency-parsing">1.3 Dependency Parsing</h3>

<ol>
  <li><strong>Dependency Parsing</strong>.
<em>Sandra Kubler, Ryan McDonald, Joakim Nivre</em>. SLHLT 2009. [<a href="https://www.linguisticsociety.org/sites/default/files/e-learning/dependencies.pdf">paper</a>]</li>
</ol>

<h3 id="14-semantic-parsing">1.4 Semantic Parsing</h3>

<ol>
  <li><strong>A Survey on Semantic Parsing</strong>.
<em>Aishwarya Kamath, Rajarshi Das</em>. AKBC 2018. [<a href="https://arxiv.org/pdf/1812.00978">paper</a>]</li>
</ol>

<h3 id="15-part-of-speech-tagging">1.5 Part of Speech Tagging</h3>

<ol>
  <li><strong>Part‐of‐speech Tagging</strong>.
<em>Angel R Martinez</em>. WIREs Comp Stats 2012. [<a href="https://wires.onlinelibrary.wiley.com/doi/epdf/10.1002/wics.195">paper</a>]</li>
</ol>

<h3 id="16-word-sense-disambiguation">1.6 Word Sense Disambiguation</h3>

<ol>
  <li>
    <p><strong>Word Sense Disambiguation: A Survey</strong>.
<em>Alok Ranjan Pal</em>. arXiv 2015. [<a href="https://arxiv.org/pdf/1508.01346">paper</a>]</p>
  </li>
  <li>
    <p><strong>Word Sense Disambiguation: A Survey</strong>.
<em>Roberto Navigli</em>. CSUR 2009. [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.8457&amp;rep=rep1&amp;type=pdf">paper</a>]</p>
  </li>
</ol>

<h3 id="17-named-entity-recognization">1.7 Named Entity Recognization</h3>

<ol>
  <li>
    <p><strong>A Survey on Deep Learning for Named Entity Recognition</strong>.
<em>Jing Li, Aixin Sun, Jianglei Han, Chenliang Li</em>. TKDE 2020. [<a href="https://arxiv.org/pdf/1812.09449">paper</a>]</p>
  </li>
  <li>
    <p><strong>A Survey of Named Entity Recognition and Classification</strong>.
<em>David Nadeau, Satoshi Sekine</em>. Lingvisticae Investigationes 2007. [<a href="https://www.time.mk/trajkovski/thesis/li07.pdf">paper</a>]</p>
  </li>
</ol>

<h3 id="18-coreference-resolution">1.8 Coreference Resolution</h3>

<ol>
  <li><strong>Coreference Resolution: A Survey</strong>.
<em>Pradheep Elango</em>. University of Wisconsin, Madison, WI 2005. [<a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.1565&amp;rep=rep1&amp;type=pdf">paper</a>]</li>
</ol>

<h2 id="2-natural-language-understanding-and-generation">2. Natural Language Understanding and Generation</h2>

<h3 id="21-text-classification">2.1 Text Classification</h3>

<ol>
  <li>
    <p><strong>Text Classification Algorithms: A Survey</strong>. 
<em>Kamran Kowsari, Kiana Jafari Meimandi, Mojtaba Heidarysafa, Sanjana Mendu, Laura Barnes, Donald Brown</em>. Information 2019. [<a href="https://www.mdpi.com/2078-2489/10/4/150/pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Semantic Text Classification: A Survey of Past and Recent Advances</strong>.
<em>Berna Altinel, Murat Can Ganiz</em>. IP\&amp;M 2018. [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0306457317305757">paper</a>]</p>
  </li>
</ol>

<h3 id="22-sentiment-analysis">2.2 Sentiment Analysis</h3>

<ol>
  <li>
    <p><strong>A Survey of Sentiment Analysis in Social Media</strong>. 
<em>Lin Yue, Weitong Chen, Xue Li, Wanli Zuo, Minghao Yin</em>. KAIS 2019. [<a href="http://cse.iitkgp.ac.in/~saptarshi/courses/socomp2020a/sentiment-analysis-survey-yue2019.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Sentiment Analysis Algorithms and Applications: A Survey</strong>.
<em>Walaa Medhat, Ahmed Hassan, Hoda Korashy</em>. ASEJ 2014. [<a href="https://www.sciencedirect.com/science/article/pii/S2090447914000550">paper</a>]</p>
  </li>
</ol>

<h3 id="23-natural-language-inference">2.3 Natural Language Inference</h3>

<ol>
  <li><strong>Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches</strong>. 
<em>Shane Storks, Qiaozi Gao, Joyce Y Chai</em>. arXiv 2019. [<a href="https://arxiv.org/pdf/1904.01172">paper</a>]</li>
</ol>

<h3 id="24-reading-comprehension">2.4 Reading Comprehension</h3>

<ol>
  <li>
    <p><strong>A Survey on Machine Reading Comprehension—Tasks, Evaluation Metrics and Benchmark Datasets</strong>. 
<em>Changchang Zeng, Shaobo Li, Qin Li, Jie Hu, Jianjun Hu</em>. AS 2020. [<a href="https://www.mdpi.com/2076-3417/10/21/7640/pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Neural Machine Reading Comprehension: Methods and Trends</strong>.
<em>Shanshan Liu, Xin Zhang, Sheng Zhang, Hui Wang, Weiming Zhang</em>. AS 2019. [<a href="https://www.mdpi.com/2076-3417/9/18/3698/pdf">paper</a>]</p>
  </li>
</ol>

<h3 id="25-text-generation">2.5 Text Generation</h3>

<ol>
  <li>
    <p><strong>Pretrained Language Models for Text Generation: A Survey</strong>.
<em>Junyi Li, Tianyi Tang, Wayne Xin Zhao, Ji-Rong Wen</em>. arXiv 2021. [<a href="https://arxiv.org/pdf/2105.10311.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Survey of the State of the Art in Natural Language Generation: Core Tasks, Applications and Evaluation</strong>. 
<em>Albert Gatt, Emiel Krahmer</em>. JAIR 2018. [<a href="https://www.jair.org/index.php/jair/article/download/11173/26378">paper</a>]</p>
  </li>
</ol>

<h3 id="26-machine-translation">2.6 Machine Translation</h3>

<ol>
  <li><strong>Neural Machine Translation: A Review of Methods, Resources, and Tools</strong>.
<em>Zhixing Tan, Shuo Wang, Zonghan Yang, Gang Chen, Xuancheng Huang, Maosong Sun, YangLiu</em>. AI Open 2020. [<a href="https://pdf.sciencedirectassets.com/777606/1-s2.0-S2666651020X00027/1-s2.0-S2666651020300024/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIEI%2Fd%2BRJ29itBNaq4DDn72X5y%2BvR4sUPQVYGkvCaOxSlAiBb9Jk8gNj2eRv5XzqU3MDZLcM9cNVYMk3bApmgOuKo5SqDBAjh%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAQaDDA1OTAwMzU0Njg2NSIMGBZpbHJaLTbA2IKlKtcDlKl3M%2FKoev68AxfA1LPWWUNURJZeL4opVifdAsIMyGUSQ0PEtmApxPZUw7VrdigGDkvaShDCCYh0Y0RJWXF9GXX%2BpJBuuv8eae1mGQ1OjjBgT2rmIVCx%2BcCpyBeTkz2BWEzf36ZBqIs96pGUGptZOruWn03TkrTIk9u7reHlD1dP3WAhEynkyAFu6ZYxhJ4i54R%2FDDPUvKhvHRe54QvYHciX%2BDUQr%2B8LqkhGPLs3%2F1fKkpbtbYKPaEd2Il2rJAG26xNhj2b6%2FZnHoA6cn%2B%2F3CszEXb6QhQHDB8g4ZhmJTivtVtRmWXexmpFo0%2FUpMXLLlojv9SoCME80T1skNCRqOWzWjN7T%2F4exLLxIHVn9YXDKHczyKkAY0F%2B8gcICr36m0y9joAsGo8cSj5afhzA1GalxsYdOiSV0rfZApSZ3giU74snMygiXsmYtI7o6G%2FpRGC%2FNuJfP0%2BZgviIhCXY2OtOcujYyj3dixk6AFMkAHmbJEG2XyqE6HdOxsv7pcBDe%2BBtkbMMriBdlARwyP13qdS%2BaP8NOuTwdF3ykM8dwsQXC7Bg1soovygfTiBYPr%2FBBewCVXlY%2BEWo1XTCF2rBh93od29atHRiaFnH16zU%2FeBHqFR%2FwIueOMMups4cGOqYBUMp8kSHbPS7itMjQoLFtUow0nDP1jtAKu7aZ0pc2575N2vF3ljE%2BOb4EOjRX38EC9s%2BoKu62gEeZPpIHXOuAlmMopPwkPOmAhgsS6SBm8GkkbUOsqiZYrkMMCaxBXLof7Hb0J%2FO%2BP5X0pfoxehoAhhA5kAsxgmYc%2BfOvhKaScNacloAs3j1fIq5yPXSz97%2B98GxPDNKE1%2BZ349rpPxYdOHMWLomZNw%3D%3D&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20210713T011505Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTYXAOF4ABF%2F20210713%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=e7ed2a8e3a1864f8e8501ab7267e8fccb4063f50bede5feafa0b70ccab5b2521&amp;hash=da1e8d310c84ee9994d7353a0f8bd6819053d8d02889f652f94641cbcfea9a19&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S2666651020300024&amp;tid=spdf-def16018-cee7-4413-938c-6b22e9f94fdc&amp;sid=27eca1f72344884dbe7913d4b18b564d6a85gxrqa&amp;type=client">paper</a>]</li>
</ol>

<h3 id="27-text-summarization">2.7 Text Summarization</h3>

<ol>
  <li>
    <p><strong>A Survey on Dialogue Summarization: Recent Advances and New Frontiers</strong>.
 <em>Xiachong Feng, Xiaocheng Feng, Bing Qin</em>. arXiv 2021. [<a href="https://arxiv.org/pdf/2107.03175">paper</a>]</p>
  </li>
  <li>
    <p><strong>The Factual Inconsistency Problem in Abstractive Text Summarization: A Survey</strong>. <em>Yichong Huang, Xiachong Feng, Xiaocheng Feng, Bing Qin</em>. arXiv 2021. [<a href="https://arxiv.org/pdf/2104.14839">paper</a>]</p>
  </li>
  <li>
    <p><strong>What Have We Achieved on Text Summarization?</strong>
 <em>Dandan Huang, Leyang Cui, Sen Yang, Guangsheng Bao, Kun Wang, Jun Xie, Yue Zhang</em>. EMNLP 2020. [<a href="https://aclanthology.org/2020.emnlp-main.33.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Recent Automatic Text Summarization Techniques: A Survey</strong>. 
 <em>Mahak Gambhir, Vishal Gupta</em>. AIR 2017. [<a href="https://link.springer.com/content/pdf/10.1007/s10462-016-9475-9.pdf">paper</a>]</p>
  </li>
</ol>

<h2 id="3-information-extraction">3. Information Extraction</h2>

<h3 id="31-relation-extraction">3.1 Relation Extraction</h3>

<ol>
  <li>
    <p><strong>More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction</strong>.
<em>Xu Han, Tianyu Gao, Yankai Lin, Hao Peng, Yaoliang Yang, Chaojun Xiao, Zhiyuan Liu, Peng Li, Maosong Sun, Jie Zhou</em>. AACL 2020. [<a href="https://aclanthology.org/2020.aacl-main.75.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Relation Extraction: A Survey</strong>.
<em>Sachin Pawar, Girish K. Palshikara, Pushpak Bhattacharyyab</em>. arXiv 2017. [<a href="https://arxiv.org/pdf/1712.05191.pdf">paper</a>]</p>
  </li>
</ol>

<h3 id="32-event-extraction">3.2 Event Extraction</h3>

<ol>
  <li><strong>Extracting Events and Their Relations from Texts: A Survey on Recent Research Progress and Challenges</strong>.
<em>Kang Liu, Yubo Chen, Jian Liu, Xinyu Zuo, Jun Zhao</em>. AI Open 2020. [<a href="https://www.sciencedirect.com/science/article/pii/S266665102100005X/pdfft?md5=3983861e9ae91ce7b45f0c5533071077&amp;pid=1-s2.0-S266665102100005X-main.pdf">paper</a>]</li>
</ol>

<h3 id="33-open-information-extraction">3.3 Open Information Extraction</h3>

<ol>
  <li><strong>A Survey on Open Information Extraction</strong>. 
<em>Christina Niklaus, Matthias Cetto, Andre Freitas, Siegfried Handschuh</em>. COLING 2018. [<a href="https://arxiv.org/pdf/1806.05599">paper</a>]</li>
</ol>

<h2 id="4-information-retrieval">4. Information Retrieval</h2>

<ol>
  <li>
    <p><strong>Pretrained Transformers for Text Ranking: BERT and Beyond</strong>. <em>Andrew Yates, Rodrigo Nogueira, Jimmy Lin</em>. WSDM 2021. [<a href="https://dl.acm.org/doi/pdf/10.1145/3437963.3441667">paper</a>]</p>
  </li>
  <li>
    <p><strong>Data Mining and Information Retrieval in the 21st Century: A Bibliographic Review</strong>. <em>Jiaying Liu, Xiangjie, Kong, Xinyu Zhou, Lei Wang, Da Zhang, Ivan Lee, Bo Xu, Feng Xia</em>. Science Review 2019. [<a href="https://pdf.sciencedirectassets.com/276226/1-s2.0-S1574013719X00040/1-s2.0-S1574013719301297/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCICq5IyB56s6Und0UJRNRuwZ8moPqdExErZ0TtRQQLGUNAiAFqh%2FtINYbe%2BmWQnEo%2B4GbKrlum0q8IMz0DkqT4sB%2B1CqDBAjN%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAQaDDA1OTAwMzU0Njg2NSIM5WDlAL%2BoE9iRKE4WKtcDlh9uPvVVjUQ9h8KwcYFwpbaEfF6xvjLl%2Fyzn4gGE3ARgGVsEJbi2kVc83hDhw03g%2BaKxGWSQr10OLGqG0nYTUrJdQZY6WcZpJRBDcdjfMe%2FVlGlQuG0Mu%2BZYZRO%2F96h%2BAiAXwDIuZyLRAftKyIrBLgqnZ0PBsC6lyOFdPH0RFW%2B19YFKHoNuof%2Fx%2BrmpL63bLK6EBPzjI6ZOQ7f3Hc%2Fo%2FiZGoAH2AAMsidgyBIBk%2FZx56S%2B%2FWv6hvkmZh%2BbUj%2FK9ElXqnIDgyokzOX4%2FR9SVPFP5lXslzU3BJmpS2LsMv9SI4xY92ISOdXGTw2eCgMnqvY4huM92tSJoNkaKuipZPU8Em61WcrCcjP2v%2Bubxaz0LCTwrnbB2jQYLf9%2BzIZf7DWrIaWVu8XuoPwMfj%2FY7IELkNdidCHErVp94D3%2Fcv%2FIHGcHIUxVuK2pvElHB85xF0hgsWRWbX9RusDU2S7KryloCMjkedsgSfiNh0uAaiuiL40S5olbAVuK00LgXEq9o1H3%2B%2BQekDo%2Bn0kzIolfMBPAWpf2Anmvfa0vGEIrtXqS7tqIGHvDNNpmE8gg9lB63QlKJu2Yt3jiUbcQJbuWhEz8OCqcngVgRVtQRT7Nstb8V1yMc43QcMNPzrocGOqYB3b0JzWmueBzXIGbAdfLifUj%2BGQm2Kx0Qi4LsuBnJEYaX0GfcWxtT%2BaIk%2By3PCP2H3vABGfO0bInuXflJBhpkW4pZ5i7d51ysfp%2FKXu4yEiZT2JhDFgi70p0roesXyHrD5z5pi2nYWXptCTD6oe6JWR02QtCr5IsQVMBTRa3RUwOjAf3VP58zT2dNSwLjUTOjNdAC3e2j1FA2cQn9f0C94pIrKjPt4g%3D%3D&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20210712T045217Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTY74QVIXG7%2F20210712%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=f2f453778540f3e5bf0883461f74ac8314f34bee23d998cb46403e9eee9c23c2&amp;hash=6e521d2013bcd4ebe81b93a081d055b01acebb5dbd35d82f8502f2de73ce799e&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S1574013719301297&amp;tid=spdf-35941364-0392-4be0-b75e-20e00a183bf2&amp;sid=27eca1f72344884dbe7913d4b18b564d6a85gxrqa&amp;type=client">paper</a>]</p>
  </li>
  <li>
    <p><strong>Deep Learning for Matching in Search and Recommendation</strong>. <em>Jun Xu, Xiangnan He, Hang Li</em>. SIGIR tutorial 2018. [<a href="http://staff.ustc.edu.cn/~hexn/papers/www18-tutorial-deep-matching-paper.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Neural Models for Information Retrieval</strong>.
<em>Bhaskar Mitra, Nick Craswell</em>. arXiv 2017. [<a href="https://arxiv.org/pdf/1705.01509.pdf">paper</a>]</p>
  </li>
</ol>

<h2 id="5-dialogue-and-question-answering">5. Dialogue and Question Answering</h2>

<h3 id="51-dialogue">5.1 Dialogue</h3>

<ol>
  <li><strong>A Survey on Dialogue Systems: Recent Advances and New Frontiers</strong>.
<em>Hongshen Chen, Xiaorui Liu, Dawei Yin, Jiliang Tang</em>. Acm SIGKDD Explorations Newsletter 2017. [<a href="https://arxiv.org/pdf/1711.01731">paper</a>]</li>
</ol>

<h3 id="52-question-answering">5.2 Question Answering</h3>

<ol>
  <li>
    <p><strong>Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering</strong>. <em>Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, Tat-Seng Chua</em>. arXiv 2021. [<a href="https://arxiv.org/pdf/2101.00774">paper</a>]</p>
  </li>
  <li>
    <p><strong>Core Techniques of Question Answering Systems over Knowledge Bases: A Survey</strong>. <em>Dennis Diefenbach, Vanessa Lopez, Kamal Singh, Pierre Maret</em>. KAIS 2018. [<a href="https://hal.archives-ouvertes.fr/hal-01637143/document">paper</a>]</p>
  </li>
  <li>
    <p><strong>Question Answering Systems: Survey and Trends</strong>. <em>Abdelghani Bouziane, Djelloul Bouchiha, Noureddine Doumi, Mimoun Malki</em>. Procedia Computer Science 2015. [<a href="https://www.sciencedirect.com/science/article/pii/S1877050915034663/pdf?md5=e483aabf699b13dd1fdb74c8e95b5100&amp;pid=1-s2.0-S1877050915034663-main.pdf&amp;_valck=1">paper</a>]</p>
  </li>
</ol>

<h2 id="6-representation-learning">6. Representation Learning</h2>

<h3 id="61-representation-learning">6.1 Representation Learning</h3>

<ol>
  <li><strong>Representation Learning: A Review and New Perspectives.</strong> 
<em>Yoshua Bengio, Aaron Courville, and Pascal Vincent.</em> TPAMI 2013. [<a href="https://arxiv.org/pdf/1206.5538">paper</a>]</li>
</ol>

<h3 id="62-word-representation-learning">6.2 Word Representation Learning</h3>

<ol>
  <li><strong>From Word to Sense Embeddings: A Survey on Vector Representations of Meaning</strong>.
<em>Jose Camacho-Collados, Mohammad Taher Pilehvar</em>. JAIR 2018. [<a href="https://www.jair.org/index.php/jair/article/download/11259/26454/">paper</a>]</li>
</ol>

<h3 id="63-network-representation-learning">6.3 Network Representation Learning</h3>

<ol>
  <li>
    <p><strong>Network Representation Learning: A Macro and Micro View</strong>.
<em>Xueyi Liu, Jie Tang</em>. AI Open 2021. [<a href="https://pdf.sciencedirectassets.com/777606/1-s2.0-S2666651021X00022/1-s2.0-S2666651021000024/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQDF4AZ3X%2BNSkwIYrQFjT5J2NmWQoHmxcdnZ%2FcUedLywSgIhAII%2FNrzVTGMN1PMuzFJn%2FSKD4UfyWdV3w2K6wuGU8GSJKoMECOH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMMDU5MDAzNTQ2ODY1Igx4dtx3R0qAisPhSuAq1wO%2FfY2wuQ6oZ9%2FyuJoq4P7j2zbMRSxFWEdIFt%2BInUKHuKOR6Z2QolCfx10s7ool05vvnLgkwesm4G5TIbFdq9AyaKtnGB2fIkRL872m94O9RRUYvWONG6UxFcMCmEbXhvQPWBsz1ypEsJkTeZ7S9oVZaWXaJeNr90BrHWxSdoOQ2U%2Fy%2Bo7OCY4cExwbBzRGVpQQ%2BhwEjUpzBmhHRa3ITiZJZrIedCZE7tL%2FuQ2AxM963t9GOX0dl3fx2aF4u89FLnXjSUwS8kSII37OmEoOoqU8GalrGQSqbLfVX3jCh4LJucC76fZNXB7Ueu%2Bn%2FY%2BpYSn71iAFnSpsVYoxL2zx%2BqyTq8twGK70%2BU9bRtCHoAV26Z8Z7IRqiMZm5wLdvuaUDt%2B79izGneQ4dfPymy5Z50RWxhHDupoYYuCcl53EwHS5DJ8eOoQ6mjOszngrVwZsnohHIw0v1kOwH8zAmwUFuYvar543JI1HfXIPLndTFsKXhxnN%2BppqrW5Myxf06NvQgZ9QJPYcnFlcgCn3pN0QbjgZx%2FNkwqYvp3qFe6ASVZzON694ufdsBnzCfKK4W7kczivEsmd83%2Fd5nC8P18I3EMeGK%2FqI34SpBpJqGB0Me3Fc6nhQQM8eW3Yw6a%2BzhwY6pAGtEmsONGDApmnuJDw06%2FP5MqunMCAPmOCm5j4p%2BqWbtDyaACe9vPmBt4RPgRA4B7Axxi05VzhjJ525wrThobJ86%2BFIHHyfXcipLDY3Z5wz1wIdv%2FL6qvXR%2B1A05XULV2BMQVEEGzFrFTr%2BFSLx%2BStedvTrwlS8s22mBg6Y4U6yoH7XrI28KcIpMaIfbTscy34E3aqKqCE%2FLcdl19JYgwg46dUebw%3D%3D&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20210713T011759Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTY4MKE7SXL%2F20210713%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=b475442910cb1cbe2893d7a57cb204012ba3fb1c4038481a79775f88eaf78ec9&amp;hash=b0aee28209890c3e40e3b1fca16a70a0d6f7c8ed6c36846912b65f7811a8d480&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S2666651021000024&amp;tid=spdf-69cab0cb-463d-46df-b673-08b0dc37a6fa&amp;sid=27eca1f72344884dbe7913d4b18b564d6a85gxrqa&amp;type=client">paper</a>]</p>
  </li>
  <li>
    <p><strong>A Survey on Network Embedding</strong>.
<em>Peng Cui, Xiao Wang, Jian Pei, Wenwu Zhu</em>. TKDE 2018. [<a href="https://arxiv.org/pdf/1711.08752">paper</a>]</p>
  </li>
  <li>
    <p><strong>Network Representation Learning: A Survey</strong>.
<em>Daokun Zhang, Jie Yin, Xingquan Zhu, Chengqi Zhang</em>. TBD 2018. [<a href="https://arxiv.org/pdf/1801.05852.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Network Representation Learning: An Overview</strong>.
<em>Cunchao Tu, Cheng Yang, Zhiyuan Liu, Maosong Sun</em>. SSI 2017. [<a href="http://engine.scichina.com/publisher/scp/journal/SSI/47/8/10.1360/N112017-00145">paper</a>]</p>
  </li>
</ol>

<h2 id="7-knowledge-graph">7. Knowledge Graph</h2>

<h3 id="71-knowledge-graph">7.1 Knowledge Graph</h3>

<ol>
  <li><strong>Neural, Symbolic and Neural-symbolic Reasoning on Knowledge Graphs</strong>.</li>
</ol>

<p><em>Jing Zhang, Bo Chen, Lingxi Zhang, Xirui Ke, Haipeng Ding</em>. AI Open 2021. [<a href="https://www.sciencedirect.com/science/article/pii/S2666651021000061/pdfft?md5=41dae412c5802b063f8ff0615ba12622&amp;pid=1-s2.0-S2666651021000061-main.pdf">paper</a>]</p>

<ol>
  <li>
    <p><strong>Knowledge Graph Embedding: A Survey of Approaches and Applications</strong>.
<em>Quan Wang, Zhendong Mao, Bin Wang, Li Guo</em>. TKDE 2017. [<a href="http://ieeexplore.ieee.org/abstract/document/8047276/">paper</a>]</p>
  </li>
  <li>
    <p><strong>Knowledge Graph Refinement: A Survey of Approaches and Evaluation Methods</strong>. <em>Heiko Paulheim</em>. Semantic Web 2017. [<a href="http://www.semantic-web-journal.net/system/files/swj1167.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Knowledge Representation Learning: A Review</strong>.
<em>Zhiyuan Liu, Maosong Sun, Yankai Lin, Ruobing Xie</em>. JCRD 2016. [<a href="https://crad.ict.ac.cn/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=3099">paper</a>]</p>
  </li>
  <li>
    <p><strong>A Review of Relational Machine Learning for Knowledge Graphs</strong>.
<em>Maximilian Nickel, Kevin Murphy, Volker Tresp, Evgeniy Gabrilovich</em>. Proceedings of the IEEE 2015. [<a href="https://arxiv.org/pdf/1503.00759">paper</a>]</p>
  </li>
</ol>

<h3 id="72-common-sense-knowledge-graph">7.2 Common Sense Knowledge Graph</h3>

<ol>
  <li><strong>Sememe Knowledge Computation: A Review of Recent Advances in Application and Expansion of Sememe Knowledge Bases</strong>.
<em>Fanchao Qi, Ruobing Xie, Yuan Zang, Zhiyuan Liu, Maosong Sun</em>. FCS 2021. [<a href="https://link.springer.com/article/10.1007/s11704-020-0002-4">paper</a>]</li>
</ol>

<h2 id="8-machine-learning-for-natural-language-processing">8. Machine Learning for Natural Language Processing</h2>

<h3 id="81-deep-learning-for-natural-language-processing">8.1 Deep Learning for Natural Language Processing</h3>

<ol>
  <li>
    <p><strong>A Survey of the Usages of Deep Learning for Natural Language Processing</strong>.
<em>Daniel W. Otter, Julian R. Medina, Jugal K. Kalita</em>. TNNLS 2021. [<a href="https://arxiv.org/pdf/1807.10854">paper</a>]</p>
  </li>
  <li>
    <p><strong>Recent Trends in Deep Learning Based Natural Language Processing</strong>.
<em>Tom Young, Devamanyu Hazarika, Soujanya Poria, Erik Cambria</em>. CIM 2018. [<a href="https://arxiv.org/pdf/1708.02709.pdf%C2%A0">paper</a>]</p>
  </li>
</ol>

<h3 id="82-transformers-and-pre-trained-language-models">8.2 Transformers and Pre-trained Language Models</h3>

<ol>
  <li>
    <p><strong>A Survey of Transformers</strong>.
<em>Tianyang Lin, Yuxin Wang, Xiangyang Liu, Xipeng Qiu</em>. arXiv 2021. [<a href="https://arxiv.org/pdf/2106.04554">paper</a>]</p>
  </li>
  <li>
    <p><strong>Pre-Trained Models: Past, Present and Future</strong>.
<em>Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Liang Zhang, Wentao Han, Minlie Huang, Qin Jin, Yanyan Lan, Yang Liu, Zhiyuan Liu, Zhiwu Lu, Xipeng Qiu, Ruihua Song, Jie Tang, Ji-Rong Wen, Jinhui Yuan, Wayne Xin Zhao, Jun Zhu</em>. arXiv 2021. [<a href="https://arxiv.org/abs/2106.07139">paper</a>]</p>
  </li>
  <li>
    <p><strong>Pre-trained models for natural language processing: A survey</strong>.
<em>XiPeng Qiu, TianXiang Sun, YiGe Xu, YunFan Shao, Ning Dai, XuanJing Huang</em>. Science China Technological Sciences 2020. [<a href="https://link.springer.com/content/pdf/10.1007/s11431-020-1647-3.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Efficient Transformers: A Survey</strong>.
<em>Yi Tay, Mostafa Dehghani, Dara Bahri, Donald Metzler</em>. arXiv 2020. [<a href="https://arxiv.org/pdf/2009.06732">paper</a>]</p>
  </li>
</ol>

<h3 id="83-graph-neural-networks">8.3 Graph Neural Networks</h3>

<ol>
  <li>
    <p><strong>Graph Neural Networks for Natural Language Processing: A Survey</strong>.
<em>Lingfei Wu, Yu Chen, Kai Shen, Xiaojie Guo, Hanning Gao, Shucheng Li, Jian Pei, Bo Long</em>. arXiv 2021. [<a href="https://arxiv.org/pdf/2106.04554">paper</a>]</p>
  </li>
  <li>
    <p><strong>Robustness of Deep Learning Models on Graphs: A Survey</strong>.
<em>Jiarong Xu, Junru Chen, Siqi You, Zhiqing Xiao, Yang Yang, Jiangang Lu</em>. AI Open 2021. [<a href="https://pdf.sciencedirectassets.com/777606/1-s2.0-S2666651021X00022/1-s2.0-S2666651021000139/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBEaCXVzLWVhc3QtMSJHMEUCIQDmcB9h7dKn3wvTXbv0mGpCRs2zxb7v0oNAoEYfK65lXAIgWbqRSd0Dcxz1EoKSYxbMQb0Iazt1HZAUteMHhXvc2F0qgwQI%2Bf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAEGgwwNTkwMDM1NDY4NjUiDMMC3gpvzxTpfbscwyrXAzesgUHaJWjNaP29to2qfBQFPC6lwNAHbcRwVgCWfdvccX%2BQi%2BX0hgSkVMDLB3F5nfKwG05JfDE3ZsfVttAZ2djvytUk3%2F8R9UszAqjBWKFeNsuWKK0Ogh3N6acYe7w7bBkMJ9vdFgf%2BjAPnIvsDCX6hmDeZQQe4RokCv1oCM4M01T5%2FTmVzZS2f9AukdAZ%2BvwXH2ATXMB27n9vhN01kTbcci9IK2F2wpbRr2%2Bbuebs1yYHE0SP3EuAsyuDdbSCpZxxB%2BnEGBt%2FBnVm7LHR%2ByHDHgXtY1K7co6oHwM0AQHK8b5IjSd7OjRFnHBYjuOGWe3hCE0N7MixhK7kh4rV1DPb8FgOYxTZgwZ8f0upRvdK9cOGx3aoyxXVGpMO%2B5ScgkXn3i6wDbwX5FLFb%2FbHtBIvEWj1MQ9KbhYzfrc2kTfqTacN9uRxGw8wc8NS%2BsBus9U7oyjvvpgknJ5je7guaCXgotoXmvOdeIlXEywP7XnBzMz1oxvdeIXteNc8k%2Fq9kKLe6EMiGz0dKwu3lSxS0N9jBvDAup8yoT%2BnHE6zWxyGFiOy720aKS%2FH0HS8TFpX648TTjG2Kv6bcE9%2FHsHD9Fea3ydeGLRscRAx02asRcerDARdGjCuzWzC91biHBjqlAenPBD5BQFVYcnENsDGaZCqFDGVju%2BLTSvkglhMraDbXEKEGNiOMcDNt321b%2FEbsNFjB7r7sfJYAp8PizoFiR9mVds2oM2KQYW5YKrq252dWYS7SP%2BNi6nvnmKRBBLs%2F4r59bk3SHemKj%2FxbLucRMzd9qB9mPSIzzfOudBeACQ%2BEHQ1Fmc6CaY109NGRayIkfOtE6iM0XOW%2BQX07crvRWo%2FHlw%2F%2FvQ%3D%3D&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20210714T020215Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTYV7YMI542%2F20210714%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=dcaf351d4a7f1c1818f4d436fd3c522460839dd98c69809aecf7466c4c9debed&amp;hash=c51537b014f1d20d25cd8553fa5586fab12f731df76eee3dabbcc0b342f0048a&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S2666651021000139&amp;tid=spdf-90eddceb-73c9-4b80-878d-65985d4a175a&amp;sid=80948377662c7948732be96-54885b4a3c51gxrqa&amp;type=client">paper</a>]</p>
  </li>
  <li>
    <p><strong>Graph Neural Networks: A Review of Methods and Applications</strong>.
<em>Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, Maosong Sun</em>. AI Open 2020. [<a href="https://www.sciencedirect.com/science/article/pii/S2666651021000012">paper</a>]</p>
  </li>
  <li>
    <p><strong>A Comprehensive Survey on Graph Neural Networks</strong>.
<em>Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu</em>. TNNLS 2020. [<a href="https://arxiv.org/pdf/1901.00596.pdf">paper</a>]</p>
  </li>
</ol>

<h3 id="84-reinforcement-learning">8.4 Reinforcement Learning</h3>

<ol>
  <li><strong>A Survey of Reinforcement Learning Informed by Natural Language</strong>.
<em>Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktäschel</em>. IJCAI 2019. [<a href="https://arxiv.org/pdf/1906.03926">paper</a>]</li>
</ol>

<h3 id="85-data-augmentation">8.5 Data Augmentation</h3>

<ol>
  <li>
    <p><strong>A Survey of Data Augmentation Approaches for NLP</strong>.
 <em>Steven Y. Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, Eduard Hovy</em>. ACL Findings 2021. [<a href="https://arxiv.org/pdf/2105.03075">paper</a>]</p>
  </li>
  <li>
    <p><strong>An Empirical Survey of Data Augmentation for Limited Data Learning in NLP</strong>. 
 <em>Jiaao Chen, Derek Tam, Colin Raffel, Mohit Bansal, Diyi Yang</em>. arXiv 2021. [<a href="https://arxiv.org/pdf/2106.07499">paper</a>]</p>
  </li>
</ol>

<h3 id="86-few-and-zero-shot-learning">8.6 Few and Zero Shot Learning</h3>

<ol>
  <li>
    <p><strong>A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios</strong>.
<em>Michael A. Hedderich, Lukas Lange, Heike Adel, Jannik Strötgen, Dietrich Klakow</em>. NAACL 2021. [<a href="https://aclanthology.org/2021.naacl-main.201.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>A Survey of Zero-Shot Learning: Settings, Methods, and Applications</strong>.
<em>Wei Wang, Vincent W. Zheng, Han Yu, Chunyan Miao</em>. ACM TIST 2019. [<a href="https://www.ntulily.org/wp-content/uploads/journal/A_Survey_of_Zero-Shot_Learning_Settings_Methods_and_Applications_accepted.pdf">paper</a>]</p>
  </li>
</ol>

<h3 id="87-meta-learning">8.7 Meta Learning</h3>

<ol>
  <li>
    <p><strong>Meta-learning in Neural Networks: A Survey</strong>.
<em>Timothy Hospedales, Antreas Antoniou, Paul Micaelli, Amos Storkey</em>. PAMI 2020. [<a href="https://arxiv.org/pdf/2004.05439">paper</a>]</p>
  </li>
  <li>
    <p><strong>A Survey of Deep Meta‐learning</strong>. <em>Mike Huisman, Jan N. van Rijn, Aske Plaat</em>. AIR 2021. [<a href="https://link.springer.com/content/pdf/10.1007/s10462-021-10004-4.pdf">paper</a>]</p>
  </li>
</ol>

<h3 id="88-continual-learning">8.8 Continual Learning</h3>

<ol>
  <li><strong>A Continual Learning Survey: Defying Forgetting in Classification Tasks</strong>.
<em>Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Greg Slabaugh, Tinne Tuytelaars</em>. PAMI 2021. [<a href="https://arxiv.org/pdf/1909.08383">paper</a>]</li>
</ol>

<h3 id="89-contrastive-learning">8.9 Contrastive Learning</h3>

<ol>
  <li><strong>A Survey on Contrastive Self-Supervised Learning</strong>. <em>Ashish Jaiswal, Ashwin Ramesh Babu, Mohammad Zaki Zadeh, Debapriya Banerjee, Fillia Makedon</em>. Technologies 2021. [<a href="https://www.mdpi.com/2227-7080/9/1/2/pdf">paper</a>]</li>
</ol>

<h3 id="810-multi-task-learning">8.10 Multi-Task Learning</h3>

<ol>
  <li>
    <p><strong>Multi-task learning for natural language processing in the 2020s: Where are we going?</strong>
<em>Joseph Worsham, Jugal Kalita</em>. Pattern Recognition Letters 2020. [<a href="https://arxiv.org/pdf/2007.16008">paper</a>]</p>
  </li>
  <li>
    <p><strong>An Overview of Multi-Task Learning in Deep Neural Networks</strong>.
<em>Sebastian Ruder</em>. arXiv 2017. [<a href="https://arxiv.org/pdf/1706.05098">paper</a>]</p>
  </li>
</ol>

<h3 id="811-intepretability-and-analysis">8.11 Intepretability and Analysis</h3>

<ol>
  <li>
    <p><strong>On Interpretability of Artificial Neural Networks: A Survey</strong>.
<em>Feng-Lei Fan, Jinjun Xiong, Mengzhou Li, Ge Wang</em>. TRPMS 2021. [<a href="https://arxiv.org/pdf/2001.02522">paper</a>]</p>
  </li>
  <li>
    <p><strong>A Survey of the State of Explainable AI for Natural Language Processing</strong>.
<em>Marina Danilevsky, Kun Qian, Ranit Aharonov, Yannis Katsis, Ban Kawas, Prithviraj Sen</em>. AACL 2020. [<a href="https://arxiv.org/pdf/2010.00711">paper</a>].</p>
  </li>
  <li>
    <p><strong>Machine Learning Interpretability: A Survey on Methods and Metrics</strong>.
<em>Diogo V. Carvalho, Eduardo M. Pereira, Jaime S. Cardoso</em>. Electronics 2019. [<a href="https://www.mdpi.com/2079-9292/8/8/832/pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Analysis Methods in Neural Language Processing: A Survey</strong>.
<em>Yonatan Belinkov, James Glass</em>. TACL 2019. [<a href="https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00254/1923061/tacl_a_00254.pdf">paper</a>]</p>
  </li>
  <li>
    <p><strong>Teach Me to Explain: A Review of Datasets for Explainable NLP</strong>. 
 <em>Sarah Wiegreffe, Ana Marasović</em>. arXiv 2021. [<a href="https://arxiv.org/pdf/2102.12060">paper</a>]</p>
  </li>
</ol>

<h3 id="812-security-threats-and-defense">8.12 Security Threats and Defense</h3>

<ol>
  <li>
    <p><strong>Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey</strong>. 
<em>Wei Emma Zhang, Quan Z. Sheng, Ahoud Alhazmi, Chenliang Li</em>. ACM TIST 2020. [<a href="https://dl.acm.org/doi/pdf/10.1145/3374217">paper</a>]</p>
  </li>
  <li>
    <p><strong>Backdoor Learning: A Survey</strong>.
<em>Yiming Li, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shu-Tao Xia</em>. arXiv 2020. [<a href="https://arxiv.org/pdf/2007.08745.pdf">paper</a>].</p>
  </li>
  <li>
    <p><strong>A Survey of Privacy Attacks in Machine Learning</strong>.
<em>Maria Rigaki, Sebastian Garcia</em>. arXiv 2020. [<a href="https://arxiv.org/pdf/2007.07646">paper</a>]</p>
  </li>
</ol>

<h2 id="9-natural-language-processing-applications">9. Natural language Processing Applications</h2>

<h3 id="91-legal-intelligence">9.1 Legal Intelligence</h3>

<ol>
  <li><strong>How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence</strong>.
<em>Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun</em>. ACL 2020. [<a href="https://arxiv.org/pdf/2004.12158">paper</a>]</li>
</ol>

<h3 id="92-bioinformatics">9.2 Bioinformatics</h3>

<ol>
  <li><strong>Survey of Natural Language Processing Techniques in Bioinformatics</strong>.
<em>Zhiqiang Zeng, Hua Shi, Yun Wu, Zhiling Hong</em>. CMMM 2015. [<a href="https://pdfs.semanticscholar.org/7013/479be7dda124750aa22fb6231eea2671f630.pdf">paper</a>].</li>
</ol>

<h3 id="93-financial-intelligence">9.3 Financial Intelligence</h3>

<ol>
  <li><strong>Natural Language Based Financial Forecasting: A Survey</strong>.
<em>Frank Z. Xing, Erik Cambria, Roy E. Welsch</em>. AIR 2018. [<a href="https://dspace.mit.edu/bitstream/handle/1721.1/116314/10462_2017_9588_ReferencePDF.pdf?sequence=2&amp;isAllowed=y">paper</a>].</li>
</ol>

<h3 id="94-recommendation">9.4 Recommendation</h3>

<ol>
  <li><strong>Knowledge Transfer via Pre-training for Recommendation: A Review and Prospect</strong>.
<em>Zheni Zeng, Chaojun Xiao, Yuan Yao, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin, Maosong Sun</em>. Frontiers in Big Data 2021. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8013982/">paper</a>].</li>
</ol>

<h3 id="95-computational-social-science">9.5 Computational Social Science</h3>

<ol>
  <li><strong>From Symbols to Embeddings: A Tale of Two Representations in Computational Social Science</strong>.
<em>Huimin Chen, Cheng Yang, Xuanming Zhang, Zhiyuan Liu, Maosong Sun, Jianbin Jin</em>. arXiv 2021. [<a href="https://arxiv.org/pdf/2106.14198">paper</a>].</li>
</ol>]]></content><author><name>zhao</name></author><category term="NLP" /><category term="nlp" /><category term="paper" /><summary type="html"><![CDATA[0. Surveys of Natural Language Processing]]></summary></entry><entry><title type="html">Triển khai seq2seq với Pytorch</title><link href="https://zhaospei.github.io//nlp/2023/10/06/seq2seq-pytorch/" rel="alternate" type="text/html" title="Triển khai seq2seq với Pytorch" /><published>2023-10-06T00:00:00+07:00</published><updated>2023-10-06T00:00:00+07:00</updated><id>https://zhaospei.github.io//nlp/2023/10/06/seq2seq-pytorch</id><content type="html" xml:base="https://zhaospei.github.io//nlp/2023/10/06/seq2seq-pytorch/"><![CDATA[<p>Bài viết này giới thiệu cách sử dụng <code class="language-plaintext highlighter-rouge">Pytorch</code> để xây dựng mô hình seq2seq và triển khai một ứng dụng dịch máy đơn giản, vui lòng đọc sơ qua bài báo sau trước, <a href="https://arxiv.org/pdf/1406.1078.pdf">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation(2014)</a>, để hiểu rõ cấu trúc seq2seq hoạt động như thế nào, sau đó đọc bài viết này để đạt được hiệu quả gấp đôi chỉ với một nửa công sức.</p>

<p>Tôi đã thấy rất nhiều sơ đồ cấu trúc mạng seq2seq và tôi cảm thấy sơ đồ này do Pytorch cung cấp là dễ hiểu nhất.</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/seq2seq.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<p>Trước hết, từ hình trên ta có thể thấy rõ ràng, seq2seq cần hoạt động trên ba “biến”, khác với tất cả các cấu trúc mạng mà tôi đã tiếp xúc trước đây. Chúng ta gọi đầu vào cho Encoder là <code class="language-plaintext highlighter-rouge">enc_input</code>, đầu vào cho Decoder là <code class="language-plaintext highlighter-rouge">dec_input</code> và đầu ra của Decoder là <code class="language-plaintext highlighter-rouge">dec_output</code>. Phần sau đây sử dụng một ví dụ cụ thể để minh họa cho toàn bộ quy trình thực hiện của seq2seq.</p>

<p>Hình bên dưới là cấu trúc Encoder cấu tạo từ LTSM, đầu vào là từng chữ cái (bao gồm cả dấu cách) trong “go away”, chúng ta cần thông tin của <code class="language-plaintext highlighter-rouge">hidden state</code> ở thời điểm cuối cùng, bao gồm \(h_{t}\) và \(c_{t}\).</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/LSTM_Encoder.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<p>Sau đó sử dụng đầu ra gồm \(h_{t}\) và \(c_{t}\) làm đầu vào cho hidden state đầu tiên của Decoder là \(h_{0}, c_{0}\), như hình bên dưới. Đồng thời, lớp đầu vào (<code class="language-plaintext highlighter-rouge">input layer</code>) đầu của Decoder sẽ được nhập một ký tự đại diện cho phần đầu của câu (Do người dùng tự định nghĩa có thể là “&lt;SOS&gt;”, “\t”, “S”, …. đều được chấp nhận. Ở đây, tôi lấy “\t” làm ví dụ), và sau đó nhận đầu ra “m”, và một hidden state mới \(h_{1}\) và \(c_{1}\)</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/gFRVkq.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<p>Sau đó lấy \(h_{1}\), \(c_{1}\) và “m” làm đầu vào, nhận đầu ra là “a”, và một hidden state mới \(h_{2}\) và \(c_{2}\)</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/gFR1B9.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<p>Lặp lại các bước trên cho đến khi ký tự kết thúc của câu cuối cùng được xuất ra (do người dùng xác định, “&lt;EOS&gt;”, “\n”, “E”, … ở đây tôi lấy “\n” làm ví dụ).</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/gFRGA1.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<p>Trong phần Decoder, bạn sẽ có thể có những câu hỏi sau và tôi sẽ trả lời chúng theo hiểu biết cá nhân.</p>

<ul>
  <li>Tôi phài làm như thế nào nếu Decoder không thể dừng lại trong quá trình đào tạo? Tức là ký tự kết thúc của câu không bao giờ được đưa ra.
    <ul>
      <li>Đầu tiên, trong quá trình huấn luyện, <strong>độ dài của câu mà Decoder sẽ xuất ra sẽ được biết</strong>. Giả sử thời điểm hiện tại đã đến ký tự cuối cùng của độ dài câu và dự đoán không phải là ký tự kết thúc thì cũng không sao, chỉ dừng lại ở đây và tính toán tổn thất.</li>
    </ul>
  </li>
  <li>Tôi phải làm như thế nào nếu Decocder không thể dừng lại trong quá trình kiểm tra? Ví dụ, dự đoán là “wasd s w \n sdsw \n …… (tiếp tục sinh từ)”
    <ul>
      <li>Nó sẽ không dừng lại, vì trong quá trình kiểm tra, Decoder cũng có đầu vào, nhưng đầu vào này có rất nhiều placeholder vô nghĩa, chẳng hạn rất nhiều “&lt;pad&gt;”. Vì Decoder phải có đầu ra có độ dài hữu hạn. Khi đó bạn chỉ lấy tất cả các ký tự trước ký tự kết thúc đầu tiên. Ví dụ trên kết quả dự đoán cuối cùng là “wasd s w”.</li>
    </ul>
  </li>
  <li>Mối quan hệ giữa đầu vào và đầu ra của Decoder, tức là <code class="language-plaintext highlighter-rouge">dec_input</code> và <code class="language-plaintext highlighter-rouge">dec_output</code> là gì?
    <ul>
      <li>Trong quá trình huấn luyện, bất kể Decoder sinh ra kí tự nào tại thời điểm hiện tại, Decoder tại thời điểm tiếp theo sẽ nhập theo “kế hoạch” ban đầu. Ví dụ: giả sử <code class="language-plaintext highlighter-rouge">dec_input = "\twasted"</code>, sau khi nhập “\t” lần đầu, Decoder sẽ xuất ra chữ “m”, ghi lại thôi, nó sẽ không ảnh hưởng đến thời điểm tiếp theo khi Decoder tiếp tục nhập chữ “w”.</li>
      <li>Trong quá trình valid và testing, đầu ra của Decoder tại mỗi thời điểm sẽ ảnh hưởng đến đầu vào, vì trong quá trình valid và testing, mạng không thể nhìn thấy kết quả nên chỉ tiến hành theo vòng lặp. Ví dụ, bây giờ tôi muốn dịch từ “wasted” trong tiếng anh sang tiếng “lãng phí” trong tiếng việt. Sau đó, Decoder bắt đầu với việc nhập ký tự “\t”, nhận kết quả đầu ra nếu là “m”, tại thời điểm tiếp theo, Decoder sẽ nhập “m”, nhận đầu ra, nếu là “a”, sau đó nhận “a” là đầu vào, nhận đầu ra, … và cứ thế cho đến khi gặp kí tự cuối cùng hoặc đạt độ dài tối đa. Mặc dù từ sinh ra không đúng nhưng mong đợi nhưng phải chấp nhận thôi :smiley:.</li>
    </ul>
  </li>
</ul>

<p>Hơi lạc đề một chút, cá nhân tôi nghĩ seq2seq rất giống với AutoEncoder.</p>

<h2 id="hãy-bắt-đầu-giải-thích-mã">Hãy bắt đầu giải thích mã</h2>

<p>Đầu tiên, import thư viện, ở đây tôi dùng ‘S’ làm ký tự bắt đầu và ‘E’ làm ký tự kết thúc, nếu đầu vào hoặc đầu ra quá ngắn, tôi sẽ padding nó bằng ký tự ‘?’.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># code by Tae Hwan Jung(Jeff Jung) @graykode, modify by zhaospei
</span><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.utils.data</span> <span class="k">as</span> <span class="n">Data</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># S: Symbol that shows starting of decoding input
# E: Symbol that shows starting of decoding output
# ?: Symbol that will fill in blank sequence if current batch data size is short than n_step
</span>
</code></pre></div></div>

<p>Xác định tập dữ liệu và các tham số tập dữ liệu ở đây rất đơn giản, có thể coi như một công việc dịch thuật, chỉ là dịch tiếng Anh sang tiếng Anh.
<code class="language-plaintext highlighter-rouge">n_step</code>` là độ dài của từ dài nhất, tất cả các từ khác không đủ dài sẽ được padding bằng ‘?’.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">letter</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="sh">'</span><span class="s">SE?abcdefghijklmnopqrstuvwxyz</span><span class="sh">'</span><span class="p">]</span>
<span class="n">letter2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">letter</span><span class="p">)}</span>

<span class="n">seq_data</span> <span class="o">=</span> <span class="p">[[</span><span class="sh">'</span><span class="s">man</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">women</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">white</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">king</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">queen</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">girl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">boy</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">up</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">down</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">high</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">low</span><span class="sh">'</span><span class="p">]]</span>

<span class="c1"># Seq2Seq Parameter
</span><span class="n">n_step</span> <span class="o">=</span> <span class="nf">max</span><span class="p">([</span><span class="nf">max</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">j</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">seq_data</span><span class="p">])</span> <span class="c1"># max_len(=5)
</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">n_class</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">letter2idx</span><span class="p">)</span> <span class="c1"># classfication problem
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">3</span>
</code></pre></div></div>

<p>Sau đây là xử lý dữ liệu, trước tên là xử lý các từ không đủ độ dài, sử dụng ký tự ‘?’ để padding; Sau đó thêm flag kết thúc ‘E’ vào cuối dữ liệu đầu vào của Encoder, thêm flag bắt đầu ‘S’ vào đầu dữ liệu đầu vào của Decoder và flag kết thúc ‘E’ vào cuối dữ liệu đầu ra của Decoder. Xem hình phía dưới để hiểu rõ hơn.</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/gFRU1O.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">seq_data</span><span class="p">):</span>
    <span class="n">enc_input_all</span><span class="p">,</span> <span class="n">dec_input_all</span><span class="p">,</span> <span class="n">dec_output_all</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">seq_data</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">seq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">seq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s">?</span><span class="sh">'</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_step</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="c1"># 'man??', 'women'
</span>
        <span class="n">enc_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">letter2idx</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="p">)]</span> <span class="c1"># ['m', 'a', 'n', '?', '?', 'E']
</span>        <span class="n">dec_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">letter2idx</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="sh">'</span><span class="s">S</span><span class="sh">'</span> <span class="o">+</span> <span class="n">seq</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="c1"># ['S', 'w', 'o', 'm', 'e', 'n']
</span>        <span class="n">dec_output</span> <span class="o">=</span> <span class="p">[</span><span class="n">letter2idx</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="p">)]</span> <span class="c1"># ['w', 'o', 'm', 'e', 'n', 'E']
</span>
        <span class="n">enc_input_all</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">n_class</span><span class="p">)[</span><span class="n">enc_input</span><span class="p">])</span>
        <span class="n">dec_input_all</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">n_class</span><span class="p">)[</span><span class="n">dec_input</span><span class="p">])</span>
        <span class="n">dec_output_all</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dec_output</span><span class="p">)</span> <span class="c1"># not one-hot
</span>
    <span class="c1"># make tensor
</span>    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">(</span><span class="n">enc_input_all</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">(</span><span class="n">dec_input_all</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nc">LongTensor</span><span class="p">(</span><span class="n">dec_output_all</span><span class="p">)</span>

<span class="sh">'''</span><span class="s">
enc_input_all: [6, n_step+1 (because of </span><span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="s">), n_class]
dec_input_all: [6, n_step+1 (because of </span><span class="sh">'</span><span class="s">S</span><span class="sh">'</span><span class="s">), n_class]
dec_output_all: [6, n_step+1 (because of </span><span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="s">)]
</span><span class="sh">'''</span>
<span class="n">enc_input_all</span><span class="p">,</span> <span class="n">dec_input_all</span><span class="p">,</span> <span class="n">dec_output_all</span> <span class="o">=</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">seq_data</span><span class="p">)</span>
</code></pre></div></div>

<p>Ví có ba dữ liệu trả về ở đây, vì vậy cần tùy chỉnh Dataset, cụ thể là kế thừa lớp <code class="language-plaintext highlighter-rouge">torch.utils.data.Dataset</code>, sau đó triển khai các phương thức <code class="language-plaintext highlighter-rouge">__len__</code> và <code class="language-plaintext highlighter-rouge">__getitem__</code> bên trong.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TranslateDataSet</span><span class="p">(</span><span class="n">Data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">enc_input_all</span><span class="p">,</span> <span class="n">dec_input_all</span><span class="p">,</span> <span class="n">dec_output_all</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">enc_input_all</span> <span class="o">=</span> <span class="n">enc_input_all</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dec_input_all</span> <span class="o">=</span> <span class="n">dec_input_all</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dec_output_all</span> <span class="o">=</span> <span class="n">dec_output_all</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span> <span class="c1"># return dataset size
</span>        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">enc_input_all</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">enc_input_all</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">dec_input_all</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">dec_output_all</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">Data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="nc">TranslateDataSet</span><span class="p">(</span><span class="n">enc_input_all</span><span class="p">,</span> <span class="n">dec_input_all</span><span class="p">,</span> <span class="n">dec_output_all</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>Xác định mô hình seq2seq bên dưới, tôi sử dụng RNN đơn giản làm Encoder và Decoder. Nếu bạn đã quen thuộc với RNN thì thực sự không có gì phải nói về việc xác định cấu trúc mạng, tôi cũng đã viết nhận xét rất rõ ràng, bao gồm cả những thay đổi về kích thước dữ liệu.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model
</span><span class="k">class</span> <span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Seq2Seq</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">n_class</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1"># encoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">n_class</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1"># decoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_class</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">enc_input</span><span class="p">,</span> <span class="n">enc_hidden</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">):</span>
        <span class="c1"># enc_input(=input_batch): [batch_size, n_step+1, n_class]
</span>        <span class="c1"># dec_inpu(=output_batch): [batch_size, n_step+1, n_class]
</span>        <span class="n">enc_input</span> <span class="o">=</span> <span class="n">enc_input</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># enc_input: [n_step+1, batch_size, n_class]
</span>        <span class="n">dec_input</span> <span class="o">=</span> <span class="n">dec_input</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># dec_input: [n_step+1, batch_size, n_class]
</span>
        <span class="c1"># h_t : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]
</span>        <span class="n">_</span><span class="p">,</span> <span class="n">h_t</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">enc_input</span><span class="p">,</span> <span class="n">enc_hidden</span><span class="p">)</span>
        <span class="c1"># outputs : [n_step+1, batch_size, num_directions(=1) * n_hidden(=128)]
</span>        <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">decoder</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">h_t</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="c1"># model : [n_step+1, batch_size, n_class]
</span>        <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Seq2Seq</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</code></pre></div></div>

<p>Sau đây là phần training. Vì giá trị đầu ra là dữ liệu ba chiều nên việc tính toán loss đòi hỏi phải tính toán từng mẫu riêng biệt, do đó có mã vòng for sau đây.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">enc_input_batch</span><span class="p">,</span> <span class="n">dec_input_batch</span><span class="p">,</span> <span class="n">dec_output_batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
      <span class="c1"># make hidden shape [num_layers * num_directions, batch_size, n_hidden]
</span>      <span class="n">h_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

      <span class="p">(</span><span class="n">enc_input_batch</span><span class="p">,</span> <span class="n">dec_intput_batch</span><span class="p">,</span> <span class="n">dec_output_batch</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">enc_input_batch</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_input_batch</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_output_batch</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
      <span class="c1"># enc_input_batch : [batch_size, n_step+1, n_class]
</span>      <span class="c1"># dec_intput_batch : [batch_size, n_step+1, n_class]
</span>      <span class="c1"># dec_output_batch : [batch_size, n_step+1], not one-hot
</span>      <span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">enc_input_batch</span><span class="p">,</span> <span class="n">h_0</span><span class="p">,</span> <span class="n">dec_intput_batch</span><span class="p">)</span>
      <span class="c1"># pred : [n_step+1, batch_size, n_class]
</span>      <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># [batch_size, n_step+1(=6), n_class]
</span>      <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">dec_output_batch</span><span class="p">)):</span>
          <span class="c1"># pred[i] : [n_step+1, n_class]
</span>          <span class="c1"># dec_output_batch[i] : [n_step+1]
</span>          <span class="n">loss</span> <span class="o">+=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dec_output_batch</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="nf">if </span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
          <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch:</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">%04d</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="sh">'</span><span class="s">cost =</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">{:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
          
      <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div>
<p>Như có thể thấy từ mã testing bên dưới, trong quá trình testing, đầu vào của Decoder là một phần giữ chỗ vô nghĩa và độ dài của vị trí bị chiếm giữ là độ dài tối đa <code class="language-plaintext highlighter-rouge">n_step</code>. Và tìm vị trí của dấu kết thúc đầu tiên ở đầu ra, chặn tất cả các ký tự trước nó.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Test
</span><span class="k">def</span> <span class="nf">translate</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
    <span class="n">enc_input</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">make_data</span><span class="p">([[</span><span class="n">word</span><span class="p">,</span> <span class="sh">'</span><span class="s">?</span><span class="sh">'</span> <span class="o">*</span> <span class="n">n_step</span><span class="p">]])</span>
    <span class="n">enc_input</span><span class="p">,</span> <span class="n">dec_input</span> <span class="o">=</span> <span class="n">enc_input</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_input</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># make hidden shape [num_layers * num_directions, batch_size, n_hidden]
</span>    <span class="n">hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">enc_input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>
    <span class="c1"># output : [n_step+1, batch_size, n_class]
</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># select n_class dimension
</span>    <span class="n">decoded</span> <span class="o">=</span> <span class="p">[</span><span class="n">letter</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">predict</span><span class="p">]</span>
    <span class="n">translated</span> <span class="o">=</span> <span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">decoded</span><span class="p">[:</span><span class="n">decoded</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="p">)])</span>

    <span class="k">return</span> <span class="n">translated</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">?</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">man -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">man</span><span class="sh">'</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">mans -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">mans</span><span class="sh">'</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">king -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">king</span><span class="sh">'</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">black -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">up -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">up</span><span class="sh">'</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="mã-hoàn-chỉnh-như-sau">Mã hoàn chỉnh như sau</h2>

<p>Phần thực thi bạn có thể xem tại notebook trên kaggle tại <a href="https://www.kaggle.com/code/overvisual/seq2seq-torch?scriptVersionId=145596925">https://www.kaggle.com/code/overvisual/seq2seq-torch?scriptVersionId=145596925</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># code by Tae Hwan Jung(Jeff Jung) @graykode, modify by zhaospei
</span><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.utils.data</span> <span class="k">as</span> <span class="n">Data</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># S: Symbol that shows starting of decoding input
# E: Symbol that shows starting of decoding output
# ?: Symbol that will fill in blank sequence if current batch data size is short than n_step
</span>
<span class="n">letter</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="sh">'</span><span class="s">SE?abcdefghijklmnopqrstuvwxyz</span><span class="sh">'</span><span class="p">]</span>
<span class="n">letter2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">letter</span><span class="p">)}</span>

<span class="n">seq_data</span> <span class="o">=</span> <span class="p">[[</span><span class="sh">'</span><span class="s">man</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">women</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">white</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">king</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">queen</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">girl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">boy</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">up</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">down</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">high</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">low</span><span class="sh">'</span><span class="p">]]</span>

<span class="c1"># Seq2Seq Parameter
</span><span class="n">n_step</span> <span class="o">=</span> <span class="nf">max</span><span class="p">([</span><span class="nf">max</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">j</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">seq_data</span><span class="p">])</span> <span class="c1"># max_len(=5)
</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">n_class</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">letter2idx</span><span class="p">)</span> <span class="c1"># classfication problem
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">seq_data</span><span class="p">):</span>
    <span class="n">enc_input_all</span><span class="p">,</span> <span class="n">dec_input_all</span><span class="p">,</span> <span class="n">dec_output_all</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">seq_data</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">seq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">seq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s">?</span><span class="sh">'</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_step</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="c1"># 'man??', 'women'
</span>
        <span class="n">enc_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">letter2idx</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="p">)]</span> <span class="c1"># ['m', 'a', 'n', '?', '?', 'E']
</span>        <span class="n">dec_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">letter2idx</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="sh">'</span><span class="s">S</span><span class="sh">'</span> <span class="o">+</span> <span class="n">seq</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="c1"># ['S', 'w', 'o', 'm', 'e', 'n']
</span>        <span class="n">dec_output</span> <span class="o">=</span> <span class="p">[</span><span class="n">letter2idx</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="p">)]</span> <span class="c1"># ['w', 'o', 'm', 'e', 'n', 'E']
</span>
        <span class="n">enc_input_all</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">n_class</span><span class="p">)[</span><span class="n">enc_input</span><span class="p">])</span>
        <span class="n">dec_input_all</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">n_class</span><span class="p">)[</span><span class="n">dec_input</span><span class="p">])</span>
        <span class="n">dec_output_all</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dec_output</span><span class="p">)</span> <span class="c1"># not one-hot
</span>
    <span class="c1"># make tensor
</span>    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">(</span><span class="n">enc_input_all</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">(</span><span class="n">dec_input_all</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nc">LongTensor</span><span class="p">(</span><span class="n">dec_output_all</span><span class="p">)</span>

<span class="sh">'''</span><span class="s">
enc_input_all: [6, n_step+1 (because of </span><span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="s">), n_class]
dec_input_all: [6, n_step+1 (because of </span><span class="sh">'</span><span class="s">S</span><span class="sh">'</span><span class="s">), n_class]
dec_output_all: [6, n_step+1 (because of </span><span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="s">)]
</span><span class="sh">'''</span>
<span class="n">enc_input_all</span><span class="p">,</span> <span class="n">dec_input_all</span><span class="p">,</span> <span class="n">dec_output_all</span> <span class="o">=</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">seq_data</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">TranslateDataSet</span><span class="p">(</span><span class="n">Data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">enc_input_all</span><span class="p">,</span> <span class="n">dec_input_all</span><span class="p">,</span> <span class="n">dec_output_all</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">enc_input_all</span> <span class="o">=</span> <span class="n">enc_input_all</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dec_input_all</span> <span class="o">=</span> <span class="n">dec_input_all</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dec_output_all</span> <span class="o">=</span> <span class="n">dec_output_all</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span> <span class="c1"># return dataset size
</span>        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">enc_input_all</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">enc_input_all</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">dec_input_all</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">dec_output_all</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">Data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="nc">TranslateDataSet</span><span class="p">(</span><span class="n">enc_input_all</span><span class="p">,</span> <span class="n">dec_input_all</span><span class="p">,</span> <span class="n">dec_output_all</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>

<span class="c1"># Model
</span><span class="k">class</span> <span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Seq2Seq</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">n_class</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1"># encoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">n_class</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1"># decoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_class</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">enc_input</span><span class="p">,</span> <span class="n">enc_hidden</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">):</span>
        <span class="c1"># enc_input(=input_batch): [batch_size, n_step+1, n_class]
</span>        <span class="c1"># dec_inpu(=output_batch): [batch_size, n_step+1, n_class]
</span>        <span class="n">enc_input</span> <span class="o">=</span> <span class="n">enc_input</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># enc_input: [n_step+1, batch_size, n_class]
</span>        <span class="n">dec_input</span> <span class="o">=</span> <span class="n">dec_input</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># dec_input: [n_step+1, batch_size, n_class]
</span>
        <span class="c1"># h_t : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]
</span>        <span class="n">_</span><span class="p">,</span> <span class="n">h_t</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">enc_input</span><span class="p">,</span> <span class="n">enc_hidden</span><span class="p">)</span>
        <span class="c1"># outputs : [n_step+1, batch_size, num_directions(=1) * n_hidden(=128)]
</span>        <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">decoder</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">h_t</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="c1"># model : [n_step+1, batch_size, n_class]
</span>        <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Seq2Seq</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">enc_input_batch</span><span class="p">,</span> <span class="n">dec_input_batch</span><span class="p">,</span> <span class="n">dec_output_batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
      <span class="c1"># make hidden shape [num_layers * num_directions, batch_size, n_hidden]
</span>      <span class="n">h_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

      <span class="p">(</span><span class="n">enc_input_batch</span><span class="p">,</span> <span class="n">dec_intput_batch</span><span class="p">,</span> <span class="n">dec_output_batch</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">enc_input_batch</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_input_batch</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_output_batch</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
      <span class="c1"># enc_input_batch : [batch_size, n_step+1, n_class]
</span>      <span class="c1"># dec_intput_batch : [batch_size, n_step+1, n_class]
</span>      <span class="c1"># dec_output_batch : [batch_size, n_step+1], not one-hot
</span>      <span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">enc_input_batch</span><span class="p">,</span> <span class="n">h_0</span><span class="p">,</span> <span class="n">dec_intput_batch</span><span class="p">)</span>
      <span class="c1"># pred : [n_step+1, batch_size, n_class]
</span>      <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># [batch_size, n_step+1(=6), n_class]
</span>      <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">dec_output_batch</span><span class="p">)):</span>
          <span class="c1"># pred[i] : [n_step+1, n_class]
</span>          <span class="c1"># dec_output_batch[i] : [n_step+1]
</span>          <span class="n">loss</span> <span class="o">+=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dec_output_batch</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="nf">if </span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
          <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch:</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">%04d</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="sh">'</span><span class="s">cost =</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">{:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
          
      <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    
<span class="c1"># Test
</span><span class="k">def</span> <span class="nf">translate</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
    <span class="n">enc_input</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">make_data</span><span class="p">([[</span><span class="n">word</span><span class="p">,</span> <span class="sh">'</span><span class="s">?</span><span class="sh">'</span> <span class="o">*</span> <span class="n">n_step</span><span class="p">]])</span>
    <span class="n">enc_input</span><span class="p">,</span> <span class="n">dec_input</span> <span class="o">=</span> <span class="n">enc_input</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_input</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># make hidden shape [num_layers * num_directions, batch_size, n_hidden]
</span>    <span class="n">hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">enc_input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>
    <span class="c1"># output : [n_step+1, batch_size, n_class]
</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># select n_class dimension
</span>    <span class="n">decoded</span> <span class="o">=</span> <span class="p">[</span><span class="n">letter</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">predict</span><span class="p">]</span>
    <span class="n">translated</span> <span class="o">=</span> <span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">decoded</span><span class="p">[:</span><span class="n">decoded</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="p">)])</span>

    <span class="k">return</span> <span class="n">translated</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">?</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">man -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">man</span><span class="sh">'</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">mans -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">mans</span><span class="sh">'</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">king -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">king</span><span class="sh">'</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">black -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">up -&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="nf">translate</span><span class="p">(</span><span class="sh">'</span><span class="s">up</span><span class="sh">'</span><span class="p">))</span>
</code></pre></div></div>

<h1 id="tham-khảo">Tham khảo</h1>

<p>[1] <a href="https://www.kaggle.com/code/overvisual/seq2seq-torch?scriptVersionId=145596925">https://www.kaggle.com/code/overvisual/seq2seq-torch?scriptVersionId=145596925</a></p>]]></content><author><name>zhao</name></author><category term="NLP" /><category term="nlp" /><category term="pytorch" /><category term="model" /><summary type="html"><![CDATA[Bài viết này giới thiệu cách sử dụng Pytorch để xây dựng mô hình seq2seq và triển khai một ứng dụng dịch máy đơn giản, vui lòng đọc sơ qua bài báo sau trước, Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation(2014), để hiểu rõ cấu trúc seq2seq hoạt động như thế nào, sau đó đọc bài viết này để đạt được hiệu quả gấp đôi chỉ với một nửa công sức.]]></summary></entry><entry><title type="html">[NLP] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title><link href="https://zhaospei.github.io//nlp/2023/10/05/bert-pretrained-model/" rel="alternate" type="text/html" title="[NLP] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" /><published>2023-10-05T00:00:00+07:00</published><updated>2023-10-05T00:00:00+07:00</updated><id>https://zhaospei.github.io//nlp/2023/10/05/bert-pretrained-model</id><content type="html" xml:base="https://zhaospei.github.io//nlp/2023/10/05/bert-pretrained-model/"><![CDATA[<p>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</p>

<h2 id="tiêu-đề">Tiêu đề</h2>
<p><code class="language-plaintext highlighter-rouge">Pre-training (Đào tạo trước)</code>: Nếu một mô hình được đào tạo trên một tập dữ liệu lớn nhưng mục đích chính là sử dụng cho nhiệm vụ khác (được gọi là <code class="language-plaintext highlighter-rouge">Training</code>), thì nhiệm vụ đào tạo mô hình đó được gọi là <code class="language-plaintext highlighter-rouge">Pre-training</code>.</p>

<p><code class="language-plaintext highlighter-rouge">Deep</code>: rất dễ hiểu, chỉ là sâu thôi.</p>

<p><code class="language-plaintext highlighter-rouge">Bidirectional</code>: nghĩa là có 2 chiều, được giải thích ở cuối bài viết.</p>

<p><code class="language-plaintext highlighter-rouge">Transformers</code>: Mô hình học sâu được thiết kế dùng để phục vụ giải quyết nhiều bài toán trong xử lý ngôn ngữ tự nhiên và tiếng nói. Vui lòng <a href="">xem thêm</a></p>

<p>Tóm lại, mô hình BERT là một mô hình Transfomers sâu 2 chiều, được sử dụng làm mô hình đào tạo trước để hiểu ngôn ngữ.</p>

<h2 id="abstract">Abstract</h2>
<p>BERT viết tắt của Bidirectional Encoder Representations from Transformers.</p>

<p>Như đã nói ở đoạn đầu, BERT dùng thiết kể để đào tạo sâu, biểu diễn hai chiều, dữ liệu không gán nhãn được sử dụng và thông tin ngữ cảnh song phương trái và phải được kết hợp (Tức context được xác định ở cả hai phía của từ). Do thiết kế tinh tế của BERT, nó chỉ cần thêm một lớp đầu ra bổ sung và thực hiện tinh chỉnh tương ứng, và nó có thể được áp dụng cho nhiểu tác vụ mà không cần thực hiên nhiều sửa đổi đối với các tác vụ cụ thể.</p>

<h2 id="introduction">Introduction</h2>
<p>Đào tạo trước đã trở nên phổ biến trong NLP. Ví dụ, trong bài toán nhận dạng thực thể có tên (<code class="language-plaintext highlighter-rouge">NER</code>), BERT không phải là mô hình đầu tiên được đề xuất, xét cho cùng chúng ta có thể dùng BERT ứng dụng trong <code class="language-plaintext highlighter-rouge">CV - Compution Vision</code>, nhưng BERT ứng dụng tốt nhất trong các bài toán NLP.</p>

<p>Khi sử dụng mô hình đào tạo trước để biểu diễn đặc trưng cho các tác vụ tiếp theo, thường có hai chiến lược, một chiến lược dựa trên các đặc trưng (<code class="language-plaintext highlighter-rouge">feature-based</code>) và chiến lược còn lại dựa trên tinh chỉnh (<code class="language-plaintext highlighter-rouge">fine-tuning</code>). Cả hai phương pháp đều sử dụng cùng một hàm mục tiêu trong quá trình đào tạo trước, đây là mô hình ngôn ngữ một chiều.</p>

<p>Dựa trên tính năng, cách làm tiêu biểu [ELMo], sử dụng kiến trúc RRN, đối với mỗi tác vụ xuôi dòng, xây dựng mạng thần kinh liên quan đến tác vụ hiện tại, biểu diễn đặc trưng được đào tạo trước, như một tính năng bổ sung, đưa nó vào mạng cùng với đầu vào ban đầu.</p>

<p>Dựa trên sự tinh chỉnh, cách làm tiêu biểu [GPT], giảm tham số cho một tác vụ cụ thể, khi đưa các tham số mô hình được huấn luyện trước vào dữ liệu xuôi dòng, tất cả các thông số sẽ được tinh chinh.</p>

<p>Sau đó tác giả thảo luận về những hạn chế của các phương pháp này, đặc biêt với phương pháp tinh chỉnh, do mô hình ngôn ngữ là một chiều nên có một số hạn chế trong việc lựa chọn kiến trúc. Ví dụ: trong GPT sử dụng kiến trúc từ trái sang phải. Theo cách nói của con người, khi đọc một câu, chúng ta chỉ có thể đọc từ trái sang phải. Trong một số nhiệm vụ, chẳng hạn như đánh giá cảm xúc của một câu (QA), … việc đọc từ phải sang trái hay trái sang phải được hợp pháp. Tác giả tin rằng việc đưa thông tin từ cả hai hướng vào cùng một lúc sẽ giúp nâng cao hiệu quả thực hiện.</p>

<p>(Tiếp tục viết trong tương lai xa…)</p>]]></content><author><name>zhao</name></author><category term="NLP" /><category term="nlp" /><category term="paper" /><category term="model" /><summary type="html"><![CDATA[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding]]></summary></entry><entry><title type="html">Bọ là gì? Defect, Fault, Error, Bug, Failure?</title><link href="https://zhaospei.github.io//se/2023/07/02/what-is-bug/" rel="alternate" type="text/html" title="Bọ là gì? Defect, Fault, Error, Bug, Failure?" /><published>2023-07-02T00:00:00+07:00</published><updated>2023-07-02T00:00:00+07:00</updated><id>https://zhaospei.github.io//se/2023/07/02/what-is-bug</id><content type="html" xml:base="https://zhaospei.github.io//se/2023/07/02/what-is-bug/"><![CDATA[<h2 id="người-đọc-tự-chịu-trách-nhiệm-về-tính-xác-thực-của-bài-viết">Người đọc tự chịu trách nhiệm về tính xác thực của bài viết.</h2>

<h1 id="context">Context</h1>
<p>Chuyện là tuần vừa rồi tôi tham gia lab nghiên cứu ở trường và được giao đọc một bài báo khoa học. Nếu không nhầm thì mục đích của thầy khi bảo tôi đọc bài báo này là nắm được sơ qua “context” nghiên cứu của nhóm đang thực hiện.</p>

<p>Do lần đầu tôi được giao đọc một bài báo khoa học (à trước đó có đọc, dịch gì đấy một bài rồi nhưng mà khi chú tâm thực hiện), thì tất nhiên chưa có kinh nghiệm nên là chỉ nghĩ đọc hiểu nghĩa, cái chung chung bài báo đang nói là gì, hiểu cách bài báo đang thực hiện, vân vân mây mây… Và rồi, sau một tuần được giao đọc bài báo thì mình lên gặp thầy trao đổi về hiểu biết của mình về bài báo. À thì mọi việc sẽ chả có gì nếu như cách đọc của mình là đúng.</p>

<p>Nhưng <strong>KHÔNG</strong>, mình đã được khai sáng một đống tri thức mới. Thầy bảo mình không thể hiểu chung chung bài báo nói gì được mà phải nắm rõ và chính xác toàn bộ khái niệm mà bài báo đã đề cập như bài báo mình “được” đọc là <a href="https://ieeexplore.ieee.org/document/4408585?denied=">“Classifying Software Changes: Clean or Buggy?”</a> thì đầu tiên phải đặt câu hỏi <em>Software Changes</em> là gì? <em>Clean, Buggy</em> là gì? (Tất nhiên là trong “context” của bài báo).</p>

<p>Trong một đống thứ thầy nói và hỏi mình thì chắc thứ tồn đọng lại (khắc sâu mình nhất) là câu hỏi (cũng là câu hỏi đầu tiên) là: <strong>“Theo em, bug là gì?”</strong> (Vì tiêu đề bài báo có việc phân loại hai nhãn là Clean và Buggy mà). Lúc đấy, mình kiểu :))). Tại mình nghĩ là thầy sẽ vấn đề và hướng giải quyết của bài báo chứ không phải mấy câu hỏi lí thuyết như này. Và thầy doạ mình là không trả lời được sẽ hạ điểm (tất nhiên là đùa) môn mình kì trước (Do kì trước mình có tham gia lớp kiểm thử của thầy, không hiểu sao thầy vẫn còn nhớ mình :)).</p>

<p>Và một đứa thường bỏ qua những thứ căn bản như mình thì tất nhiên chả bao giờ tìm hiểu định nghĩa nó là gì rồi và khi một từ thông dụng và được dùng rất nhiều trong cộng đồng lập trình như từ “bug” như thế thì mình trả lời đại khái là: <em>“Bug là lỗi phần mềm. Nó xảy ra khi phần mềm thực hiện sai và không đúng mong đợi đã được đề ra ban đầu”.</em> Và thầy nhìn mình, nhìn ánh mắt “trìu mến” mà thầy nhìn mình là mình biết chất lượng trả lời câu hỏi của mình như thế nào rồi. Xong thầy bảo, trong phát triển phần mềm, lỗi phần mềm không chỉ là bug, mà còn có <em>defect</em>, <em>fault</em>, <em>error</em>, <em>failure</em>. Lúc thầy nói mấy từ này mình chả nghe ra đâu (do trình nghe đọc tiếng anh mình hơi kém, thực ra là rất kém) đến lúc thầy viết ra mình và giải thích mình mới có thể hình dung ra những từ này. Và đấy là lí do mình viết bài viết này để “flex” (đùa chứ xem mình hiểu tới đâu và nhờ bạn đọc xác nhận lại giùm mình.).</p>

<h1 id="main">Main</h1>
<p>Thực ra trên mạng có rất nhiều bài viết viết về vấn đề này rồi, bạn chỉ cần hỏi “ông Gu Gồ” là nó ra một đống cho bạn đọc nên là mình không đi sâu vào lắm mà chỉ sơ qua những gì mình hiểu được về nó và phân biệt những khái niệm đã nêu ở phần tiêu đề.</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/bug-vs-defect-vs-error-vs-fault-vs-failure.png" alt="" style="margin: auto;" />
    <figcaption style="font-style: italic;"></figcaption>
</figure>

<p><strong>Defects</strong>, like quality, can be defined in many different ways but are more commonly defined as deviations from specifications or expectations which might lead to <strong>failures</strong> in operation. <em>(Có thể dịch là: Defects, giống như Quality (Chất lượng phần mềm), có thể định nghĩa bằng nhiều cách khách nhau nhưng thường được định nghĩa là sai lệch so với thông số kỹ thuật hoặc mong đợi có thể dẫn đến failures khi vận hành.)</em></p>

<p>A software <strong>failure</strong> is <strong>observable</strong> software misbehavior; however, a <strong>defect</strong> may not always lead to a <strong>failure</strong>. <em>(Có thể dịch là: Failure là hành vi sai trái của phần mềm có thể quan sát được. Tuy nhiên, một defect không phải lúc nào cũng dẫn đến một failure.)</em></p>

<p><strong>Defects</strong> colloquially called <strong>bugs</strong> in software artifacts, typically in the software source code. <em>(Có thể dịch là: Defects thường được gọi (một cách không chính thức) là bugs trong software artifacts (bất kỳ thứ gì tạo ra phần mềm), điển hình là mã nguồn.)</em></p>

<h1 id="exit">Exit</h1>
<p>Bài viết này khoảng một nửa là mình bịa, một nửa còn lại cũng bịa nốt.</p>]]></content><author><name>zhao</name></author><category term="SE" /><category term="Bug" /><category term="Defect" /><category term="Fault" /><category term="Failure" /><summary type="html"><![CDATA[Người đọc tự chịu trách nhiệm về tính xác thực của bài viết.]]></summary></entry><entry><title type="html">Lựa chọn đặc trưng trong học máy bằng kiểm tra Chi-Square</title><link href="https://zhaospei.github.io//machine-learning/2023/06/27/chi-square-feature-selection-ml/" rel="alternate" type="text/html" title="Lựa chọn đặc trưng trong học máy bằng kiểm tra Chi-Square" /><published>2023-06-27T00:00:00+07:00</published><updated>2023-06-27T00:00:00+07:00</updated><id>https://zhaospei.github.io//machine-learning/2023/06/27/chi-square-feature-selection-ml</id><content type="html" xml:base="https://zhaospei.github.io//machine-learning/2023/06/27/chi-square-feature-selection-ml/"><![CDATA[<p>Lựa chọn đặc trưng là một trong những vấn đề quan trọng trong học máy, khi chúng ta có một đống cái đặc trưng và quyết định xem những đặc trưng nào là tốt nhất để xây dựng mô hình.</p>

<p>Có nhiều phương pháp để lựa chọn đặc trưng, trong bài viết này tôi sẽ đưa giải pháp thực hiện bằng <strong>Chi-Square</strong>.</p>

<h1 id="phân-phối-chi-square">Phân phối Chi-Square</h1>
<p>Một biến ngẫu nhiên \(\chi\) tuân theo phân phối chi-square nếu nó có thể viết được viết dưới dạng tổng bình phương các biến chuẩn chuẩn hoá.</p>

\[\chi^{2} = \sum_{}^{}Z_{i}^{2}\]

<p>Trong đó \(Z_{1}, Z_{2}, ...\) là các biến chuẩn chuẩn hoá.</p>

<h1 id="bậc-tự-do-degrees-of-freedom">Bậc tự do (Degrees of freedom)</h1>
<p>Bậc tự do đề cập đến số lượng tối đa các giá trị độc lập logic, có quyền tự do thay đổi. Nói một cách đơn giản, nó có thể được định nghĩa là tổng số mẫu dữ liệu trừ đi số lượng ràng buộc độc lập áp đặt cho các mẫu dữ liệu.</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/Chi-squared-distribution.png" alt="Phân phối Chi-Square" style="margin: auto;" />
    <figcaption style="font-style: italic;">Phân phối Chi-Square</figcaption>
</figure>

<p>Trong hình trên, chúng ta có thể thấy phân phối Chi-Square cho các bậc tự do khác nhau. Chúng ta cũng có thể quan sát thấy rằng khi bậc tự do tăng thì phân phối Chi-Square xấp xỉ với phân phối chuẩn.</p>

<h1 id="kiểm-tra-tính-độc-lập-của-hai-biến-cố-bằng-chi-square">Kiểm tra tính độc lập của hai biến cố bằng Chi-Square</h1>
<p>Chi-Square được sử dụng trong thống kê để kiểm tra tính độc lập của hai sự kiện. Với dữ liệu của hai biến, chúng ta có thể nhận được số lượng thực tế quan sát (observed) \(O\) và số lượng kỳ vọng (expected) \(​​E\). Chi-Square đo lường mức độ chênh lệch của hai đại lượng này.</p>

\[\chi_{c}^{2} = \sum_{}^{}\frac{(O_{i} - E_{i})^{2}}{E_{i}}\]

<p>Trong đó:</p>
<ul>
  <li>\(c\) : Số bậc tự do</li>
  <li>\(O\) : Số lượng thực tế quan sát</li>
  <li>\(E\) : Số lượng kỳ vọng</li>
</ul>

<p>Khi hai sự kiện độc lập, số lượng được quan sát gần với số lượng dự kiến, do đó chúng ta sẽ có giá trị Chi-Square nhỏ hơn. Vì vậy, giá trị Chi-Square cao cho thấy giả thuyết về tính độc lập là không chính xác. Nói một cách đơn giản, giá trị Chi-Square càng cao thì các sự kiện này càng phụ thuộc vào nhau. Hay nếu ta xem một sự kiện là một đặc trưng của mô hình và sự kiện còn lại là phân loại mà mô hình cần dự đoán (Phản hồi). Khi đó nếu giá trị Chi-Square càng cao thì đặc trưng này càng phụ thuộc vào phản hồi và nó có thể được chọn để đào tạo mô hình.</p>

<p>Đối với lựa chọn đặc trưng bằng Chi-Square, chúng ta mong đợi rằng trong tổng số các đặc trưng được chọn có một phần nhỏ trong chúng vẫn độc lập với lớp phân loại. Tuy nhiên, trong phân loại văn bản hiếm khi các đặc trưng này được thêm vào trong tập đặc trưng trích xuất cuối cùng. Tất nhiên là nó vẫn tốt miễn là phương pháp vẫn xếp hàng các đặc trưng theo tính hữu ích của nó đối với mô hình chứ không phải chỉ sử dụng để đưa ra tuyên bố về sự phụ thuộc hay tính độc lập của các biến trong thống kê.</p>

<h2 id="các-bước-thực-hiện-kiểm-tra-chi-square">Các bước thực hiện kiểm tra Chi-Square</h2>

<p>Hãy xem xét một tập dữ liệu mà chúng ta phải xác định lý do tại sao khách hàng rời khỏi ngân hàng, hãy thực hiện kiểm tra Chi-Square cho hai biến. <strong>Giới tính</strong> của khách hàng với các giá trị là <strong>Nam/Nữ</strong> và <strong>Rời khỏi</strong> mô tả liệu khách hàng có rời ngân hàng hay không với các giá trị <strong>Có/Không</strong>. Trong thử nghiệm này, chúng tôi sẽ kiểm tra xem có mối quan hệ nào giữa <strong>Giới tính</strong> và <strong>Rời khỏi</strong>.</p>

<h3 id="1-xác-định-giả-thuyết">1. Xác định giả thuyết</h3>
<p><strong>Giả thuyết rỗng</strong> (\(H_{0}\)): Hai biến đã cho độc lập</p>

<p><strong>Giả thuyết thay thế</strong> (\(H_{1}\)): Hai biến đã cho phụ thuộc nhau</p>

<h3 id="2-xây-dựng-bảng-tương-quan">2. Xây dựng bảng tương quan</h3>
<p>Một bảng hiển thị phân phối của một biến trong hàng và biến khác trong cột. Nó được sử dụng để nghiên cứu mối quan hệ giữa hai biến.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Giới tính</strong> \ <strong>Rời bỏ</strong></td>
      <td><strong>Có</strong></td>
      <td><strong>Không</strong></td>
      <td><strong>Tổng</strong></td>
    </tr>
    <tr>
      <td><strong>Nam</strong></td>
      <td>38</td>
      <td>178</td>
      <td>216</td>
    </tr>
    <tr>
      <td><strong>Nữ</strong></td>
      <td>44</td>
      <td>140</td>
      <td>184</td>
    </tr>
    <tr>
      <td><strong>Tổng</strong></td>
      <td>82</td>
      <td>318</td>
      <td>400</td>
    </tr>
  </tbody>
</table>

<p>Bậc tự do của bảng tương quan được tính bằng công thức: \((r-1) * (c-1)\) trong đó  \(r\), \(c\) là số hàng và số cột. 
Như bảng trên, ta có:</p>

\[df = (2–1) * (2–1) = 1.\]

<p>Trong bảng trên, chúng ta đã tìm ra tất cả các giá trị được quan sát và các bước tiếp theo của chúng tôi là tìm các giá trị kỳ vọng, tính giá trị Chi-Square và kiểm tra mối quan hệ giữa chúng.</p>

<h3 id="3-tìm-giá-trị-kỳ-vọng">3. Tìm giá trị kỳ vọng</h3>
<p>Dựa trên giả thiết rỗng là hai biến đã cho độc lập lẫn nhau. Nếu hai biến A, B là biến cố độc lập ta có:</p>

\[P(A \cap B) = P(A) * P(B)\]

<p>Hãy tính giá trị kỳ vọng cho ô đầu tiên là những người là <strong>Nam</strong> và <strong>Có</strong> rời khỏi ngân hàng.</p>

\[p = p(Yes) * p(Male)\]

\[p = (82/400) * (216/400)\]

\[p = 0.1107\]

\[E_{1} = n * p = 400 * 0.1107 = 44\]

<p>Tương tự, ta tính toán được có giá trị \(E_{2}\),  \(E_{3}\), \(E_{4}\) và được kết quả như bên dưới.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Giới tính</strong> \ <strong>Rời bỏ</strong></td>
      <td><strong>Có</strong></td>
      <td><strong>Không</strong></td>
    </tr>
    <tr>
      <td><strong>Nam</strong></td>
      <td>44</td>
      <td>172</td>
    </tr>
    <tr>
      <td><strong>Nữ</strong></td>
      <td>38</td>
      <td>146</td>
    </tr>
  </tbody>
</table>

<h3 id="4-tính-toán-giá-trị-chi-square">4. Tính toán giá trị Chi-Square</h3>

\[\chi_{c}^{2} = \sum_{}^{}\frac{(O_{i} - E_{i})^{2}}{E_{i}}\]

<p>Sử dụng công thức đã cho ở trên và các giá trị đã tính toán được, ta dễ dàng có giá trị của <strong>Chi-Square</strong> bằng <strong>2.22</strong></p>

<h3 id="5-bác-bỏ-giả-thuyết-rỗng">5. Bác bỏ Giả thuyết rỗng</h3>
<p>Với độ tin cậy \(95\%\) là \(\alpha = 0,05\), chúng ta sẽ kiểm tra xem giá trị <strong>Chi-Square</strong> tính được có nằm trong vùng chấp nhận hay từ chối hay không.</p>

<p>Các giá trị <strong>Chi-Square</strong> chấp thuận có thể xác định bẳng <strong>Bảng Chi-Square</strong>. Bạn đọc có thể tham khảo tại <a href="https://people.richland.edu/james/lecture/m170/tbl-chi.html">https://people.richland.edu/james/lecture/m170/tbl-chi.html</a>. Dưới đây là phần của bảng trên.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">df</th>
      <th style="text-align: right">0.995</th>
      <th style="text-align: right">0.99</th>
      <th style="text-align: right">0.975</th>
      <th style="text-align: right">0.95</th>
      <th style="text-align: right">0.90</th>
      <th style="text-align: right">0.10</th>
      <th style="text-align: right">0.05</th>
      <th style="text-align: right">0.025</th>
      <th style="text-align: right">0.01</th>
      <th style="text-align: right">0.005</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">—</td>
      <td style="text-align: right">—</td>
      <td style="text-align: right">0.001</td>
      <td style="text-align: right">0.004</td>
      <td style="text-align: right">0.016</td>
      <td style="text-align: right">2.706</td>
      <td style="text-align: right">3.841</td>
      <td style="text-align: right">5.024</td>
      <td style="text-align: right">6.635</td>
      <td style="text-align: right">7.879</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">0.010</td>
      <td style="text-align: right">0.020</td>
      <td style="text-align: right">0.051</td>
      <td style="text-align: right">0.103</td>
      <td style="text-align: right">0.211</td>
      <td style="text-align: right">4.605</td>
      <td style="text-align: right">5.991</td>
      <td style="text-align: right">7.378</td>
      <td style="text-align: right">9.210</td>
      <td style="text-align: right">10.597</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">0.072</td>
      <td style="text-align: right">0.115</td>
      <td style="text-align: right">0.216</td>
      <td style="text-align: right">0.352</td>
      <td style="text-align: right">0.584</td>
      <td style="text-align: right">6.251</td>
      <td style="text-align: right">7.815</td>
      <td style="text-align: right">9.348</td>
      <td style="text-align: right">11.345</td>
      <td style="text-align: right">12.838</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">0.207</td>
      <td style="text-align: right">0.297</td>
      <td style="text-align: right">0.484</td>
      <td style="text-align: right">0.711</td>
      <td style="text-align: right">1.064</td>
      <td style="text-align: right">7.779</td>
      <td style="text-align: right">9.488</td>
      <td style="text-align: right">11.143</td>
      <td style="text-align: right">13.277</td>
      <td style="text-align: right">14.860</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: right">0.412</td>
      <td style="text-align: right">0.554</td>
      <td style="text-align: right">0.831</td>
      <td style="text-align: right">1.145</td>
      <td style="text-align: right">1.610</td>
      <td style="text-align: right">9.236</td>
      <td style="text-align: right">11.070</td>
      <td style="text-align: right">12.833</td>
      <td style="text-align: right">15.086</td>
      <td style="text-align: right">16.750</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: right">0.676</td>
      <td style="text-align: right">0.872</td>
      <td style="text-align: right">1.237</td>
      <td style="text-align: right">1.635</td>
      <td style="text-align: right">2.204</td>
      <td style="text-align: right">10.645</td>
      <td style="text-align: right">12.592</td>
      <td style="text-align: right">14.449</td>
      <td style="text-align: right">16.812</td>
      <td style="text-align: right">18.548</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: right">0.989</td>
      <td style="text-align: right">1.239</td>
      <td style="text-align: right">1.690</td>
      <td style="text-align: right">2.167</td>
      <td style="text-align: right">2.833</td>
      <td style="text-align: right">12.017</td>
      <td style="text-align: right">14.067</td>
      <td style="text-align: right">16.013</td>
      <td style="text-align: right">18.475</td>
      <td style="text-align: right">20.278</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: right">1.344</td>
      <td style="text-align: right">1.646</td>
      <td style="text-align: right">2.180</td>
      <td style="text-align: right">2.733</td>
      <td style="text-align: right">3.490</td>
      <td style="text-align: right">13.362</td>
      <td style="text-align: right">15.507</td>
      <td style="text-align: right">17.535</td>
      <td style="text-align: right">20.090</td>
      <td style="text-align: right">21.955</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: right">1.735</td>
      <td style="text-align: right">2.088</td>
      <td style="text-align: right">2.700</td>
      <td style="text-align: right">3.325</td>
      <td style="text-align: right">4.168</td>
      <td style="text-align: right">14.684</td>
      <td style="text-align: right">16.919</td>
      <td style="text-align: right">19.023</td>
      <td style="text-align: right">21.666</td>
      <td style="text-align: right">23.589</td>
    </tr>
    <tr>
      <td style="text-align: right">10</td>
      <td style="text-align: right">2.156</td>
      <td style="text-align: right">2.558</td>
      <td style="text-align: right">3.247</td>
      <td style="text-align: right">3.940</td>
      <td style="text-align: right">4.865</td>
      <td style="text-align: right">15.987</td>
      <td style="text-align: right">18.307</td>
      <td style="text-align: right">20.483</td>
      <td style="text-align: right">23.209</td>
      <td style="text-align: right">25.188</td>
    </tr>
    <tr>
      <td style="text-align: right">11</td>
      <td style="text-align: right">2.603</td>
      <td style="text-align: right">3.053</td>
      <td style="text-align: right">3.816</td>
      <td style="text-align: right">4.575</td>
      <td style="text-align: right">5.578</td>
      <td style="text-align: right">17.275</td>
      <td style="text-align: right">19.675</td>
      <td style="text-align: right">21.920</td>
      <td style="text-align: right">24.725</td>
      <td style="text-align: right">26.757</td>
    </tr>
    <tr>
      <td style="text-align: right">12</td>
      <td style="text-align: right">3.074</td>
      <td style="text-align: right">3.571</td>
      <td style="text-align: right">4.404</td>
      <td style="text-align: right">5.226</td>
      <td style="text-align: right">6.304</td>
      <td style="text-align: right">18.549</td>
      <td style="text-align: right">21.026</td>
      <td style="text-align: right">23.337</td>
      <td style="text-align: right">26.217</td>
      <td style="text-align: right">28.300</td>
    </tr>
    <tr>
      <td style="text-align: right">13</td>
      <td style="text-align: right">3.565</td>
      <td style="text-align: right">4.107</td>
      <td style="text-align: right">5.009</td>
      <td style="text-align: right">5.892</td>
      <td style="text-align: right">7.042</td>
      <td style="text-align: right">19.812</td>
      <td style="text-align: right">22.362</td>
      <td style="text-align: right">24.736</td>
      <td style="text-align: right">27.688</td>
      <td style="text-align: right">29.819</td>
    </tr>
    <tr>
      <td style="text-align: right">14</td>
      <td style="text-align: right">4.075</td>
      <td style="text-align: right">4.660</td>
      <td style="text-align: right">5.629</td>
      <td style="text-align: right">6.571</td>
      <td style="text-align: right">7.790</td>
      <td style="text-align: right">21.064</td>
      <td style="text-align: right">23.685</td>
      <td style="text-align: right">26.119</td>
      <td style="text-align: right">29.141</td>
      <td style="text-align: right">31.319</td>
    </tr>
    <tr>
      <td style="text-align: right">15</td>
      <td style="text-align: right">4.601</td>
      <td style="text-align: right">5.229</td>
      <td style="text-align: right">6.262</td>
      <td style="text-align: right">7.261</td>
      <td style="text-align: right">8.547</td>
      <td style="text-align: right">22.307</td>
      <td style="text-align: right">24.996</td>
      <td style="text-align: right">27.488</td>
      <td style="text-align: right">30.578</td>
      <td style="text-align: right">32.801</td>
    </tr>
    <tr>
      <td style="text-align: right">16</td>
      <td style="text-align: right">5.142</td>
      <td style="text-align: right">5.812</td>
      <td style="text-align: right">6.908</td>
      <td style="text-align: right">7.962</td>
      <td style="text-align: right">9.312</td>
      <td style="text-align: right">23.542</td>
      <td style="text-align: right">26.296</td>
      <td style="text-align: right">28.845</td>
      <td style="text-align: right">32.000</td>
      <td style="text-align: right">34.267</td>
    </tr>
  </tbody>
</table>

<p>Ta có <strong>bậc tự do (df)</strong> bằng <strong>1</strong> (được tính toán dựa vào bảng tương quan phía trên) và  \(\alpha = 0,05\) thì giá trị <strong>Chi-Square</strong> chấp nhận là <strong>3.84</strong>.</p>

<p>Nhận thấy giá trị <strong>Chi-Square</strong> tính được thấp hơn giá trị <strong>Chi-Square</strong> chấp nhận thì ta chấp nhận giả thiết rỗng. Hay ta có thể kết luận được rằng hai biến cố đã cho độc lập nhau. Vậy nếu ta xem <strong>Giới tính</strong> là một đặc trưng cần xem xét của mô hình và <strong>Rời bỏ ngân hàng</strong> hay không là lớp giá trị mô hình cần phân loại, thì ta có thể kết luận, <strong>Giới tính</strong> không thể được sử dụng để huấn luyện mô hình vì hai biến cố này không có mối liên hệ lẫn nhau.</p>

<h1 id="sử-dụng-chi-square-để-lựa-chọn-đặc-trưng-cho-mô-hình-phân-loại-văn-bản">Sử dụng Chi-Square để lựa chọn đặc trưng cho mô hình phân loại văn bản</h1>
<p>Một phương pháp lựa chọn đặc trưng phổ biến được sử dụng với dữ liệu văn bản là lựa chọn đặc trưng với <strong>Chi-Square</strong>. \(\chi^{2}\) như chúng ta thấy ở trên có thể được sử dụng trong thống kê để kiểm tra tính độc lập của hai biến cố. Cụ thể hơn, trong lựa chọn đặc trưng cho mô hình, chúng ta sử dụng nó để kiểm tra một thuật ngữ cụ thể và một lớp phân loại cụ thể có độc lập hay không.</p>

<p>Cho một văn bản \(D\), chúng tôi ước tính số lượng sau cho mỗi thuật ngữ và xếp hạng chúng theo điểm số của chúng:</p>

\[\chi^2(D, t, c) = \sum_{e_t \in \{0, 1\}} \sum_{e_c \in \{0, 1\}}  \frac{ (O_{e_te_c} - E_{e_te_c} )^2 }{ E_{e_te_c} }\]

<p>Trong đó:</p>
<ul>
  <li>\(O\) là tần số quan sát và \(E\) tần số kỳ vọng</li>
  <li>\(e_{t}\) nhận giá trị \(1\) nếu văn bản có chứa thuật ngữ \(t\), \(0\) với trường hợp ngược lại.</li>
  <li>\(e_{c}\) nhận giá trị \(1\) nếu văn bản thuộc lớp phân loại \(c\), \(0\) với trường hợp ngược lại.</li>
</ul>

<p>Với mỗi đặc trưng (thuật ngữ), một điểm  \(\chi^{2}\) tương ứng chỉ ra <strong>Giả thuyết rỗng</strong> \(H_{0}\) về tính độc lập của hai biến cố (có nghĩa là lớp của văn bản được phân loại không ảnh hưởng đến tần suất xuất hiện của thuật ngữ) nên bị bác bỏ hay sự xuất hiện của thuật ngữ và lớp của văn bản phụ thuộc lẫn nhau. Hay trong trường hợp này, chúng ta sẽ chọn thuật ngữ này làm đặc trưng cho mô hình phân loại văn bản.</p>

<h1 id="kết-luận">Kết luận</h1>
<p><strong>Chi-Square</strong> nhạy cảm với kích thước mẫu. Các mối quan hệ có thể có ý nghĩa khi chúng không chỉ đơn giản là do một mẫu rất lớn được sử dụng. Ngoài ra, <strong>Chi-Square</strong> không thể xác định liệu một biến cố có mối quan hệ nhân quả với biến khác hay không. Nó chỉ có thể xác định liệu hai biến cố có liên quan với nhau hay không.. Nói chung, khi giá trị kỳ vọng ​​trong một ô của bảng tương quan nhỏ hơn 5, <strong>Chi-Square</strong> có thể dẫn đến sai sót trong kết luận. Hy vọng bài viết có thể giúp bạn có cái nhìn tổng quan về phương pháp này và có thể áp dụng nó cho mô hình của bạn.</p>]]></content><author><name>zhao</name></author><category term="Machine-Learning" /><category term="Data Science" /><category term="Statistics" /><category term="Machine Learning" /><category term="Feature Selection" /><summary type="html"><![CDATA[Lựa chọn đặc trưng là một trong những vấn đề quan trọng trong học máy, khi chúng ta có một đống cái đặc trưng và quyết định xem những đặc trưng nào là tốt nhất để xây dựng mô hình.]]></summary></entry><entry><title type="html">Kiểm thử bằng phương pháp phân tích giá trị biên</title><link href="https://zhaospei.github.io//testing/2023/05/13/kiem-thu-gia-tri-bien/" rel="alternate" type="text/html" title="Kiểm thử bằng phương pháp phân tích giá trị biên" /><published>2023-05-13T00:00:00+07:00</published><updated>2023-05-13T00:00:00+07:00</updated><id>https://zhaospei.github.io//testing/2023/05/13/kiem-thu-gia-tri-bien</id><content type="html" xml:base="https://zhaospei.github.io//testing/2023/05/13/kiem-thu-gia-tri-bien/"><![CDATA[<p>Trong quá trình phát triển phần mềm, kiểm thử là một bước không thể thiếu để đảm bảo chất lượng và độ tin cậy của sản phẩm.</p>

<p>Trong số các phương pháp kiểm thử, kiểm thử phân tích giá trị biên (Boundary Value Analysis) đã được đánh giá cao vì tính hiệu quả và độ chính xác của nó. Phương pháp này giúp tập trung kiểm thử vào các giá trị biên của dữ liệu đầu vào, từ đó giảm thiểu thời gian và chi phí kiểm thử.</p>

<p>Bài viết này sẽ cách sinh test cho ca kiểm thử phân tích giá trị biên thông qua một bài toán kiểm thử nhỏ.</p>

<h1 id="bài-toán">Bài toán</h1>

<p><strong>DummyTel</strong> có cấu trúc tỷ lệ sau đây cho các cuộc gọi đường dài:</p>

<ul>
  <li>Bất kỳ cuộc gọi nào bắt đầu lúc hoặc sau 18:00 nhưng trước 08:00 được giảm 50%.</li>
  <li>Bất kỳ cuộc gọi nào bắt đầu lúc hoặc sau 08:00 nhưng trước 18:00 được tính giá đầy đủ.</li>
  <li>Bất kỳ cuộc gọi nào dài hơn 60 phút đều được giảm giá 15% trên chi phí (sau khi trừ đi bất kỳ khoản giảm giá nào khác).</li>
</ul>

<p>Chương trình đọc <strong>thời điểm bắt đầu cuộc gọi</strong> dựa trên đồng hồ 24 giờ và <strong>thời lượng của cuộc gọi</strong>. Thời gian cuộc gọi tối đa là 180 phút.</p>

<p>Chương trả về:</p>
<ul>
  <li>-1 nếu đầu vào không hợp lệ.</li>
  <li>0  nếu không được giảm giá.</li>
  <li>1  nếu được giảm 15%.</li>
  <li>2  nếu được giảm 50%.</li>
  <li>3  nếu vừa được giảm 50% và 15%.</li>
</ul>

<p>Chương trình sẽ giả sử chỉ các giá trị số nguyên được nhập vào, thời lượng không âm và thời gian bắt đầu biểu thị thời gian đồng hồ thực.</p>

<h1 id="phân-tích-yêu-cầu">Phân tích yêu cầu</h1>

<p>Đầu vào của chương trình: Thời điểm bắt đầu, Thời lượng của cuộc gọi. 
Đầu ra của chường trình: Chi phí của cuộc gọi 
Điều kiện hợp lệ của đầu vào:</p>
<ul>
  <li>Thời điểm bắt đầu: Có giá trị nguyên trong khoảng từ 0 đến 23.</li>
  <li>Thời lượng cuộc gọi: Từ 0 đến 180.
Giá trị đầu ra: 0 (nếu không được giảm giá), 1 (nếu được giảm 15%), 2 (nếu được giảm 50%), 3 (nếu vừa được giảm 50% và 15%).</li>
</ul>

<h1 id="phân-vùng-tương-đương">Phân vùng tương đương</h1>
<p>Ta chia thành các giá trị đầu vào thành các phân vùng tương đương sau:</p>

<p>Gọi <strong>TĐBB</strong> là Thời điểm bắt đầu cuộc gọi, <strong>TLCG</strong> là Thời lượng cuộc gọi.</p>

<table>
  <thead>
    <tr>
      <th>TH</th>
      <th>Inputs</th>
      <th>Output</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>TĐBB ∉{0,…,23} hoặc TGCG ∉{0,…,180}</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Hợp lệ và (8 &lt;= TĐBB &lt; 18 và TGCG &lt;= 60)</td>
      <td>0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Hợp lệ và (8 &lt;= TĐBB &lt; 18 và TGCG &gt; 60)</td>
      <td>1</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Hợp lệ và (TGCG &lt;= 60 và (TĐBB &gt;= 18 hoặc TĐBB &lt; 8))</td>
      <td>2</td>
    </tr>
    <tr>
      <td>5</td>
      <td>Các TH còn lại</td>
      <td>3</td>
    </tr>
  </tbody>
</table>

<p>Từ bảng trên ta sinh 5 test cho 5 phần vùng tương đương lần lượt là:</p>

<table>
  <thead>
    <tr>
      <th>Testcase</th>
      <th>Inputs</th>
      <th>EO</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>TĐBB = -2 và TGCG = 191</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>2</td>
      <td>TĐBB = 12 và TGCG = 45</td>
      <td>0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>TĐBB = 14 và TGCG = 92</td>
      <td>1</td>
    </tr>
    <tr>
      <td>4</td>
      <td>TĐBB = 20 và TGCG = 30</td>
      <td>2</td>
    </tr>
    <tr>
      <td>5</td>
      <td>TĐBB = 21 và TGCG = 124</td>
      <td>3</td>
    </tr>
  </tbody>
</table>

<h1 id="xác-định-biên">Xác định biên</h1>

<p><strong>Biên của TĐBB:</strong></p>

<p><img src="/assets/media/post/bien-1.png" alt="Biên của TĐBB" /></p>

<ul>
  <li>Giá trị biên của TĐBB lần lượt là 0, 8, 18, 23</li>
  <li>Giá trị nom của TĐBB là 12 (Điểm giữa của miền hợp lệ)</li>
</ul>

<p><strong>Biên của TGCG:</strong></p>

<p><img src="/assets/media/post/bien-2.png" alt="Biên của TĐBB" /></p>

<ul>
  <li>Giá trị biên của TGCG lần lượt là 0, 60, 180</li>
  <li>Giá trị nom của TGCG là 90 (Điểm giữa của miền hợp lệ)</li>
</ul>

<h1 id="sinh-test-cho-kiểm-thử-biên-đơn-giản">Sinh test cho kiểm thử biên đơn giản</h1>
<p>Mỗi giá trị biên của một input kết hợp với các giá trị nom của các input còn lại và một test bao gồm tất cả các giá trị nom của các input.</p>

<p>Hay chúng ta có tổng cộng: 4 + 3 + 1 = 8 (Testcases)</p>

<table>
  <thead>
    <tr>
      <th>Testcase</th>
      <th>Inputs</th>
      <th>EO</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>TĐBB = 0 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>2</td>
      <td>TĐBB = 8 và TGCG = 90</td>
      <td>1</td>
    </tr>
    <tr>
      <td>3</td>
      <td>TĐBB = 18 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>4</td>
      <td>TĐBB = 23 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>5</td>
      <td>TĐBB = 12 và TGCG = 0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>6</td>
      <td>TĐBB = 12 và TGCG = 60</td>
      <td>0</td>
    </tr>
    <tr>
      <td>7</td>
      <td>TĐBB = 12 và TGCG = 180</td>
      <td>1</td>
    </tr>
    <tr>
      <td>8</td>
      <td>TĐBB = 12 và TGCG = 90</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<h1 id="biên-và-cận-biên-trong-miền-hợp-lệ">Biên và cận biên trong miền hợp lệ</h1>
<p>Các test case tương tự như biên đơn giản và thêm các test case cận biên bằng cách kết hợp giá trị cận biên của một input với các giá trị nom của các input còn lại.</p>

<p>Lấy các giá trị cận biên cách giá trị biên một khoảng là 1.</p>

<p>TĐBB có 4 giá trị biên -&gt; 6 giá trị cận biên trong miền hợp lệ.</p>

<p>TGCG có 3 giá trị biên -&gt; 4 giá trị cận biên trong miền hợp lệ.</p>

<p>Vậy số test cases tất cả là 8 + 6 + 4 = 18 (Testcase)</p>

<table>
  <thead>
    <tr>
      <th>Testcase</th>
      <th>Inputs</th>
      <th>EO</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>TĐBB = 0 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>2</td>
      <td>TĐBB = 8 và TGCG = 90</td>
      <td>1</td>
    </tr>
    <tr>
      <td>3</td>
      <td>TĐBB = 18 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>4</td>
      <td>TĐBB = 23 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>5</td>
      <td>TĐBB = 12 và TGCG = 0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>6</td>
      <td>TĐBB = 12 và TGCG = 60</td>
      <td>0</td>
    </tr>
    <tr>
      <td>7</td>
      <td>TĐBB = 12 và TGCG = 180</td>
      <td>1</td>
    </tr>
    <tr>
      <td>8</td>
      <td>TĐBB = 12 và TGCG = 90</td>
      <td>1</td>
    </tr>
    <tr>
      <td>9</td>
      <td>TĐBB = 1 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>10</td>
      <td>TĐBB = 7 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>11</td>
      <td>TĐBB = 9 và TGCG = 90</td>
      <td>1</td>
    </tr>
    <tr>
      <td>12</td>
      <td>TĐBB = 17 và TGCG = 90</td>
      <td>1</td>
    </tr>
    <tr>
      <td>13</td>
      <td>TĐBB = 19 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>14</td>
      <td>TĐBB = 22 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>15</td>
      <td>TĐBB = 12 và TGCG = 1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>16</td>
      <td>TĐBB = 12 và TGCG = 59</td>
      <td>0</td>
    </tr>
    <tr>
      <td>17</td>
      <td>TĐBB = 12 và TGCG = 61</td>
      <td>1</td>
    </tr>
    <tr>
      <td>18</td>
      <td>TĐBB = 12 và TGCG = 179</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<h1 id="biên-và-cận-biên-trong-toàn-bộ-miền-giá-trị">Biên và cận biên trong toàn bộ miền giá trị.</h1>
<p>Các test case tương tự như biên và cận biên trong miền hợp lệ và thêm các test case cận biên ngoài miền hợp lệ bằng cách kết hợp giá trị cận biên ngoài miền hợp lệ của một input với các giá trị nom của các input còn lại.</p>

<p>Lấy các giá trị cận biên cách giá trị biên một khoảng là 1.</p>

<p>Nhận thấy:</p>
<ul>
  <li>TĐBB có 2 giá trị cận biên ngoài miền hợp lệ.</li>
  <li>TGCG có 2 giá trị cận biên ngoài miền hợp lệ.</li>
</ul>

<p>Vậy số test cases tất cả là 18 + 2 + 2 = 22 (Testcase)</p>

<table>
  <thead>
    <tr>
      <th>Testcase</th>
      <th>Inputs</th>
      <th>EO</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>TĐBB = 0 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>2</td>
      <td>TĐBB = 8 và TGCG = 90</td>
      <td>1</td>
    </tr>
    <tr>
      <td>3</td>
      <td>TĐBB = 18 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>4</td>
      <td>TĐBB = 23 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>5</td>
      <td>TĐBB = 12 và TGCG = 0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>6</td>
      <td>TĐBB = 12 và TGCG = 60</td>
      <td>0</td>
    </tr>
    <tr>
      <td>7</td>
      <td>TĐBB = 12 và TGCG = 180</td>
      <td>1</td>
    </tr>
    <tr>
      <td>8</td>
      <td>TĐBB = 12 và TGCG = 90</td>
      <td>1</td>
    </tr>
    <tr>
      <td>9</td>
      <td>TĐBB = 1 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>10</td>
      <td>TĐBB = 7 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>11</td>
      <td>TĐBB = 9 và TGCG = 90</td>
      <td>1</td>
    </tr>
    <tr>
      <td>12</td>
      <td>TĐBB = 17 và TGCG = 90</td>
      <td>1</td>
    </tr>
    <tr>
      <td>13</td>
      <td>TĐBB = 19 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>14</td>
      <td>TĐBB = 22 và TGCG = 90</td>
      <td>3</td>
    </tr>
    <tr>
      <td>15</td>
      <td>TĐBB = 12 và TGCG = 1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>16</td>
      <td>TĐBB = 12 và TGCG = 59</td>
      <td>0</td>
    </tr>
    <tr>
      <td>17</td>
      <td>TĐBB = 12 và TGCG = 61</td>
      <td>1</td>
    </tr>
    <tr>
      <td>18</td>
      <td>TĐBB = 12 và TGCG = 179</td>
      <td>1</td>
    </tr>
    <tr>
      <td>19</td>
      <td>TĐBB = 12 và TGCG = -1</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>20</td>
      <td>TĐBB = 12 và TGCG = 181</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>21</td>
      <td>TĐBB = -1 và TGCG = 90</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>22</td>
      <td>TĐBB = 24 và TGCG = 90</td>
      <td>-1</td>
    </tr>
  </tbody>
</table>

<h1 id="kết-luận">Kết luận</h1>
<p>Nhận thấy toàn bộ test case trong kiểm thử giá trị biên trên đều không cho output nằm trong trường hợp số 2. Vì vậy, kiểm thử giá trị biên sẽ không thể bao hàm toàn bộ trường hợp và thường kết hợp với các loại kiểm thử khác như phân hoạch tương đương hoặc kiểm thử bằng quyết định,.. 
Thường trong thực tế, các công ty thường sinh test kiểu này: Kết hợp phân hoạch tương đương (hoặc bảng quyết định) với phân tích giá trị biên thường cho kết quả tốt vì nó có chi phí, thời gian, công sức vừa phải và bao hàm hầu hết mọi trường hợp của giá trị đầu vào.</p>]]></content><author><name>zhao</name></author><category term="Testing" /><category term="testing" /><summary type="html"><![CDATA[Trong quá trình phát triển phần mềm, kiểm thử là một bước không thể thiếu để đảm bảo chất lượng và độ tin cậy của sản phẩm.]]></summary></entry><entry><title type="html">Từ nơ-ron sinh học đến nơ-ron nhân tạo</title><link href="https://zhaospei.github.io//deep-learning/2023/05/13/tu-noron-sinh-hoc-den-noron-nhan-tao/" rel="alternate" type="text/html" title="Từ nơ-ron sinh học đến nơ-ron nhân tạo" /><published>2023-05-13T00:00:00+07:00</published><updated>2023-05-13T00:00:00+07:00</updated><id>https://zhaospei.github.io//deep-learning/2023/05/13/tu-noron-sinh-hoc-den-noron-nhan-tao</id><content type="html" xml:base="https://zhaospei.github.io//deep-learning/2023/05/13/tu-noron-sinh-hoc-den-noron-nhan-tao/"><![CDATA[<p>Con người lấy cảm hứng từ các loài chim để bay, loài sứa biển để điều trị ung thư, da cá mập để làm bề mặt vật liệu chống bám và còn rất nhiều phát minh khác lấy cảm hứng từ thiên nhiên.</p>

<p>Vì thế, rất dễ hiểu khi ta xem xét cấu trúc bộ não sinh học để tìm cảm hứng cho việc xây dựng một bộ máy thông minh. Đây cũng chính là ý tưởng đằng sau của <strong>Mạng nơ-ron nhân tạo (artificial neural network - ANN)</strong>.</p>

<p>Tuy nhiên, dù máy bay lấy cảm hứng từ loài chim, chúng lại không cần phải vỗ cánh. Tương tự, ANN đã dần trở nên rất khác biệt so với phiên bản sinh học của nó. Một số nhà nghiên cứu còn cho rằng chúng ta nên ngừng sử dụng phép so sánh với sinh học (ví dụ như sử dụng từ “<em>đơn vị</em>” - “<em>unit</em>” - thay cho “<em>nơ-ron</em>”), vì lo rằng phép so sánh này sẽ giới hạn sự sáng tạo trong các hệ thống hợp lý về mặt sinh học.</p>

<h1 id="nơ-ron-sinh-học">Nơ-ron Sinh học</h1>

<p>Trước khi chúng ta bàn về nơ-ron nhân tạo, chúng ta cùng tìm hiểu qua nơ-ron sinh học. <em>Nơ-ron sinh học</em> là một tế bào với vẻ ngoài khác thường được tìm thấy trong não động vật. Nó bao gồm một <em>thân tế bào</em> chứa nhân và hầu hết các thành phần phức tạp khác, với các nhánh mở rộng được gọi là <em>sợi nhánh</em>, cùng với một phần mở rộng rất dài được gọi là <em>sợi trục</em>. Chiều dài của sợi trục lớn hơn thân tế bào từ vài lần cho đến hàng chục nghìn lần. Ở gần cuối, sợi trục tách thành nhiều nhành được gọi là <em>telodendria</em>, và tại đỉnh của những nhành này là các cấu trúc siêu nhỏ được gọi là <em>điểm tiếp hợp synap</em> (hoặc đơn giản là <em>synap</em>), được nối với các sợi nhánh hoặc thân tế bào của những nơ-ron khác. Các nơ-ron sinh học sinh ra các xung điện ngắn được gọi là <em>điện thế hoạt động</em> (hoặc đơn giản  là <em>tín hiệu</em>). Chúng di chuyển dọc theo sợi trục và kích thích synap giải phóng ra tín hiệu hoá học được gọi <em>chất dẫn truyền thần kinh</em>. Khi một nơ-ron nhận đủ một lượng chất dẫn truyền thần kinh này trong một vài mili giây, nó sẽ phát ra các xung điện của chính nó (thật ra, điều này còn phụ thuộc vào chất dẫn truyền thần kinh bởi có một số chất ức chế sự kích hoạt của nơ-ron).</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/no-ron-sinh-hocc.png" alt="Nơ-ron sinh học" style="margin: auto;" />
    <figcaption style="font-style: italic;">Nơ-ron sinh học</figcaption>
</figure>

<p>Do đó, mặc dù các nơ-ron sinh học riêng lẻ dường như có cách hoạt động khá đơn giản, chúng lại được tổ chức trong một mạng lưới rộng lớn với hàng tỷ nơ-ron, và ở đố mỗi nơ-ron được kết nối với hàng nghìn nơ-ron khác. Các phép tính với độ phức tạp cao có thể được xử lý bởi một mạng nơ-ron khá đơn giản, tương tự như cách một tổ kiến phức tạp được tạo nên bởi nỗ lực tổng hợp từ những các thể kiến riêng lẻ. <em>Kiến trúc mạng nơ-ron sinh học (biological neural network - BNN)</em> vẫn đang là chủ đề được tích cực nghiên cứ, tuy nhiên một vài phần của não đã được khám phá, và có vẻ như các nơ-ron thường được sắp xếp thành các tầng liên tiếp, đặc biệt là ở vùng đại não (lớp ngoài cùng của bộ não), như có thể thấy ở hình bên dưới.</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/cac-tang-trong-mang-no-ron-sinh-hoc.png" alt="Các tầng trong mạng nơ-ron sinh học (Võ não người)" style="margin: auto;" />
    <figcaption style="font-style: italic;">Các tầng trong mạng nơ-ron sinh học (Võ não người)</figcaption>
</figure>

<h1 id="nơ-ron-nhân-tạo">Nơ-ron Nhân tạo</h1>

<p>Mạng nơ-ron Nhân tạo là một phương thức, công cụ trong lĩnh vực trí tuệ nhân tạo, được lấy cảm hứng từ cấu trúc bộ não con người, để máy tính có thể xử lý dữ liệu một cách tự động. Đây là một loại Học máy(Machine Learning), còn được gọi là Học sâu (Deep Learning), sử dụng các nơ-ron kết nối với nhau trong một cấu trúc phân lớp tương tự như bộ não con người. Quá trình này cho phép máy tính học hỏi từ sai lầm và cải thiện liên tục, tạo ra một hệ thống thích ứng. Mạng nơ-ron nhân tạo được áp dụng để giải quyết các vấn đề phức tạp, chẳng hạn như tóm tắt tài liệu hoặc nhận diện khuôn mặt, với độ chính xác cao hơn.</p>

<p>Bộ não sinh học chính là nguồn cảm hứng cho kiến trúc mạng nơ ron. Các tế bào não của con người, có được gọi là nơ-ron, tạo thành một mạng lưới phức tạp, có tính liên kết cao và gửi các tín hiệu điện đến nhau để giúp con người xử lý thông tin. Tương tự, một mạng nơ-ron nhân tạo được tạo ra từ các tế bào nơ-ron nhân tạo, cùng nhau phối hợp để giải quyết một vấn đề. Nơ-ron nhân tạo là các mô đun phần mềm, được gọi là nút và mạng nơ-ron nhân tạo là các chương trình phần mềm hoặc thuật toán mà về cơ bản, sử dụng hệ thống máy tính để giải quyết các phép toán.</p>

<p>McCulloch và Pitts đề xuất một mô hình rất đơn giản để mô tả mạng nơ-ron sinh học, và mô hình này về sau được biết đến là nơ-ron nhân tạo: nó có một hoặc nhiều đầu vào nhị phân (bật/tắt) và một đầu ra nhị phân. Nơ-ron nhân tạo kích hoạt đầu vào của nó khi có nhiều hơn một lượng đầu vào nhất định được kích hoạt. Trong bài báo, họ đã chứng minh rằng ngay cả với một mô hình đơn giản như trên, ta vẫn có thể xây dựng một mạng chứa các nơ-ron nhân tạo với khả năng tính toán bất kỳ mệnh đề logic nào. Hình phía dưới là một vài ANN thực hiện các phép toán khác nhau, với giả định rằng một nơ-ron được kích hoạt khi ít nhất hai trong số các đầu vào của nó được kích hoạt.</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/ANN-phep-tinh-logic.png" alt="ANN thực hiện các phép tính logic đơn giản" style="margin: auto;" />
    <figcaption style="font-style: italic;">ANN thực hiện các phép tính logic đơn giản</figcaption>
</figure>

<p>Các mạng nơ-ron nhân tạo được nghiên cứu và phát triển thay đổi liên tục trong nhiều năm, với nhiều kiến trúc mạng nơ-ron nhân tạo khác nhau. Ngày nay, một mạng nơ-ron nhân tạo bao gồm 3 <em>lớp (layer)</em>:</p>

<p><strong>Lớp đầu vào</strong></p>

<p>Thông tin từ thế giới bên ngoài đi vào mạng nơ-ron nhân tạo thông qua lớp đầu vào. Các nút đầu vào xử lý dữ liệu, phân tích hoặc phân loại và sau đó chuyển dữ liệu sang lớp tiếp theo.</p>

<p><strong>Lớp ẩn</strong></p>

<p>Dữ liệu đi vào lớp ẩn đến từ lớp đầu vào hoặc các lớp ẩn khác. Mạng nơ-ron nhân tạo có thể có một số lượng lớn lớp ẩn. Mỗi lớp ẩn phân tích dữ liệu đầu ra từ lớp trước, xử lý dữ liệu đó sâu hơn và rồi chuyển dữ liệu sang lớp tiếp theo.</p>

<p><strong>Lớp đầu ra</strong></p>

<p>Lớp đầu ra cho ra kết quả cuối cùng của tất cả dữ liệu được xử lý bởi mạng nơ-ron nhân tạo. Lớp này có thể có một hoặc nhiều nút. Ví dụ: giả sử chúng ta gặp phải một vấn đề phân loại nhị phân (có/không), lớp đầu ra sẽ có một nút đầu ra, nút này sẽ cho kết quả 1 hoặc 0. Tuy nhiên, nếu chúng ta gặp phải vấn đề phân loại nhiều lớp, lớp đầu ra sẽ có thể bao gồm nhiều hơn một nút đầu ra.</p>

<p><strong>Kiến trúc mạng nơ-ron chuyên sâu</strong></p>

<p>Mạng nơ-ron chuyên sâu, hoặc mạng deep learning, có nhiều lớp ẩn với hàng triệu nơ-ron nhân tạo liên kết với nhau. Một con số, có tên gọi là trọng số, đại diện cho các kết nối giữa hai nút. Trọng số sẽ dương nếu một nút kích thích nút còn lại, hoặc âm nếu một nút ngăn cản nút còn lại. Các nút với trọng số cao hơn sẽ có ảnh hưởng lớn hơn lên các nút khác.</p>

<p>Về mặt lý thuyết, mạng nơ-ron chuyên sâu có thể ánh xạ bất kỳ loại dữ liệu đầu vào với bất kỳ loại dữ liệu đầu ra nào. Tuy nhiên, chúng cũng cần được đào tạo hơn rất nhiều so với các phương pháp máy học khác. Chúng cần hàng triệu ví dụ về dữ liệu đào tạo thay vì hàng trăm hoặc hàng nghìn ví dụ mà một mạng đơn giản hơn thường cần.</p>

<p>Phía dưới là một ví dụ cho kiến trúc mạng nơ-ron nhân tạo</p>

<figure class="image" style="text-align: center;">
    <img src="/assets/media/post/no-ron-nhan-tao.png" alt="Mạng nơ-ron nhân tạo" style="margin: auto;" />
    <figcaption style="font-style: italic;">Mạng nơ-ron nhân tạo</figcaption>
</figure>

<h1 id="từ-nơ-ron-sinh-học-đến-nơ-ron-nhân-tạo">Từ Nơ-ron Sinh học đến Nơ-ron Nhân tạo</h1>

<p>Một điều đáng nhiên là ANN đã tồn tại từ khá lâu: chúng được giới thiệu vào năm 1943 bởi nhà sinh lý học thần kinh <strong>Warren McCulloch</strong> và nhà toán học <strong>Walter Pitts</strong>. Trong bài báo mang tính bước ngoặt của họ “<em>A Logical Calculus of Ideas Immanent in Nervous Activity</em>”, McCulloch và Pitts đã trình bày một mô hình tính toán giản lược của cách mà các nơ-ron sinh học có thể làm việc cùng nhau trong não bộ động vật để thực hiện các phép tính phức tạp bằng <em>logic mệnh đề (propositional logic)</em>. Đây chính là kiến trúc mạng nơ-ron nhân tạo đầu tiên. Kể từ đó, hàng loạt các kiến trúc khác đã được phát minh, xử lý tính toán linh hoạt và hoạt động hiệu quả hơn.</p>

<p>Sự thành công sớm của ANN đã khiến nhiều người tin rằng họ sẽ sớm được nói chuyện với những cố máy thực sự thông minh. Vào thập niên 1960, khi rõ ràng là lời hứa này sẽ không được thực hiện (ít nhất là trong một khoảng thời gian dài), các nguồn tài trợ được chuyển sang lĩnh vực khác, và ANN bước vào một mùa đông dài. Vào thập niên 1980, các kiến trúc mới được phát minh và các kỹ thuật huấn luyện tốt hơn được phát triển, giúp cho <em>thuyết kết nối (connectionism - ngành nghiên cứu về mạng nơ-ron)</em> bắt đầu được quan tâm trở lại. Tuy nhiên, tiến độ trong ngành này khá chậm, vào vào thập niên 1990, các kỹ thuật Học Máy mạnh mẽ khác đã được phát minh, ví dụ <em>Máy Vector Hỗ trợ</em>,… Có vẻ những kỹ thuật này đem lại kết quả tốt hơn và nền tảng lý thuyết vững chắc hơn so với ANN, nên lần nữa việc nghiên cứu ANN lại bị trì hoãn.</p>

<p>Giờ đây, khi lượng dữ liệu lớn bùng nổ và sự phát triển vượt bậc về năng lực tính toán từ thập niên 1990, chúng ta lại đang chứng kiến thêm một làn sống quan tâm khác tới ANN. Liệu xu hướng này sẽ lại lụi tàn như trước?</p>]]></content><author><name>zhao</name></author><category term="Deep-Learning" /><category term="Neuron" /><category term="Deep Learning" /><summary type="html"><![CDATA[Con người lấy cảm hứng từ các loài chim để bay, loài sứa biển để điều trị ung thư, da cá mập để làm bề mặt vật liệu chống bám và còn rất nhiều phát minh khác lấy cảm hứng từ thiên nhiên.]]></summary></entry></feed>